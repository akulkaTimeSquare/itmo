{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание № 2. Нейронные сети\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Работу выполнил:**\n",
    "\n",
    "Мовчан Игорь, 368540"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "CFxNZVf0hbNxeCop4nIN2T",
     "type": "MD"
    }
   },
   "source": [
    "## Прогнозирование цены на жилье с помощью нейросетевой регрессионной модели\n",
    "\n",
    "Необходимо по имеющимся данным о ценах на жильё предсказать окончательную цену каждого дома с учетом характеристик домов с использованием нейронной сети. Описание набора данных  содержит 80 классов (набор переменых) классификации оценки типа жилья, и находится в файле `data_description.txt`.\n",
    "\n",
    "В работе требуется дополнить раздел «Моделирование» в подразделе «Построение и обучение модели» создать и инициализировать последовательную модель нейронной сети с помощью фрэймворков тренировки нейронных сетей как: Torch или Tensorflow. Скомпилировать нейронную сеть выбрав функцию потерь и оптимизатор соответственно. Оценить точность полученных результатов. Вывести предсказанные данные о продаже. \n",
    "\n",
    "\n",
    "### Импорт библиотек\n",
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "BuwU26gdC1ZUAFRZo5cgMp",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "yDvlZr4HAkGEmZYhi0oxLW",
     "type": "MD"
    }
   },
   "source": [
    "### Считываем набор данных\n",
    "\n",
    "\n",
    "Загрузим набор данных и присвоим следующими переменные:\n",
    "\n",
    "* `train_data`: данные, используемые для обучения модели\n",
    "* `test_data`: данные, используемые для проверки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "cv3SeTOL5K6waszFLFVrHV",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "OkRocMZR6KzqkfMDYArdLj",
     "type": "MD"
    }
   },
   "source": [
    "## Подготовка данных\n",
    "### Отобразим обучающие и проверочные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "FeQpLhWFiCUvkwKTZJGt77",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "PtlgCCQ1tenYmqz4uqrL0r",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
       "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
       "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
       "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       0      6    2010        WD         Normal  \n",
       "1   12500      6    2010        WD         Normal  \n",
       "2       0      3    2010        WD         Normal  \n",
       "3       0      6    2010        WD         Normal  \n",
       "4       0      1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "m2HZ1ayKDr8MOHpK2TtCFB",
     "type": "MD"
    }
   },
   "source": [
    "Как можно видеть, `train_data` имеет на один столбец больше, чем `test_data`, это столбец `SalePrice`, для обучения модели перед применением ее для предсказания меток в test_data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "LvA8hUPBQzVxQWBqcatifj",
     "type": "MD"
    }
   },
   "source": [
    "### Проверяем нет ли тестовые данные пустых значений значений (Nan)\n",
    "\n",
    "Построим функцию `def missing_value_checker` для проверки и подсчёта пропущеных значений в test_data. А также выведем тип данных этих значений.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "pxUQWKUmcS70sX8fsExVI9",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning: 4, type: object\n",
      "LotFrontage: 227, type: float64\n",
      "Alley: 1352, type: object\n",
      "Utilities: 2, type: object\n",
      "Exterior1st: 1, type: object\n",
      "Exterior2nd: 1, type: object\n",
      "MasVnrType: 894, type: object\n",
      "MasVnrArea: 15, type: float64\n",
      "BsmtQual: 44, type: object\n",
      "BsmtCond: 45, type: object\n",
      "BsmtExposure: 44, type: object\n",
      "BsmtFinType1: 42, type: object\n",
      "BsmtFinSF1: 1, type: float64\n",
      "BsmtFinType2: 42, type: object\n",
      "BsmtFinSF2: 1, type: float64\n",
      "BsmtUnfSF: 1, type: float64\n",
      "TotalBsmtSF: 1, type: float64\n",
      "BsmtFullBath: 2, type: float64\n",
      "BsmtHalfBath: 2, type: float64\n",
      "KitchenQual: 1, type: object\n",
      "Functional: 2, type: object\n",
      "FireplaceQu: 730, type: object\n",
      "GarageType: 76, type: object\n",
      "GarageYrBlt: 78, type: float64\n",
      "GarageFinish: 78, type: object\n",
      "GarageCars: 1, type: float64\n",
      "GarageArea: 1, type: float64\n",
      "GarageQual: 78, type: object\n",
      "GarageCond: 78, type: object\n",
      "PoolQC: 1456, type: object\n",
      "Fence: 1169, type: object\n",
      "MiscFeature: 1408, type: object\n",
      "SaleType: 1, type: object\n",
      "['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType']\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "def missing_value_checker(data):\n",
    "    list = []\n",
    "    for feature in data.columns:\n",
    "        if data[feature].isnull().values.any():\n",
    "            \n",
    "            sum = data[feature].isna().sum()\n",
    "\n",
    "            type = data[feature].dtype\n",
    "\n",
    "            print (f'{feature}: {sum}, type: {type}')\n",
    "            \n",
    "            list.append(feature)\n",
    "    print(list)\n",
    "\n",
    "    print(len(list))\n",
    "\n",
    "missing_value_checker(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "U2c2Jm8OgAYtZqUCaBITi4",
     "type": "MD"
    }
   },
   "source": [
    "Проверяем какие признаки в таблице можно оставить, а какие удалить. Если пропущенных значений слишком много, то удалим признак. Если их небольшое количество, то заполним `mean` или `median` для чисел, новая категория `missing` для строковых объектов.\n",
    "\n",
    "В соответствии с этим:\n",
    "\n",
    "– удалим ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'];\n",
    "\n",
    "– заполним числовое отсутствующее значение значением `mean`;\n",
    "\n",
    "– заполним строковое отсутствующее значение значением `missing`.\n",
    "\n",
    "Также нормализуем наши данные для получения более лучших результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "2KCsgKLRNIzdZGdZDJavSo",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       4\n",
       "2       4\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "1454    5\n",
       "1455    5\n",
       "1456    4\n",
       "1457    4\n",
       "1458    4\n",
       "Name: MSZoning, Length: 1459, dtype: int8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = ['Id', 'Alley','FireplaceQu','PoolQC', 'Fence', 'MiscFeature']\n",
    "test_edited = test_data.drop(to_drop, axis=1)\n",
    "train_edited = train_data.drop(to_drop, axis=1)\n",
    "\n",
    "def nan_filler(data, min_max={}):\n",
    "    flag = bool(min_max.copy())\n",
    "    for label, content in data.items():\n",
    "        if pd.api.types.is_numeric_dtype(content):\n",
    "            data[label] = content.fillna(content.median())\n",
    "            if label != \"SalePrice\":\n",
    "                if not flag:\n",
    "                    min_max[label] = [data[label].min(), data[label].max()]\n",
    "                minimum, maximum = min_max[label]\n",
    "                data[label] = (data[label] - minimum)/(maximum - minimum)\n",
    "        else:\n",
    "            data[label] = content.astype(\"category\").cat.as_ordered()\n",
    "            data[label] = pd.Categorical(content).codes+1\n",
    "    return min_max\n",
    "\n",
    "min_max = nan_filler(test_edited)\n",
    "nan_filler(train_edited, min_max)\n",
    "test_edited[\"MSZoning\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "at2x2hjP7J2ggCGjl4bDdp",
     "type": "MD"
    }
   },
   "source": [
    "### Перепроверим наши данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ndeDW0XUjTNQZbl08hStGd",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_value_checker(test_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "wLLxXh3dPBZhWswJRtePAF",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_value_checker(train_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "uun8jPN10ZuxbG043ZksEJ",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 75), (1459, 74))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edited.shape, test_edited.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Rlx0t4SQFyHXlcaeU5CL3e",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1459 entries, 0 to 1458\n",
      "Data columns (total 74 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1459 non-null   float64\n",
      " 1   MSZoning       1459 non-null   int8   \n",
      " 2   LotFrontage    1459 non-null   float64\n",
      " 3   LotArea        1459 non-null   float64\n",
      " 4   Street         1459 non-null   int8   \n",
      " 5   LotShape       1459 non-null   int8   \n",
      " 6   LandContour    1459 non-null   int8   \n",
      " 7   Utilities      1459 non-null   int8   \n",
      " 8   LotConfig      1459 non-null   int8   \n",
      " 9   LandSlope      1459 non-null   int8   \n",
      " 10  Neighborhood   1459 non-null   int8   \n",
      " 11  Condition1     1459 non-null   int8   \n",
      " 12  Condition2     1459 non-null   int8   \n",
      " 13  BldgType       1459 non-null   int8   \n",
      " 14  HouseStyle     1459 non-null   int8   \n",
      " 15  OverallQual    1459 non-null   float64\n",
      " 16  OverallCond    1459 non-null   float64\n",
      " 17  YearBuilt      1459 non-null   float64\n",
      " 18  YearRemodAdd   1459 non-null   float64\n",
      " 19  RoofStyle      1459 non-null   int8   \n",
      " 20  RoofMatl       1459 non-null   int8   \n",
      " 21  Exterior1st    1459 non-null   int8   \n",
      " 22  Exterior2nd    1459 non-null   int8   \n",
      " 23  MasVnrType     1459 non-null   int8   \n",
      " 24  MasVnrArea     1459 non-null   float64\n",
      " 25  ExterQual      1459 non-null   int8   \n",
      " 26  ExterCond      1459 non-null   int8   \n",
      " 27  Foundation     1459 non-null   int8   \n",
      " 28  BsmtQual       1459 non-null   int8   \n",
      " 29  BsmtCond       1459 non-null   int8   \n",
      " 30  BsmtExposure   1459 non-null   int8   \n",
      " 31  BsmtFinType1   1459 non-null   int8   \n",
      " 32  BsmtFinSF1     1459 non-null   float64\n",
      " 33  BsmtFinType2   1459 non-null   int8   \n",
      " 34  BsmtFinSF2     1459 non-null   float64\n",
      " 35  BsmtUnfSF      1459 non-null   float64\n",
      " 36  TotalBsmtSF    1459 non-null   float64\n",
      " 37  Heating        1459 non-null   int8   \n",
      " 38  HeatingQC      1459 non-null   int8   \n",
      " 39  CentralAir     1459 non-null   int8   \n",
      " 40  Electrical     1459 non-null   int8   \n",
      " 41  1stFlrSF       1459 non-null   float64\n",
      " 42  2ndFlrSF       1459 non-null   float64\n",
      " 43  LowQualFinSF   1459 non-null   float64\n",
      " 44  GrLivArea      1459 non-null   float64\n",
      " 45  BsmtFullBath   1459 non-null   float64\n",
      " 46  BsmtHalfBath   1459 non-null   float64\n",
      " 47  FullBath       1459 non-null   float64\n",
      " 48  HalfBath       1459 non-null   float64\n",
      " 49  BedroomAbvGr   1459 non-null   float64\n",
      " 50  KitchenAbvGr   1459 non-null   float64\n",
      " 51  KitchenQual    1459 non-null   int8   \n",
      " 52  TotRmsAbvGrd   1459 non-null   float64\n",
      " 53  Functional     1459 non-null   int8   \n",
      " 54  Fireplaces     1459 non-null   float64\n",
      " 55  GarageType     1459 non-null   int8   \n",
      " 56  GarageYrBlt    1459 non-null   float64\n",
      " 57  GarageFinish   1459 non-null   int8   \n",
      " 58  GarageCars     1459 non-null   float64\n",
      " 59  GarageArea     1459 non-null   float64\n",
      " 60  GarageQual     1459 non-null   int8   \n",
      " 61  GarageCond     1459 non-null   int8   \n",
      " 62  PavedDrive     1459 non-null   int8   \n",
      " 63  WoodDeckSF     1459 non-null   float64\n",
      " 64  OpenPorchSF    1459 non-null   float64\n",
      " 65  EnclosedPorch  1459 non-null   float64\n",
      " 66  3SsnPorch      1459 non-null   float64\n",
      " 67  ScreenPorch    1459 non-null   float64\n",
      " 68  PoolArea       1459 non-null   float64\n",
      " 69  MiscVal        1459 non-null   float64\n",
      " 70  MoSold         1459 non-null   float64\n",
      " 71  YrSold         1459 non-null   float64\n",
      " 72  SaleType       1459 non-null   int8   \n",
      " 73  SaleCondition  1459 non-null   int8   \n",
      "dtypes: float64(36), int8(38)\n",
      "memory usage: 464.6 KB\n"
     ]
    }
   ],
   "source": [
    "test_edited.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "F2soDeOs0hu9vFpzLvQWtO",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 75 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1460 non-null   float64\n",
      " 1   MSZoning       1460 non-null   int8   \n",
      " 2   LotFrontage    1460 non-null   float64\n",
      " 3   LotArea        1460 non-null   float64\n",
      " 4   Street         1460 non-null   int8   \n",
      " 5   LotShape       1460 non-null   int8   \n",
      " 6   LandContour    1460 non-null   int8   \n",
      " 7   Utilities      1460 non-null   int8   \n",
      " 8   LotConfig      1460 non-null   int8   \n",
      " 9   LandSlope      1460 non-null   int8   \n",
      " 10  Neighborhood   1460 non-null   int8   \n",
      " 11  Condition1     1460 non-null   int8   \n",
      " 12  Condition2     1460 non-null   int8   \n",
      " 13  BldgType       1460 non-null   int8   \n",
      " 14  HouseStyle     1460 non-null   int8   \n",
      " 15  OverallQual    1460 non-null   float64\n",
      " 16  OverallCond    1460 non-null   float64\n",
      " 17  YearBuilt      1460 non-null   float64\n",
      " 18  YearRemodAdd   1460 non-null   float64\n",
      " 19  RoofStyle      1460 non-null   int8   \n",
      " 20  RoofMatl       1460 non-null   int8   \n",
      " 21  Exterior1st    1460 non-null   int8   \n",
      " 22  Exterior2nd    1460 non-null   int8   \n",
      " 23  MasVnrType     1460 non-null   int8   \n",
      " 24  MasVnrArea     1460 non-null   float64\n",
      " 25  ExterQual      1460 non-null   int8   \n",
      " 26  ExterCond      1460 non-null   int8   \n",
      " 27  Foundation     1460 non-null   int8   \n",
      " 28  BsmtQual       1460 non-null   int8   \n",
      " 29  BsmtCond       1460 non-null   int8   \n",
      " 30  BsmtExposure   1460 non-null   int8   \n",
      " 31  BsmtFinType1   1460 non-null   int8   \n",
      " 32  BsmtFinSF1     1460 non-null   float64\n",
      " 33  BsmtFinType2   1460 non-null   int8   \n",
      " 34  BsmtFinSF2     1460 non-null   float64\n",
      " 35  BsmtUnfSF      1460 non-null   float64\n",
      " 36  TotalBsmtSF    1460 non-null   float64\n",
      " 37  Heating        1460 non-null   int8   \n",
      " 38  HeatingQC      1460 non-null   int8   \n",
      " 39  CentralAir     1460 non-null   int8   \n",
      " 40  Electrical     1460 non-null   int8   \n",
      " 41  1stFlrSF       1460 non-null   float64\n",
      " 42  2ndFlrSF       1460 non-null   float64\n",
      " 43  LowQualFinSF   1460 non-null   float64\n",
      " 44  GrLivArea      1460 non-null   float64\n",
      " 45  BsmtFullBath   1460 non-null   float64\n",
      " 46  BsmtHalfBath   1460 non-null   float64\n",
      " 47  FullBath       1460 non-null   float64\n",
      " 48  HalfBath       1460 non-null   float64\n",
      " 49  BedroomAbvGr   1460 non-null   float64\n",
      " 50  KitchenAbvGr   1460 non-null   float64\n",
      " 51  KitchenQual    1460 non-null   int8   \n",
      " 52  TotRmsAbvGrd   1460 non-null   float64\n",
      " 53  Functional     1460 non-null   int8   \n",
      " 54  Fireplaces     1460 non-null   float64\n",
      " 55  GarageType     1460 non-null   int8   \n",
      " 56  GarageYrBlt    1460 non-null   float64\n",
      " 57  GarageFinish   1460 non-null   int8   \n",
      " 58  GarageCars     1460 non-null   float64\n",
      " 59  GarageArea     1460 non-null   float64\n",
      " 60  GarageQual     1460 non-null   int8   \n",
      " 61  GarageCond     1460 non-null   int8   \n",
      " 62  PavedDrive     1460 non-null   int8   \n",
      " 63  WoodDeckSF     1460 non-null   float64\n",
      " 64  OpenPorchSF    1460 non-null   float64\n",
      " 65  EnclosedPorch  1460 non-null   float64\n",
      " 66  3SsnPorch      1460 non-null   float64\n",
      " 67  ScreenPorch    1460 non-null   float64\n",
      " 68  PoolArea       1460 non-null   float64\n",
      " 69  MiscVal        1460 non-null   float64\n",
      " 70  MoSold         1460 non-null   float64\n",
      " 71  YrSold         1460 non-null   float64\n",
      " 72  SaleType       1460 non-null   int8   \n",
      " 73  SaleCondition  1460 non-null   int8   \n",
      " 74  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(36), int64(1), int8(38)\n",
      "memory usage: 476.3 KB\n"
     ]
    }
   ],
   "source": [
    "train_edited.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "sctXpXpVAyHpq6e2u72Jit",
     "type": "MD"
    }
   },
   "source": [
    "### Разделим данные\n",
    "\n",
    "Поскольку мы не знаем метку (Цена) тестовых данных, для оценки модели, чтобы получить лучшую модель перед прогнозированием тестовых данных, разделим данные в файле train.scv на обучающие и проверочные данные, соотношение составляет 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "t8LurcYSC79LJFUQFBR6IP",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "X = train_edited.drop('SalePrice', axis=1)\n",
    "y = train_edited['SalePrice']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размерности получившихся разделений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168,), (1168, 74), (292, 74), (292,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, X_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "i93j4GwqcU1GyQ4VPlqVfO",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 74), (1459, 74))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, test_edited.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "rwifuS2QgPW48EMtsBXdFH",
     "type": "MD"
    }
   },
   "source": [
    "## Моделирование"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "ZV0KjiWMU6QB7jLp3j5yc8",
     "type": "MD"
    }
   },
   "source": [
    "### Построение и обучение модели"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "G277rUWTnvZaphr9V2bwEz",
     "type": "MD"
    }
   },
   "source": [
    "Создадим последовательную модель нейронной сети с помощью фрэймворка тренировки нейронных сетей Tensorflow. На начальном слое будет 16 нейронов, активация - линейная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "MpU8VN6DOjpBNi6I834Lpu",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_dim=X_train.shape[1], activation='linear'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "random.set_seed(40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "TuMuPzKI9mkpXMfMOnK1LA",
     "type": "MD"
    }
   },
   "source": [
    "Скомпилируем нейронную сеть, выбрав в качестве функции потерь, которую необходимо минимизировать, `mae`, а в качестве оптимизатора - `Adam` с `learning_rate=0.05`, метрика стандартная для задачи регрессии - `mae`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "Qxs8obrnFlj2CqfZz7kIHz",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.05),\n",
    "              loss='mae',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "wUdHBe7xu6vMejIXVhekbo",
     "type": "MD"
    }
   },
   "source": [
    "Обучим модель на обучающих данных `X_train` и `y_train`, задав гиперпараметры гипепараметеры:\n",
    "- `epochs=100`\n",
    "- `batch_size=32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "3vAX3eHvqUuLLDkTWRLTni",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 1s 9ms/step - loss: 177559.0625 - mae: 177559.0625 - val_loss: 167612.0312 - val_mae: 167612.0312\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 149246.6562 - mae: 149246.6562 - val_loss: 118639.8750 - val_mae: 118639.8750\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 84233.9688 - mae: 84233.9688 - val_loss: 55695.2500 - val_mae: 55695.2500\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 53573.8750 - mae: 53573.8750 - val_loss: 53891.1406 - val_mae: 53891.1406\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 52511.8711 - mae: 52511.8711 - val_loss: 53199.2773 - val_mae: 53199.2773\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 51860.6836 - mae: 51860.6836 - val_loss: 52462.3672 - val_mae: 52462.3672\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 51155.3047 - mae: 51155.3047 - val_loss: 51693.9258 - val_mae: 51693.9258\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 50411.9258 - mae: 50411.9258 - val_loss: 50866.4688 - val_mae: 50866.4688\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 49686.3047 - mae: 49686.3047 - val_loss: 50008.8906 - val_mae: 50008.8906\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 48894.0117 - mae: 48894.0117 - val_loss: 49142.8477 - val_mae: 49142.8477\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 48139.1328 - mae: 48139.1328 - val_loss: 48239.4844 - val_mae: 48239.4844\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 47290.1289 - mae: 47290.1289 - val_loss: 47323.0898 - val_mae: 47323.0898\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 46471.1797 - mae: 46471.1797 - val_loss: 46522.6250 - val_mae: 46522.6250\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 45472.4531 - mae: 45472.4531 - val_loss: 45302.7695 - val_mae: 45302.7695\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 44534.6172 - mae: 44534.6172 - val_loss: 44257.4023 - val_mae: 44257.4023\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 43627.5625 - mae: 43627.5625 - val_loss: 43288.9570 - val_mae: 43288.9570\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 42583.7344 - mae: 42583.7344 - val_loss: 42187.7031 - val_mae: 42187.7031\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 41605.6602 - mae: 41605.6602 - val_loss: 41073.6133 - val_mae: 41073.6133\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 40503.7891 - mae: 40503.7891 - val_loss: 40056.5078 - val_mae: 40056.5078\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 39475.1133 - mae: 39475.1133 - val_loss: 38925.0430 - val_mae: 38925.0430\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 38491.6875 - mae: 38491.6875 - val_loss: 38068.3477 - val_mae: 38068.3477\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 37432.6523 - mae: 37432.6523 - val_loss: 36868.2109 - val_mae: 36868.2109\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 36416.3086 - mae: 36416.3086 - val_loss: 36036.6641 - val_mae: 36036.6641\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 35599.8984 - mae: 35599.8984 - val_loss: 34976.1172 - val_mae: 34976.1172\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 34652.8750 - mae: 34652.8750 - val_loss: 34122.1016 - val_mae: 34122.1016\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 33943.6758 - mae: 33943.6758 - val_loss: 33375.1172 - val_mae: 33375.1172\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 33244.2578 - mae: 33244.2578 - val_loss: 32738.2012 - val_mae: 32738.2012\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 32641.8809 - mae: 32641.8809 - val_loss: 32155.0918 - val_mae: 32155.0918\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 32205.3359 - mae: 32205.3359 - val_loss: 31746.2090 - val_mae: 31746.2090\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 31570.6582 - mae: 31570.6582 - val_loss: 31155.4512 - val_mae: 31155.4512\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 30935.4043 - mae: 30935.4043 - val_loss: 30880.2402 - val_mae: 30880.2402\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 30550.1582 - mae: 30550.1582 - val_loss: 30596.6602 - val_mae: 30596.6602\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 30016.7734 - mae: 30016.7734 - val_loss: 30276.2461 - val_mae: 30276.2461\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 29775.8125 - mae: 29775.8125 - val_loss: 29749.0586 - val_mae: 29749.0586\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 29443.0352 - mae: 29443.0352 - val_loss: 29493.4727 - val_mae: 29493.4727\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 28961.0723 - mae: 28961.0723 - val_loss: 29485.1230 - val_mae: 29485.1230\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 28732.6543 - mae: 28732.6543 - val_loss: 29528.4141 - val_mae: 29528.4141\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 28648.0430 - mae: 28648.0430 - val_loss: 28735.5273 - val_mae: 28735.5273\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 28148.5547 - mae: 28148.5547 - val_loss: 28548.8770 - val_mae: 28548.8770\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 27959.4238 - mae: 27959.4238 - val_loss: 28266.7852 - val_mae: 28266.7852\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 27740.5488 - mae: 27740.5488 - val_loss: 28109.4062 - val_mae: 28109.4062\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 27449.5137 - mae: 27449.5137 - val_loss: 27789.6992 - val_mae: 27789.6992\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 27147.2637 - mae: 27147.2637 - val_loss: 27890.9102 - val_mae: 27890.9102\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 26978.1719 - mae: 26978.1719 - val_loss: 27639.4805 - val_mae: 27639.4805\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 26737.0840 - mae: 26737.0840 - val_loss: 27120.1113 - val_mae: 27120.1113\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 26689.0938 - mae: 26689.0938 - val_loss: 27524.5566 - val_mae: 27524.5566\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 26210.0273 - mae: 26210.0273 - val_loss: 26764.7090 - val_mae: 26764.7090\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 26051.0527 - mae: 26051.0527 - val_loss: 26485.8652 - val_mae: 26485.8652\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 25748.0430 - mae: 25748.0430 - val_loss: 26401.7070 - val_mae: 26401.7070\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 25584.9824 - mae: 25584.9824 - val_loss: 26317.4590 - val_mae: 26317.4590\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 25467.7676 - mae: 25467.7676 - val_loss: 26634.8477 - val_mae: 26634.8477\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 25086.4297 - mae: 25086.4297 - val_loss: 25755.8789 - val_mae: 25755.8789\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 25050.5723 - mae: 25050.5723 - val_loss: 25506.9590 - val_mae: 25506.9590\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 24892.7598 - mae: 24892.7598 - val_loss: 25937.4863 - val_mae: 25937.4863\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 24632.2012 - mae: 24632.2012 - val_loss: 25178.8418 - val_mae: 25178.8418\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 24553.3047 - mae: 24553.3047 - val_loss: 25177.6172 - val_mae: 25177.6172\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 24225.1230 - mae: 24225.1230 - val_loss: 24874.7422 - val_mae: 24874.7422\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 24124.6523 - mae: 24124.6523 - val_loss: 25193.5332 - val_mae: 25193.5332\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23932.8730 - mae: 23932.8730 - val_loss: 25113.4863 - val_mae: 25113.4863\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23789.5332 - mae: 23789.5332 - val_loss: 24346.9648 - val_mae: 24346.9648\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23545.9375 - mae: 23545.9375 - val_loss: 24259.2715 - val_mae: 24259.2715\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23440.2129 - mae: 23440.2129 - val_loss: 24007.9902 - val_mae: 24007.9902\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23314.7246 - mae: 23314.7246 - val_loss: 24193.5449 - val_mae: 24193.5449\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23113.3262 - mae: 23113.3262 - val_loss: 23884.7793 - val_mae: 23884.7793\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23285.3516 - mae: 23285.3516 - val_loss: 23629.7500 - val_mae: 23629.7500\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22944.8086 - mae: 22944.8086 - val_loss: 23483.4961 - val_mae: 23483.4961\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22727.6289 - mae: 22727.6289 - val_loss: 23350.9844 - val_mae: 23350.9844\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22771.2148 - mae: 22771.2148 - val_loss: 24498.4375 - val_mae: 24498.4375\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22640.8281 - mae: 22640.8281 - val_loss: 23197.4141 - val_mae: 23197.4141\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22373.1504 - mae: 22373.1504 - val_loss: 23561.0215 - val_mae: 23561.0215\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22378.5195 - mae: 22378.5195 - val_loss: 23040.2559 - val_mae: 23040.2559\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22816.9766 - mae: 22816.9766 - val_loss: 24038.6914 - val_mae: 24038.6914\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22162.7969 - mae: 22162.7969 - val_loss: 22686.1543 - val_mae: 22686.1543\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22005.3730 - mae: 22005.3730 - val_loss: 22496.8965 - val_mae: 22496.8965\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21959.2383 - mae: 21959.2383 - val_loss: 23036.6055 - val_mae: 23036.6055\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21879.0352 - mae: 21879.0352 - val_loss: 22636.5371 - val_mae: 22636.5371\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21671.8105 - mae: 21671.8105 - val_loss: 22173.0273 - val_mae: 22173.0273\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21714.2363 - mae: 21714.2363 - val_loss: 22912.5410 - val_mae: 22912.5410\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21559.1152 - mae: 21559.1152 - val_loss: 22561.3496 - val_mae: 22561.3496\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21483.0723 - mae: 21483.0723 - val_loss: 21899.3535 - val_mae: 21899.3535\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21486.5410 - mae: 21486.5410 - val_loss: 21983.2285 - val_mae: 21983.2285\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21333.3203 - mae: 21333.3203 - val_loss: 21840.1641 - val_mae: 21840.1641\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21344.0918 - mae: 21344.0918 - val_loss: 22028.5898 - val_mae: 22028.5898\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 21232.4492 - mae: 21232.4492 - val_loss: 22483.1621 - val_mae: 22483.1621\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21126.0996 - mae: 21126.0996 - val_loss: 21627.7344 - val_mae: 21627.7344\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21074.4668 - mae: 21074.4668 - val_loss: 21725.8262 - val_mae: 21725.8262\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20979.2539 - mae: 20979.2539 - val_loss: 21517.0332 - val_mae: 21517.0332\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20949.2441 - mae: 20949.2441 - val_loss: 21644.8984 - val_mae: 21644.8984\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20914.1035 - mae: 20914.1035 - val_loss: 21606.5566 - val_mae: 21606.5566\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20821.1504 - mae: 20821.1504 - val_loss: 21674.8691 - val_mae: 21674.8691\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20794.0215 - mae: 20794.0215 - val_loss: 22062.6211 - val_mae: 22062.6211\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20780.7461 - mae: 20780.7461 - val_loss: 21139.8984 - val_mae: 21139.8984\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20839.9531 - mae: 20839.9531 - val_loss: 21145.5078 - val_mae: 21145.5078\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20619.2090 - mae: 20619.2090 - val_loss: 21271.8398 - val_mae: 21271.8398\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20516.4062 - mae: 20516.4062 - val_loss: 21060.3770 - val_mae: 21060.3770\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20600.5898 - mae: 20600.5898 - val_loss: 21252.1660 - val_mae: 21252.1660\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20495.2324 - mae: 20495.2324 - val_loss: 20945.1855 - val_mae: 20945.1855\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20468.3164 - mae: 20468.3164 - val_loss: 21128.1406 - val_mae: 21128.1406\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20351.7871 - mae: 20351.7871 - val_loss: 21420.7559 - val_mae: 21420.7559\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20602.9688 - mae: 20602.9688 - val_loss: 21245.6816 - val_mae: 21245.6816\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "LZFQS0AKCW5TXjLQTrI0OR",
     "type": "MD"
    }
   },
   "source": [
    "**Оценка полученных результатов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "wZBd4zSZSgFw6r0HmnY5NE",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [177559.0625, 149246.65625, 84233.96875, 53573.875, 52511.87109375, 51860.68359375, 51155.3046875, 50411.92578125, 49686.3046875, 48894.01171875, 48139.1328125, 47290.12890625, 46471.1796875, 45472.453125, 44534.6171875, 43627.5625, 42583.734375, 41605.66015625, 40503.7890625, 39475.11328125, 38491.6875, 37432.65234375, 36416.30859375, 35599.8984375, 34652.875, 33943.67578125, 33244.2578125, 32641.880859375, 32205.3359375, 31570.658203125, 30935.404296875, 30550.158203125, 30016.7734375, 29775.8125, 29443.03515625, 28961.072265625, 28732.654296875, 28648.04296875, 28148.5546875, 27959.423828125, 27740.548828125, 27449.513671875, 27147.263671875, 26978.171875, 26737.083984375, 26689.09375, 26210.02734375, 26051.052734375, 25748.04296875, 25584.982421875, 25467.767578125, 25086.4296875, 25050.572265625, 24892.759765625, 24632.201171875, 24553.3046875, 24225.123046875, 24124.65234375, 23932.873046875, 23789.533203125, 23545.9375, 23440.212890625, 23314.724609375, 23113.326171875, 23285.3515625, 22944.80859375, 22727.62890625, 22771.21484375, 22640.828125, 22373.150390625, 22378.51953125, 22816.9765625, 22162.796875, 22005.373046875, 21959.23828125, 21879.03515625, 21671.810546875, 21714.236328125, 21559.115234375, 21483.072265625, 21486.541015625, 21333.3203125, 21344.091796875, 21232.44921875, 21126.099609375, 21074.466796875, 20979.25390625, 20949.244140625, 20914.103515625, 20821.150390625, 20794.021484375, 20780.74609375, 20839.953125, 20619.208984375, 20516.40625, 20600.58984375, 20495.232421875, 20468.31640625, 20351.787109375, 20602.96875], 'mae': [177559.0625, 149246.65625, 84233.96875, 53573.875, 52511.87109375, 51860.68359375, 51155.3046875, 50411.92578125, 49686.3046875, 48894.01171875, 48139.1328125, 47290.12890625, 46471.1796875, 45472.453125, 44534.6171875, 43627.5625, 42583.734375, 41605.66015625, 40503.7890625, 39475.11328125, 38491.6875, 37432.65234375, 36416.30859375, 35599.8984375, 34652.875, 33943.67578125, 33244.2578125, 32641.880859375, 32205.3359375, 31570.658203125, 30935.404296875, 30550.158203125, 30016.7734375, 29775.8125, 29443.03515625, 28961.072265625, 28732.654296875, 28648.04296875, 28148.5546875, 27959.423828125, 27740.548828125, 27449.513671875, 27147.263671875, 26978.171875, 26737.083984375, 26689.09375, 26210.02734375, 26051.052734375, 25748.04296875, 25584.982421875, 25467.767578125, 25086.4296875, 25050.572265625, 24892.759765625, 24632.201171875, 24553.3046875, 24225.123046875, 24124.65234375, 23932.873046875, 23789.533203125, 23545.9375, 23440.212890625, 23314.724609375, 23113.326171875, 23285.3515625, 22944.80859375, 22727.62890625, 22771.21484375, 22640.828125, 22373.150390625, 22378.51953125, 22816.9765625, 22162.796875, 22005.373046875, 21959.23828125, 21879.03515625, 21671.810546875, 21714.236328125, 21559.115234375, 21483.072265625, 21486.541015625, 21333.3203125, 21344.091796875, 21232.44921875, 21126.099609375, 21074.466796875, 20979.25390625, 20949.244140625, 20914.103515625, 20821.150390625, 20794.021484375, 20780.74609375, 20839.953125, 20619.208984375, 20516.40625, 20600.58984375, 20495.232421875, 20468.31640625, 20351.787109375, 20602.96875], 'val_loss': [167612.03125, 118639.875, 55695.25, 53891.140625, 53199.27734375, 52462.3671875, 51693.92578125, 50866.46875, 50008.890625, 49142.84765625, 48239.484375, 47323.08984375, 46522.625, 45302.76953125, 44257.40234375, 43288.95703125, 42187.703125, 41073.61328125, 40056.5078125, 38925.04296875, 38068.34765625, 36868.2109375, 36036.6640625, 34976.1171875, 34122.1015625, 33375.1171875, 32738.201171875, 32155.091796875, 31746.208984375, 31155.451171875, 30880.240234375, 30596.66015625, 30276.24609375, 29749.05859375, 29493.47265625, 29485.123046875, 29528.4140625, 28735.52734375, 28548.876953125, 28266.78515625, 28109.40625, 27789.69921875, 27890.91015625, 27639.48046875, 27120.111328125, 27524.556640625, 26764.708984375, 26485.865234375, 26401.70703125, 26317.458984375, 26634.84765625, 25755.87890625, 25506.958984375, 25937.486328125, 25178.841796875, 25177.6171875, 24874.7421875, 25193.533203125, 25113.486328125, 24346.96484375, 24259.271484375, 24007.990234375, 24193.544921875, 23884.779296875, 23629.75, 23483.49609375, 23350.984375, 24498.4375, 23197.4140625, 23561.021484375, 23040.255859375, 24038.69140625, 22686.154296875, 22496.896484375, 23036.60546875, 22636.537109375, 22173.02734375, 22912.541015625, 22561.349609375, 21899.353515625, 21983.228515625, 21840.1640625, 22028.58984375, 22483.162109375, 21627.734375, 21725.826171875, 21517.033203125, 21644.8984375, 21606.556640625, 21674.869140625, 22062.62109375, 21139.8984375, 21145.5078125, 21271.83984375, 21060.376953125, 21252.166015625, 20945.185546875, 21128.140625, 21420.755859375, 21245.681640625], 'val_mae': [167612.03125, 118639.875, 55695.25, 53891.140625, 53199.27734375, 52462.3671875, 51693.92578125, 50866.46875, 50008.890625, 49142.84765625, 48239.484375, 47323.08984375, 46522.625, 45302.76953125, 44257.40234375, 43288.95703125, 42187.703125, 41073.61328125, 40056.5078125, 38925.04296875, 38068.34765625, 36868.2109375, 36036.6640625, 34976.1171875, 34122.1015625, 33375.1171875, 32738.201171875, 32155.091796875, 31746.208984375, 31155.451171875, 30880.240234375, 30596.66015625, 30276.24609375, 29749.05859375, 29493.47265625, 29485.123046875, 29528.4140625, 28735.52734375, 28548.876953125, 28266.78515625, 28109.40625, 27789.69921875, 27890.91015625, 27639.48046875, 27120.111328125, 27524.556640625, 26764.708984375, 26485.865234375, 26401.70703125, 26317.458984375, 26634.84765625, 25755.87890625, 25506.958984375, 25937.486328125, 25178.841796875, 25177.6171875, 24874.7421875, 25193.533203125, 25113.486328125, 24346.96484375, 24259.271484375, 24007.990234375, 24193.544921875, 23884.779296875, 23629.75, 23483.49609375, 23350.984375, 24498.4375, 23197.4140625, 23561.021484375, 23040.255859375, 24038.69140625, 22686.154296875, 22496.896484375, 23036.60546875, 22636.537109375, 22173.02734375, 22912.541015625, 22561.349609375, 21899.353515625, 21983.228515625, 21840.1640625, 22028.58984375, 22483.162109375, 21627.734375, 21725.826171875, 21517.033203125, 21644.8984375, 21606.556640625, 21674.869140625, 22062.62109375, 21139.8984375, 21145.5078125, 21271.83984375, 21060.376953125, 21252.166015625, 20945.185546875, 21128.140625, 21420.755859375, 21245.681640625]}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAGwCAYAAABrUCsdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4q0lEQVR4nO3deXgUZbo28Lv3LUlnIwnNGgTCEkAMDOsIyqoE3EZ0AhFGBRUREXDBGXcFF0SPcHA7MzAqEmcG8QNxMKgIImELRAk7GEgICYGk09l6r/f7o0NpE8AAnXTo3L/r6ouk6unupyue6fu89dZbCiGEABERERFdMWWwGyAiIiIKFQxWRERERAHCYEVEREQUIAxWRERERAHCYEVEREQUIAxWRERERAHCYEVEREQUIOpgN9DcSJKEkydPIjw8HAqFItjtEBERUT0IIVBZWQmLxQKl8sLjUgxWjezkyZNo06ZNsNsgIiKiy1BQUIDWrVtfcD+DVSMLDw8H4PvDREREBLkbIiIiqo+Kigq0adNG/h6/EAarRnb29F9ERASDFRER0VXm96bxcPI6ERERUYAwWBEREREFCIMVERERUYBwjhUREVED83q9cLvdwW6DLkKj0UClUl3x6zBYERERNRAhBIqLi1FeXh7sVqgeIiMjkZCQcEXrTAY1WG3atAlvvPEGsrOzUVRUhFWrVuHWW2+V91dVVeGpp57CF198gdLSUrRv3x4zZszAQw89JNc4nU7MmTMHK1asgN1ux7Bhw7BkyRK/NSasVitmzJiB1atXAwDGjRuHRYsWITIyUq7Jz8/Hww8/jO+++w4GgwFpaWlYsGABtFqtXLNnzx5Mnz4d27dvR3R0NB544AE888wzXOiTiIjO62yoiouLg9Fo5PdFEyWEQE1NDUpKSgAALVu2vOzXCmqwqq6uRq9evfCXv/wFd9xxR539jz32GDZs2IBPPvkE7du3R2ZmJqZNmwaLxYJbbrkFADBz5kysWbMGGRkZiImJwezZs5Gamors7Gx5SC8tLQ0nTpzAunXrAABTp05Feno61qxZA8A3RDtmzBi0aNECmzdvRmlpKSZNmgQhBBYtWgTAt37FiBEjcMMNN2DHjh04dOgQJk+eDJPJhNmzZzfG4SIioquI1+uVQ1VMTEyw26HfYTAYAAAlJSWIi4u7/NOCookAIFatWuW3rXv37uLFF1/023bdddeJv/3tb0IIIcrLy4VGoxEZGRny/sLCQqFUKsW6deuEEELs27dPABBbt26Va7KysgQAceDAASGEEF999ZVQKpWisLBQrlmxYoXQ6XTCZrMJIYRYsmSJMJvNwuFwyDXz588XFotFSJJU789ps9kEAPl1iYgoNNntdrFv3z5RU1MT7FaonmpqasS+ffuE3W6vs6++399N+qrAwYMHY/Xq1SgsLIQQAhs2bMChQ4cwatQoAEB2djbcbjdGjhwpP8disSA5ORlbtmwBAGRlZcFsNqNfv35yTf/+/WE2m/1qkpOTYbFY5JpRo0bB6XQiOztbrhkyZAh0Op1fzcmTJ3Hs2LELfgan04mKigq/BxERNR88/Xf1CMTfqkkHq3feeQfdunVD69atodVqMXr0aCxZsgSDBw8G4Dt3rdVqERUV5fe8+Ph4FBcXyzVxcXF1XjsuLs6vJj4+3m9/VFQUtFrtRWvO/n625nzmz58Ps9ksP3ifQCIiotDV5IPV1q1bsXr1amRnZ+PNN9/EtGnT8M0331z0eUIIv9R5vgQaiBohxAWfe9bcuXNhs9nkR0FBwUV7JyIioqtXk11uwW634+mnn8aqVaswZswYAEDPnj2Rk5ODBQsWYPjw4UhISIDL5YLVavUbtSopKcHAgQMBAAkJCTh16lSd1z99+rQ84pSQkIBt27b57bdarXC73X41545Mnb164NyRrN/S6XR+pw+JiIiauqFDh+Laa6/F22+/HexWrjpNdsTK7XbD7XZDqfRvUaVSQZIkAEBKSgo0Gg3Wr18v7y8qKkJubq4crAYMGACbzYbt27fLNdu2bYPNZvOryc3NRVFRkVyTmZkJnU6HlJQUuWbTpk1wuVx+NRaLBe3btw/sh79EQpJQVlKI4wd2wevxBLUXIiKi5iyowaqqqgo5OTnIyckBAOTl5SEnJwf5+fmIiIjAkCFD8Pjjj+P7779HXl4eli1bho8++gi33XYbAMBsNuO+++7D7Nmz8e2332L37t2YOHEievTogeHDhwMAunbtitGjR2PKlCnYunUrtm7diilTpiA1NRVJSUkAgJEjR6Jbt25IT0/H7t278e2332LOnDmYMmUKIiIiAPiWbNDpdJg8eTJyc3OxatUqzJs3D7NmzQr6xESv14PI/+2Odhk3oLz0wvO9iIiIqIE1wNWK9bZhwwYBoM5j0qRJQgghioqKxOTJk4XFYhF6vV4kJSWJN9980295A7vdLqZPny6io6OFwWAQqampIj8/3+99SktLxYQJE0R4eLgIDw8XEyZMEFar1a/m+PHjYsyYMcJgMIjo6Ggxffp0v6UVhBDi559/Fn/84x+FTqcTCQkJ4vnnn7+kpRaEaLjlFsqfaynEcxHi2L6dAX1dIiK6PGeXW/jtpfuSJIlqpzsoj0v5vhoyZIh49NFHhRBClJWVifT0dBEZGSkMBoMYPXq0OHTokFx77NgxkZqaKiIjI4XRaBTdunUTa9eulZ+blpYmYmNjhV6vFx07dhT/+Mc/AnOAG8D5/mZn1ff7O6hzrIYOHSpPAD+fhIQELF269KKvodfrsWjRInkhz/OJjo7GJ598ctHXadu2Lb788suL1vTo0QObNm26aE2wVCoiYBbVqLadDnYrRER0AXa3F92e/Too773vxVEwai/9a3/y5Mk4fPgwVq9ejYiICDz55JO4+eabsW/fPmg0Gjz88MNwuVzYtGkTTCYT9u3bh7CwMADAM888g3379uG///0vYmNjceTIEdjt9kB/tCalyU5ep0tTrYoAPEVwVpwJditERBQizgaqH3/8UZ6XvHz5crRp0wZffPEF7rzzTuTn5+OOO+5Ajx49AAAdOnSQn5+fn4/evXujT58+ABD0OcmNgcEqRDg0kYAHcFcyWBERNVUGjQr7XhwVtPe+VPv374darfZbZDsmJgZJSUnYv38/AMj38M3MzMTw4cNxxx13oGfPngCAhx56CHfccQd27dqFkSNH4tZbb5UDWqhqslcF0qVxaSMBAN7q0uA2QkREF6RQKGDUqoPyuJwLrS40XUf8Zp3H+++/H7/88gvS09OxZ88e9OnTR56ec9NNN+H48eOYOXMmTp48iWHDhmHOnDmXfwCvAgxWIcKr963jpahhsCIiosDo1q0bPB6P31qPpaWlOHToELp27Spva9OmDR588EF8/vnnmD17Nj788EN5X4sWLTB58mR88sknePvtt/HBBx806mdobDwVGCKEwReslA5rkDshIqJQ0alTJ9xyyy2YMmUK3n//fYSHh+Opp55Cq1atcMsttwAAZs6ciZtuugmdO3eG1WrFd999J4euZ599FikpKejevTucTie+/PJLv0AWijhiFSKUplgAgMZVHtxGiIgopCxduhQpKSlITU3FgAEDIITAV199BY1GAwDwer14+OGH5XUjk5KSsGTJEgCAVqvF3Llz0bNnT1x//fVQqVTIyMgI5sdpcApxsfUOKOAqKipgNpths9nkxUcDYdd/l+K6bTOxX9MNXf+aFbDXJSKiy+NwOJCXl4fExETo9fpgt0P1cLG/WX2/vzliFSK0Eb4RK6O3IsidEBERNV8MViHCaI4DAIRLDFZERETBwmAVIsKj4wEAEaIKktcb5G6IiIiaJwarEBER7RuxUiskVNrKgtwNERFR88RgFSJ0eiNqhA4AUFl2KsjdEBERNU8MViGkQuG7SqG6vCTInRARETVPDFYhpErlC1YO3oiZiIgoKBisQohdbQYAuCpOB7kTIiKi5onBKoTwRsxERETBxWAVQjy6SACAqOFVgURERMHAYBVCJEMMAN6ImYiIKFgYrEKAJEn4/vpekN7/CmdcKmicHLEiIqLLN3ToUDzyyCOYOXMmoqKiEB8fjw8++ADV1dX4y1/+gvDwcFxzzTX473//C8B3I+b77rsPiYmJMBgMSEpKwv/8z//Ued2lS5eia9eu0Ov16NKli3yz5lCiDnYDdOWUSiUirS7o3EC1VwWdyxbsloiI6HyEANw1wXlvjRFQKOpd/s9//hNPPPEEtm/fjs8++wwPPfQQvvjiC9x22214+umn8dZbbyE9PR35+fnQaDRo3bo1/vWvfyE2NhZbtmzB1KlT0bJlS4wfPx4A8OGHH+K5557D4sWL0bt3b+zevRtTpkyByWTCpEmTGupTNzqFEEIEu4nmpL53x75U21K6IaJaQJlaBk1EAjo8+1PAXpuIiC6dw+FAXl4eEhMTodfrfRtd1cA8S3AaevokoDXVq3To0KHwer344YcfAPhGpMxmM26//XZ89NFHAIDi4mK0bNkSWVlZ6N+/f53XePjhh3Hq1Cn85z//AQC0bdsWr732Gv785z/LNS+//DK++uorbNmy5Uo/XUCc929Wq77f3xyxChFurRKo9sIpKRHFGzETEdEV6tmzp/yzSqVCTEwMevToIW+Lj/fdo7akxLco9XvvvYf/+7//w/Hjx2G32+FyuXDttdcCAE6fPo2CggLcd999mDJlivwaHo8HZrO5ET5N42GwChEerQqAF06PAmZRCSFJUCg5hY6IqEnRGH0jR8F670sp12j8flcoFH7bFLWnFSVJwr/+9S889thjePPNNzFgwACEh4fjjTfewLZt2+QawHc6sF+/fn6vq1KpLvmjNGUMViHCo1MDcMEtqaBTuFFTUwljWGj9fwFERFc9haLep+OuJj/88AMGDhyIadOmyduOHj0q/xwfH49WrVrhl19+wYQJE4LRYqNhsAoRXp3vT+lw+0apKspKGKyIiKhRdOzYER999BG+/vprJCYm4uOPP8aOHTuQmJgo1zz//POYMWMGIiIicNNNN8HpdGLnzp2wWq2YNWtWELsPLJ4rChFenRYAYPfqAABV1lPBbIeIiJqRBx98ELfffjvuuusu9OvXD6WlpX6jVwBw//334//+7/+wbNky9OjRA0OGDMGyZcv8wlco4FWBjayhrgpcmz4MHXacxIGBStzW9gT23LgMPa6/LWCvT0REl+ZiV5hR0xSIqwI5YhUihN43UuXx+CYBOivPBLMdIiKiZonBKlQYfMlaSL65Vt4q3oiZiIiosTFYhQjF2SFLb+3lr9UMVkRERI2NwSpEKI0G378eX7BS2nm/QCIiosbGYBUilAbfwm9Kr+93lbM8eM0QERE1U0ENVps2bcLYsWNhsVigUCjwxRdf1KnZv38/xo0bB7PZjPDwcPTv3x/5+fnyfqfTiUceeQSxsbEwmUwYN24cTpw44fcaVqsV6enpMJvNMJvNSE9PR3l5uV9Nfn4+xo4dC5PJhNjYWMyYMQMul8uvZs+ePRgyZAgMBgNatWqFF198EU3lokq10bfgnMrt60frKg9iN0RERM1TUINVdXU1evXqhcWLF593/9GjRzF48GB06dIF33//PX766Sc888wzfpdAzpw5E6tWrUJGRgY2b96MqqoqpKamwuv1yjVpaWnIycnBunXrsG7dOuTk5CA9PV3e7/V6MWbMGFRXV2Pz5s3IyMjAypUrMXv2bLmmoqICI0aMgMViwY4dO7Bo0SIsWLAACxcubIAjc+nUpjDfvx5fsDK4y4PYDRERUTMlmggAYtWqVX7b7rrrLjFx4sQLPqe8vFxoNBqRkZEhbyssLBRKpVKsW7dOCCHEvn37BACxdetWuSYrK0sAEAcOHBBCCPHVV18JpVIpCgsL5ZoVK1YInU4nbDabEEKIJUuWCLPZLBwOh1wzf/58YbFYhCRJF+zR4XAIm80mPwoKCgQA+XUD5ceMt8W+pC7i6xt7CfFchCh8vmNAX5+IiC6N3W4X+/btE3a7PditUD1d7G9ms9nq9f3dZOdYSZKEtWvXonPnzhg1ahTi4uLQr18/v9OF2dnZcLvdGDlypLzNYrEgOTkZW7ZsAQBkZWXBbDb73fSxf//+MJvNfjXJycmwWCxyzahRo+B0OpGdnS3XDBkyBDqdzq/m5MmTOHbs2AU/x/z58+VTkGazGW3atLmi43IhGlO471+370aXEVJlg7wPERERXViTDVYlJSWoqqrCq6++itGjRyMzMxO33XYbbr/9dmzcuBEAUFxcDK1Wi6ioKL/nxsfHo7i4WK6Ji4ur8/pxcXF+NfHx8X77o6KioNVqL1pz9vezNeczd+5c2Gw2+VFQUHAph6HedGG+VWA1Ll+wClPY4XI6GuS9iIiI6PyabLCSJF9AuOWWW/DYY4/h2muvxVNPPYXU1FS89957F32uEAIKhUL+/bc/B7JG1E5cP99zz9LpdIiIiPB7NASd6ddg5RW+fipKeb9AIiJqfO3bt8fbb79dr9oLXbx2tWqywSo2NhZqtRrdunXz2961a1f5qsCEhAS4XC5YrVa/mpKSEnk0KSEhAadO1Q0Yp0+f9qs5d9TJarXC7XZftKakpAQA6oxkBYM+LBIAoHMLVCh8E9kry0uC2BEREVHz02SDlVarRd++fXHw4EG/7YcOHUK7du0AACkpKdBoNFi/fr28v6ioCLm5uRg4cCAAYMCAAbDZbNi+fbtcs23bNthsNr+a3NxcFBUVyTWZmZnQ6XRISUmRazZt2uS3BENmZiYsFgvat28f2A9/GQzhkQAAnRuwwTffqqb8dBA7IiIian6CGqyqqqqQk5ODnJwcAEBeXh5ycnLkEanHH38cn332GT788EMcOXIEixcvxpo1azBt2jQAgNlsxn333YfZs2fj22+/xe7duzFx4kT06NEDw4cPB+Ab4Ro9ejSmTJmCrVu3YuvWrZgyZQpSU1ORlJQEABg5ciS6deuG9PR07N69G99++y3mzJmDKVOmyKfu0tLSoNPpMHnyZOTm5mLVqlWYN28eZs2addFTgY3FGB4j/1yu8PXsqmSwIiJqSoQQqHHXBOUh6rnu4vvvv49WrVrJU3LOGjduHCZNmoSjR4/illtuQXx8PMLCwtC3b1988803ATtGe/bswY033giDwYCYmBhMnToVVVVV8v7vv/8ef/jDH2AymRAZGYlBgwbh+PHjAICffvoJN9xwA8LDwxEREYGUlBTs3LkzYL3Vh7pR3+0cO3fuxA033CD/PmvWLADApEmTsGzZMtx222147733MH/+fMyYMQNJSUlYuXIlBg8eLD/nrbfeglqtxvjx42G32zFs2DAsW7YMKpVKrlm+fDlmzJghXz04btw4v7WzVCoV1q5di2nTpmHQoEEwGAxIS0vDggUL5Bqz2Yz169fj4YcfRp8+fRAVFYVZs2bJPQebIcws/1yhMAECcFWcCWJHRER0LrvHjn6f9vv9wgawLW0bjBrj79bdeeedmDFjBjZs2IBhw4YB8E2P+frrr7FmzRpUVVXh5ptvxssvvwy9Xo9//vOfGDt2LA4ePIi2bdteUY81NTUYPXo0+vfvjx07dqCkpAT3338/pk+fjmXLlsHj8eDWW2/FlClTsGLFCrhcLmzfvl0e4JgwYQJ69+6Nd999FyqVCjk5OdBoNFfU06UKarAaOnTo7yboe++9F/fee+8F9+v1eixatAiLFi26YE10dDQ++eSTi75P27Zt8eWXX160pkePHti0adNFa4JFpVLDqfGdCrQrfP+HI9XwRsxERHRpoqOjMXr0aHz66adysPr3v/+N6OhoDBs2DCqVCr169ZLrX375ZaxatQqrV6/G9OnTr+i9ly9fDrvdjo8++ggmk++OIosXL8bYsWPx2muvQaPRwGazITU1Fddccw0A35mps/Lz8/H444+jS5cuAIBOnTpdUT+XI6jBigLLqVVA5xZwKXxrbSlqeCNmIqKmxKA2YFvatqC9d31NmDABU6dOxZIlS6DT6bB8+XLcfffdUKlUqK6uxgsvvIAvv/wSJ0+ehMfjgd1u97vd3OXav38/evXqJYcqABg0aBAkScLBgwdx/fXXY/LkyRg1ahRGjBiB4cOHY/z48WjZsiUA35mv+++/Hx9//DGGDx+OO++8Uw5gjaXJTl6nS+fW+v6cHqUvWKkc1ouVExFRI1MoFDBqjEF5XMp84LFjx8oLdRcUFOCHH37AxIkTAfjmP69cuRKvvPIKfvjhB+Tk5KBHjx517q97Oc5d5ujcYwcAS5cuRVZWFgYOHIjPPvsMnTt3xtatWwEAzz//PPbu3YsxY8bgu+++Q7du3bBq1aor7utSMFiFEI/WN69MKLQAAA1vxExERJfBYDDg9ttvx/Lly7FixQp07txZvkr+hx9+wOTJk3HbbbehR48eSEhIuOgdSC5Ft27dkJOTg+rqannbjz/+CKVSic6dO8vbevfujblz52LLli1ITk7Gp59+Ku/r3LkzHnvsMWRmZuL222/H0qVLA9JbfTFYhRCP7uyZXV/A0rttwWuGiIiuahMmTMDatWvxj3/8Qx6tAoCOHTvi888/R05ODn766SekpaXVuYLwSt5Tr9dj0qRJyM3NxYYNG/DII48gPT0d8fHxyMvLw9y5c5GVlYXjx48jMzMThw4dQteuXWG32zF9+nR8//33OH78OH788Ufs2LHDbw5WY+AcqxDirQ1WitpbQJq8DFZERHR5brzxRkRHR+PgwYNIS0uTt7/11lu49957MXDgQMTGxuLJJ59ERUVFQN7TaDTi66+/xqOPPoq+ffvCaDTijjvuwMKFC+X9Bw4cwD//+U+UlpaiZcuWmD59Oh544AF4PB6UlpbinnvuwalTpxAbG4vbb78dL7zwQkB6qy+FqO/CFhQQFRUVMJvNsNlsAb+9zVd3/hGJe87gUPpg3OL+F8oRhsjnCwP6HkREVD8OhwN5eXlITEyEXq8PdjtUDxf7m9X3+5unAkOI0PvmVik9viHZCFENr8cTzJaIiIiaFQarECL0vqsBlV5fsFIqBCrLuUgoEREFx/LlyxEWFnbeR/fu3YPdXoPgHKtQYqgdtnQ4UWUwIExhR6X1FCJjE4LbFxERNUvjxo1Dv37nX2m+sVdEbywMViFEUXs+WDgcqDBFIEzYUW0tCXJXRETUXIWHhyM8PDzYbTQqngoMIUpj7aq6dgeqVb6JdQ7eL5CIiKjRMFiFEKXBd49AhcMJu9p3U2ZXJYMVERFRY2GwCiFqUxgAQOFwwaWNBABI1bwRMxERUWNhsAohaqPvppUqhwseXRQAQNQwWBERETUWBqsQojH5JgiqnB4IQ7TvZ96ImYiIqNEwWIWQs8FK7fRAaYyq/Zm3tSEiosbVvn17vP3228FuIygYrEKILsx3JaDa5YVS65vIrpKcwWyJiIioWWGwCiE6ky9YaVwSFBrfmlYMVkRERI2HwSqE6MMiAQA6l5BHrNSSK4gdERHRbwkhINXUBOUhhKhXj++//z5atWoFSZL8to8bNw6TJk3C0aNHccsttyA+Ph5hYWHo27cvvvnmm8s+JgqFAu+//z5SU1NhNBrRtWtXZGVl4ciRIxg6dChMJhMGDBiAo0ePys+pTw8ulwtPPPEEWrVqBZPJhH79+uH777+/7D7riyuvhxBDeCRqAOjcgEPlu1WAmiNWRERNhrDbcfC6lKC8d9KubCiMxt+tu/POOzFjxgxs2LABw4YNAwBYrVZ8/fXXWLNmDaqqqnDzzTfj5Zdfhl6vxz//+U+MHTsWBw8eRNu2bS+rt5deegkLFy7EwoUL8eSTTyItLQ0dOnTA3Llz0bZtW9x7772YPn06/vvf/wJAvXr4y1/+gmPHjiEjIwMWiwWrVq3C6NGjsWfPHnTq1Omy+qwPjliFEGN4jPyzF77/z0QjOGJFRET1Fx0djdGjR+PTTz+Vt/373/9GdHQ0hg0bhl69euGBBx5Ajx490KlTJ7z88svo0KEDVq9efdnv+Ze//AXjx49H586d8eSTT+LYsWOYMGECRo0aha5du+LRRx/1G236vR6OHj2KFStW4N///jf++Mc/4pprrsGcOXMwePBgLF269LL7rA+OWIUQQ5hZ/tnr9QBgsCIiakoUBgOSdmUH7b3ra8KECZg6dSqWLFkCnU6H5cuX4+6774ZKpUJ1dTVeeOEFfPnllzh58iQ8Hg/sdjvy8/Mvu7eePXvKP8fHxwMAevTo4bfN4XCgoqICERERv9vDrl27IIRA586d/d7H6XQiJiYGDYnBKoSoVGo4Nb5TgZLHDYDBioioKVEoFPU6HRdsY8eOhSRJWLt2Lfr27YsffvgBCxcuBAA8/vjj+Prrr7FgwQJ07NgRBoMBf/rTn+ByXf73jUajkX9WKBQX3HZ23tfv9SBJElQqFbKzs6FSqfzeKyws7LL7rA8GqxDj1CqgcwtIHt+IlQ4MVkREdGkMBgNuv/12LF++HEeOHEHnzp2RkuKbG/bDDz9g8uTJuO222wD45jsdO3asUfv7vR569+4Nr9eLkpIS/PGPf2zU3hisQoxbqwSqvZDcvkCl5YgVERFdhgkTJmDs2LHYu3cvJk6cKG/v2LEjPv/8c4wdOxYKhQLPPPNMnSsIG9rv9dC5c2dMmDAB99xzD95880307t0bZ86cwXfffYcePXrg5ptvbrDeOHk9xHi0viFPb22w0ivcEI38HzwREV39brzxRkRHR+PgwYNIS0uTt7/11luIiorCwIEDMXbsWIwaNQrXXXddo/ZWnx6WLl2Ke+65B7Nnz0ZSUhLGjRuHbdu2oU2bNg3am0LUd2ELCoiKigqYzWbYbDZEREQE/PW/GZmCVvk1OPX0JAz9ZT4AwPHkSegNpoC/FxERXZjD4UBeXh4SExOh1+uD3Q7Vw8X+ZvX9/uaIVYjx6HyT/STnr+tXOR32YLVDRETUrDBYhRhJXxusHDWQhO8qCre9OpgtERFRM7V8+XKEhYWd99G9e/dgt9cgOHk9xAi9FgDgramBA1oY4YTLyRErIiJqfOPGjUO/fv3Ou++3yymEEgarECP0OgCAZK+BS6GBEU64HRyxIiKixhceHo7w8PBgt9GoeCow1Bh8k+2kGjtc8I1euV0csSIiCpbGXoqALl8g/lZBDVabNm3C2LFjYbFYoFAo8MUXX1yw9oEHHoBCocDbb7/tt93pdOKRRx5BbGwsTCYTxo0bhxMnTvjVWK1WpKenw2w2w2w2Iz09HeXl5X41+fn5GDt2LEwmE2JjYzFjxow6q8ju2bMHQ4YMgcFgQKtWrfDiiy/W+27hjUVRexWDcDjgUviClYenAomIGp1Wq4VSqcTJkydhs9lgt9vhcDj4aIIPu90Om82GkydPQqlUQqvVXvbfPainAqurq9GrVy/85S9/wR133HHBui+++ALbtm2DxWKps2/mzJlYs2YNMjIyEBMTg9mzZyM1NdVvGfu0tDScOHEC69atAwBMnToV6enpWLNmDQDA6/VizJgxaNGiBTZv3ozS0lJMmjQJQggsWrQIgO8yyxEjRuCGG27Ajh07cOjQIUyePBkmkwmzZ88O9KG5bEpj7b2g7A54FFpAAB5nTXCbIiJqhpRKJRITE1FUVISTJ08Gux2qB6PRiLZt20KpvPxxp6AGq5tuugk33XTTRWsKCwsxffp0fP311xgzZozfPpvNhr///e/4+OOPMXz4cADAJ598gjZt2uCbb77BqFGjsH//fqxbtw5bt26VJ9B9+OGHGDBgAA4ePIikpCRkZmZi3759KCgokMPbm2++icmTJ+OVV15BREQEli9fDofDgWXLlkGn0yE5ORmHDh3CwoULMWvWLPk+RudyOp1w/mbpg4qKiss+XvWhMvrWq1I4nHArdYAEeN0csSIiCgatVou2bdvC4/HA6/UGux26CJVKBbVafcHv8/pq0pPXJUlCeno6Hn/88fNelpmdnQ23242RI0fK2ywWC5KTk7FlyxaMGjUKWVlZMJvNflcl9O/fH2azGVu2bEFSUhKysrKQnJzsNyI2atQoOJ1OZGdn44YbbkBWVhaGDBkCnU7nVzN37lwcO3YMiYmJ5/0M8+fPxwsvvBCIw1EvvwYrl2/ECoCXpwKJiIJGoVBAo9GE7FVw5K9JT15/7bXXoFarMWPGjPPuLy4uhlarRVRUlN/2+Ph4FBcXyzVxcXF1nhsXF+dXEx8f77c/KioKWq32ojVnfz9bcz5z586FzWaTHwUFBRf7yFdMXRusVA4XPMraKwTdjgZ9TyIiIvJpsiNW2dnZ+J//+R/s2rXrkoflhBB+zznf8wNRc3bi+sX60+l0fqNcDU1j8l3WqnJ64FUxWBERETWmJjti9cMPP6CkpARt27aFWq2GWq3G8ePHMXv2bLRv3x4AkJCQAJfLBavV6vfckpISeTQpISEBp06dqvP6p0+f9qs5d9TJarXC7XZftKakpAQA6oxkBdPZYKV2eiApfacCJS63QERE1CiabLBKT0/Hzz//jJycHPlhsVjw+OOP4+uvvwYApKSkQKPRYP369fLzioqKkJubi4EDBwIABgwYAJvNhu3bt8s127Ztg81m86vJzc1FUVGRXJOZmQmdToeUlBS5ZtOmTX5LMGRmZsJischBrynQhfluDKl2eeFV1d5A0sMRKyIiosYQ1FOBVVVVOHLkiPx7Xl4ecnJyEB0djbZt2yImJsavXqPRICEhAUlJSQAAs9mM++67D7Nnz0ZMTAyio6MxZ84c9OjRQ75KsGvXrhg9ejSmTJmC999/H4BvuYXU1FT5dUaOHIlu3bohPT0db7zxBsrKyjBnzhxMmTJFvoN1WloaXnjhBUyePBlPP/00Dh8+jHnz5uHZZ5+94isIAklnioAEQOOSINWeChQe58WfRERERAER1BGrnTt3onfv3ujduzcAYNasWejduzeeffbZer/GW2+9hVtvvRXjx4/HoEGDYDQasWbNGnkNK8B3E8gePXpg5MiRGDlyJHr27ImPP/5Y3q9SqbB27Vro9XoMGjQI48ePx6233ooFCxbINWazGevXr8eJEyfQp08fTJs2DbNmzcKsWbMCcCQCRx8WCQDQuQSEunbEisstEBERNQqFaGpLh4e4iooKmM1m2Gw2eTQskE4XHsGZYWMBAGUzb8Sg4k+wNf5u9H/o/YC/FxERUXNR3+/vJjvHii6PIezXpSfcwneKUsE5VkRERI2CwSrEGMLM8s9u4fvzKr2cY0VERNQYGKxCjEqlhrN2cV+P5DvLy2BFRETUOBisQpBT6zsF6JV8vyu9PBVIRETUGBisQpBb6/uzSrXJSiW5LlZOREREAcJgFYI8Wt9SE1LtndTVEk8FEhERNQYGqxDk1vnWfRUe34gVgxUREVHjYLAKQV6db/a68HgAAGqeCiQiImoUDFYhSNLXBiu3L1hpBIMVERFRY2CwCkFCrwUAKFxuAAxWREREjYXBKgQJve/my6gdsdKBwYqIiKgxMFiFIoPv5ssKt2/ESssRKyIiokbBYBWCFPraYOX0jVhp4Q5mO0RERM0Gg1UIUhoNAACFyzdSpVF44XFz1IqIiKihMViFIJXR5PvX9etIldNRE6x2iIiImg0GqxB0NlgpHb8JVvbqYLVDRETUbDBYhSD12RErpxsu4VuF3eW0B7MlIiKiZoHBKgRpTOEAAJXTAyd8i4W6GayIiIgaHINVCDobrNROD1wK32Khbs6xIiIianAMViFIFxYBAFC7vHDBF6w8Lo5YERERNTQGqxCkM/mClcYlwa2sDVY8FUhERNTgGKxCkCE8CgCgcwm4Fb7b23icPBVIRETU0BisQpAcrNyAC76rAr08FUhERNTgGKxCkCEsSv65RvhOBXrdDFZEREQNjcEqBBnCzPLPNUIFAJBcjmC1Q0RE1GwwWIUglUoNp2/5Kjgl3w/CzWBFRETU0BisQpRTqwAAuITvTyx4KpCIiKjBMViFKLfW96d1e30BS3g4YkVERNTQGKxClFtXezWg5AtWCp4KJCIianAMViHKo/VNWvdKZzcwWBERETU0BqsQ5dX5Jq1LHt/vCq8ziN0QERE1D0ENVps2bcLYsWNhsVigUCjwxRdfyPvcbjeefPJJ9OjRAyaTCRaLBffccw9Onjzp9xpOpxOPPPIIYmNjYTKZMG7cOJw4ccKvxmq1Ij09HWazGWazGenp6SgvL/eryc/Px9ixY2EymRAbG4sZM2bA5XL51ezZswdDhgyBwWBAq1at8OKLL0IIEdBjEiiSvvZqQI+vPwVHrIiIiBpcUINVdXU1evXqhcWLF9fZV1NTg127duGZZ57Brl278Pnnn+PQoUMYN26cX93MmTOxatUqZGRkYPPmzaiqqkJqaiq8Xq9ck5aWhpycHKxbtw7r1q1DTk4O0tPT5f1erxdjxoxBdXU1Nm/ejIyMDKxcuRKzZ8+WayoqKjBixAhYLBbs2LEDixYtwoIFC7Bw4cIGODJXTuh9C4PC6wtWSo5YERERNTzRRAAQq1atumjN9u3bBQBx/PhxIYQQ5eXlQqPRiIyMDLmmsLBQKJVKsW7dOiGEEPv27RMAxNatW+WarKwsAUAcOHBACCHEV199JZRKpSgsLJRrVqxYIXQ6nbDZbEIIIZYsWSLMZrNwOBxyzfz584XFYhGSJNX7c9psNgFAft2Gsub+m8S+pC5ixQM3CvFchMh+PbVB34+IiCiU1ff7+6qaY2Wz2aBQKBAZGQkAyM7OhtvtxsiRI+Uai8WC5ORkbNmyBQCQlZUFs9mMfv36yTX9+/eH2Wz2q0lOTobFYpFrRo0aBafTiezsbLlmyJAh0Ol0fjUnT57EsWPHLtiz0+lERUWF36NRGPQAAIXHN3tdJXHEioiIqKFdNcHK4XDgqaeeQlpaGiIiIgAAxcXF0Gq1iIqK8quNj49HcXGxXBMXF1fn9eLi4vxq4uPj/fZHRUVBq9VetObs72drzmf+/Pny3C6z2Yw2bdpcyse+bAp9bbBy+06JMlgRERE1vKsiWLndbtx9992QJAlLliz53XohBBQKhfz7b38OZI2onbh+vueeNXfuXNhsNvlRUFDwu/0HgtJoBACo3L4RK7Xkulg5ERERBUCTD1Zutxvjx49HXl4e1q9fL49WAUBCQgJcLhesVqvfc0pKSuTRpISEBJw6darO654+fdqv5txRJ6vVCrfbfdGakpISAKgzkvVbOp0OERERfo/GoKoNVkqXb8RKzRErIiKiBtekg9XZUHX48GF88803iImJ8dufkpICjUaD9evXy9uKioqQm5uLgQMHAgAGDBgAm82G7du3yzXbtm2DzWbzq8nNzUVRUZFck5mZCZ1Oh5SUFLlm06ZNfkswZGZmwmKxoH379gH/7FdKqTcAAFQeX7DSCI5YERERNbSgBquqqirk5OQgJycHAJCXl4ecnBzk5+fD4/HgT3/6E3bu3Inly5fD6/WiuLgYxcXFcrgxm8247777MHv2bHz77bfYvXs3Jk6ciB49emD48OEAgK5du2L06NGYMmUKtm7diq1bt2LKlClITU1FUlISAGDkyJHo1q0b0tPTsXv3bnz77beYM2cOpkyZIo8wpaWlQafTYfLkycjNzcWqVaswb948zJo166KnAoNFbfAFK2Xt5HUGKyIiokbQCFcoXtCGDRsEgDqPSZMmiby8vPPuAyA2bNggv4bdbhfTp08X0dHRwmAwiNTUVJGfn+/3PqWlpWLChAkiPDxchIeHiwkTJgir1epXc/z4cTFmzBhhMBhEdHS0mD59ut/SCkII8fPPP4s//vGPQqfTiYSEBPH8889f0lILQjTecgubPnpN7EvqIv47srcQz0WIkufaNej7ERERhbL6fn8rhGiiS4eHqIqKCpjNZthstgadb5X170WIfGYJTrTSYcQf81ABEyKeP/n7TyQiIqI66vv93aTnWNHlUxtMAABV7alALU8FEhERNTgGqxClNYQBANRu34CkXuGGkKRgtkRERBTyGKxClMbgW25B4/41TDmd9mC1Q0RE1CwwWIUoecTK8+sUOqeDwYqIiKghMViFKJ0pHACgcQtIwrcchNteHcyWiIiIQh6DVYjS1Y5Y6TxAjdACAFw8FUhERNSgGKxClM7466Wg1UIDAHA7a4LVDhERUbPAYBWiDEaz/HNV7YgVgxUREVHDYrAKUWqdHmevB6yWfMHKw1OBREREDYrBKkQplUq4fWcAYa89FejhiBUREVGDYrAKYW6172pAp1ADALxujlgRERE1JAarEObW1AYrqTZYuRzBbIeIiCjkMViFMI/G9+d1Cd+/kosjVkRERA2JwSqEeTUqAIBH+P6V3ByxIiIiakgMViHsbLDyShyxIiIiagwMViHMq/UPVvBwxIqIiKghMViFMEnrm7QuSb5J7MLjDGY7REREIY/BKoQJjS9YCW/tBi63QERE1KAYrEKY0NWuEFo7YqXwcsSKiIioITFYhTCh9d3KRngFAEDBOVZEREQNisEqlNWOWClqTwUqOWJFRETUoBisQpnON2KlkHwjVgxWREREDeuyg9WRI0fw9ddfw273TYgWQgSsKQoMhU7n+9cjAQCUXp4KJCIiakiXHKxKS0sxfPhwdO7cGTfffDOKiooAAPfffz9mz54d8Abp8im1vmCl9PhCr0pyBbMdIiKikHfJweqxxx6DWq1Gfn4+jEajvP2uu+7CunXrAtocXRmlQe/71+sbsVJJPBVIRETUkNSX+oTMzEx8/fXXaN26td/2Tp064fjx4wFrjK6cUmfw/Vs7YqVhsCIiImpQlzxiVV1d7TdSddaZM2egq53TQ02DSu8bsVK5fZcFqnkqkIiIqEFdcrC6/vrr8dFHH8m/KxQKSJKEN954AzfccENAm6Mro9L7RqxUtetYaQSDFRERUUO65FOBb7zxBoYOHYqdO3fC5XLhiSeewN69e1FWVoYff/yxIXqky6Q2+EYWVW7fHCsGKyIiooZ1ySNW3bp1w88//4w//OEPGDFiBKqrq3H77bdj9+7duOaaaxqiR7pMar1/sNKCwYqIiKghXfKIFQAkJCTghRdeCHQvFGBqg8n3b+06VjqOWBERETWoSw5WmzZtuuj+66+//rKbocDSGsIAAOraqwK1cAezHSIiopB3yacChw4dWudxww03yI9LsWnTJowdOxYWiwUKhQJffPGF334hBJ5//nlYLBYYDAYMHToUe/fu9atxOp145JFHEBsbC5PJhHHjxuHEiRN+NVarFenp6TCbzTCbzUhPT0d5eblfTX5+PsaOHQuTyYTY2FjMmDEDLpf/CM+ePXswZMgQGAwGtGrVCi+++GKTXnFeUzvHSnN2jpXCC4+bo1ZEREQN5ZKDldVq9XuUlJRg3bp16Nu3LzIzMy/ptaqrq9GrVy8sXrz4vPtff/11LFy4EIsXL8aOHTuQkJCAESNGoLKyUq6ZOXMmVq1ahYyMDGzevBlVVVVITU2F1+uVa9LS0pCTk4N169Zh3bp1yMnJQXp6urzf6/VizJgxqK6uxubNm5GRkYGVK1f6rSRfUVGBESNGwGKxYMeOHVi0aBEWLFiAhQsXXtJnbkw6YziAX0esAMDpqAlWO0RERKFPBMjGjRvFddddd9nPByBWrVol/y5JkkhISBCvvvqqvM3hcAiz2Szee+89IYQQ5eXlQqPRiIyMDLmmsLBQKJVKsW7dOiGEEPv27RMAxNatW+WarKwsAUAcOHBACCHEV199JZRKpSgsLJRrVqxYIXQ6nbDZbEIIIZYsWSLMZrNwOBxyzfz584XFYhGSJNX7c9psNgFAft2GVHj0Z7EvqYv4uWsXIZ6LEOK5CFFWcrLB35eIiCjU1Pf7+7JvwnyuFi1a4ODBg4F6OeTl5aG4uBgjR46Ut+l0OgwZMgRbtmwBAGRnZ8PtdvvVWCwWJCcnyzVZWVkwm83o16+fXNO/f3+YzWa/muTkZFgsFrlm1KhRcDqdyM7OlmuGDBnitwjqqFGjcPLkSRw7duyCn8PpdKKiosLv0Vh0Z+dYSUCNV+Xrx1HdaO9PRETU3Fzy5PWff/7Z73chBIqKivDqq6+iV69eAWusuLgYABAfH++3PT4+Xr51TnFxMbRaLaKiourUnH1+cXEx4uLi6rx+XFycX8257xMVFQWtVutX0759+zrvc3ZfYmLieT/H/Pnzg3YFpc4YIf9cKbQwwg630x6UXoiIiJqDSw5W1157LRQKRZ1J2/3798c//vGPgDV2lkKh8PtdCFFn27nOrTlffSBqzh6Di/Uzd+5czJo1S/69oqICbdq0uWj/gaKvnWMFAJWSDvGww805VkRERA3mkoNVXl6e3+9KpRItWrSAvva+dIGSkJAAwDca1LJlS3l7SUmJPFKUkJAAl8sFq9XqN2pVUlKCgQMHyjWnTp2q8/qnT5/2e51t27b57bdarXC73X41Z0evfvs+QN1Rtd/S6XRBu4eiWqOFR+k7FVgtaQEAHhdHrIiIiBrKJc+xateund+jTZs2AQ9VAJCYmIiEhASsX79e3uZyubBx40Y5NKWkpECj0fjVFBUVITc3V64ZMGAAbDYbtm/fLtds27YNNpvNryY3NxdFRUVyTWZmJnQ6HVJSUuSaTZs2+S3BkJmZCYvFUucUYVPi0vj+ddRmaA9PBRIRETWYeo1YvfPOO/V+wRkzZtS7tqqqCkeOHJF/z8vLQ05ODqKjo9G2bVvMnDkT8+bNQ6dOndCpUyfMmzcPRqMRaWlpAACz2Yz77rsPs2fPRkxMDKKjozFnzhz06NEDw4cPBwB07doVo0ePxpQpU/D+++8DAKZOnYrU1FQkJSUBAEaOHIlu3bohPT0db7zxBsrKyjBnzhxMmTIFERG+eUppaWl44YUXMHnyZDz99NM4fPgw5s2bh2efffZ3T00Gk1ujBJwSHNLZYMVTgURERA2lXsHqrbfeqteLKRSKSwpWO3fu9FtU9OxcpEmTJmHZsmV44oknYLfbMW3aNFitVvTr1w+ZmZkID/917tBbb70FtVqN8ePHw263Y9iwYVi2bBlUKpVcs3z5csyYMUO+enDcuHF+a2epVCqsXbsW06ZNw6BBg2AwGJCWloYFCxbINWazGevXr8fDDz+MPn36ICoqCrNmzfKbP9UUedW+0OesDVZengokIiJqMApx7ix0alAVFRUwm82w2WzyaFhD2vjHnog77cYvY8IwJvwQdvZdgD5jpjT4+xIREYWS+n5/B2wdK2qaPFrfyJ1b8v2pJZcjmO0QERGFtEu+KhAATpw4gdWrVyM/P7/O/fSa8i1emiNJ4wtWUm2wEm4GKyIiooZyycHq22+/xbhx45CYmIiDBw8iOTkZx44dgxAC1113XUP0SFfAq6mdWyUHK86xIiIiaiiXfCpw7ty5mD17NnJzc6HX67Fy5UoUFBRgyJAhuPPOOxuiR7oCQucLVpLkm8QuPByxIiIiaiiXHKz279+PSZMmAQDUajXsdjvCwsLw4osv4rXXXgt4g3RlpNoRKyHVbvA4g9cMERFRiLvkYGUymeB0+r6cLRYLjh49Ku87c+ZM4DqjgBC62hVCa4OVgqcCiYiIGswlz7Hq378/fvzxR3Tr1g1jxozB7NmzsWfPHnz++efo379/Q/RIV0Lru5UNvL5/FF6OWBERETWUSw5WCxcuRFVVFQDg+eefR1VVFT777DN07Nix3guJUiPSnQ1WtTeM5hwrIiKiBnPJweqll17CxIkTIYSA0WjEkiVLGqIvChBFbbBS1I5YKTliRURE1GAueY5VaWkpxowZg9atW2P27NnIyclpgLYoUBQ63w2ylV7fJCulxGBFRETUUC45WK1evRrFxcV47rnnkJ2djZSUFHTr1g3z5s3DsWPHGqBFuhJnR6yUHt+pQBVHrIiIiBrMZd3SJjIyElOnTsX333+P48eP4y9/+Qs+/vhjdOzYMdD90RVS6Q0AAGXtHCsVR6yIiIgazBXdK9DtdmPnzp3Ytm0bjh07hvj4+ED1RQGiPBus3L5TgWrJdbFyIiIiugKXFaw2bNiAKVOmID4+HpMmTUJ4eDjWrFmDgoKCQPdHV0il982xUnnOBiuOWBERETWUS74qsHXr1igtLcWoUaPw/vvvY+zYsdDXfnlT06PSG33/ng1WgiNWREREDeWSg9Wzzz6LO++8E1FRUQ3RDwWYxnA2WPnmWGkZrIiIiBrMJQerqVOnNkQf1EDUtXOs1LVzrDQMVkRERA3miiavU9OnMYYBANS1pwJ1YLAiIiJqKAxWIU5rqA1Wbp4KJCIiamgMViFOazABADS1c6z0CjeEJAWzJSIiopDFYBXizo5YnQ1WAOB02oPVDhERUUhjsApxelMEAEDjBqTabOV0MFgRERE1BAarEHd2xEoJwOlVAADc9uogdkRERBS6GKxCnMFkln+2Sb6FXF08FUhERNQgGKxCnEZnxNmp6lXQAADczprgNURERBTCGKxCnFKphLt2GdhqicGKiIioITFYNQNujW9ulV3SAgBc9qpgtkNERBSyGKyagbPBqkb4bm/jqrIGsx0iIqKQxWDVDHg0vj+zHToAgLuqNJjtEBERhSwGq2bAq1EBAFwKX7DyVpcFsx0iIqKQxWDVDJwNVl7hm2Ml7DwVSERE1BAYrJoBr7Y2WCl8lwcqHeVB7IaIiCh0Nelg5fF48Le//Q2JiYkwGAzo0KEDXnzxRUi/uYmwEALPP/88LBYLDAYDhg4dir179/q9jtPpxCOPPILY2FiYTCaMGzcOJ06c8KuxWq1IT0+H2WyG2WxGeno6ysvL/Wry8/MxduxYmEwmxMbGYsaMGXC5XA32+QNFaGrXW4DvX5XTFrxmiIiIQliTDlavvfYa3nvvPSxevBj79+/H66+/jjfeeAOLFi2Sa15//XUsXLgQixcvxo4dO5CQkIARI0agsrJSrpk5cyZWrVqFjIwMbN68GVVVVUhNTYXX65Vr0tLSkJOTg3Xr1mHdunXIyclBenq6vN/r9WLMmDGorq7G5s2bkZGRgZUrV2L27NmNczCugKQ9G6x8I1daN4MVERFRgxBN2JgxY8S9997rt+32228XEydOFEIIIUmSSEhIEK+++qq83+FwCLPZLN577z0hhBDl5eVCo9GIjIwMuaawsFAolUqxbt06IYQQ+/btEwDE1q1b5ZqsrCwBQBw4cEAIIcRXX30llEqlKCwslGtWrFghdDqdsNlsF/wMDodD2Gw2+VFQUCAAXPQ5gfblxBvFvqQu4rPZtwrxXIQ4+FKfRntvIiKiUGCz2er1/d2kR6wGDx6Mb7/9FocOHQIA/PTTT9i8eTNuvvlmAEBeXh6Ki4sxcuRI+Tk6nQ5DhgzBli1bAADZ2dlwu91+NRaLBcnJyXJNVlYWzGYz+vXrJ9f0798fZrPZryY5ORkWi0WuGTVqFJxOJ7Kzsy/4GebPny+fXjSbzWjTps2VHpZLJjS+FdeVtX9uo7ei0XsgIiJqDtS/XxI8Tz75JGw2G7p06QKVSgWv14tXXnkFf/7znwEAxcXFAID4+Hi/58XHx+P48eNyjVarRVRUVJ2as88vLi5GXFxcnfePi4vzqzn3faKioqDVauWa85k7dy5mzZol/15RUdH44UrvuxpQKQkAQLiovFg1ERERXaYmHaw+++wzfPLJJ/j000/RvXt35OTkYObMmbBYLJg0aZJcp1Ao/J4nhKiz7Vzn1pyv/nJqzqXT6aDT6S7aS4PT1QYr79lgVQPJ64VSpQpmV0RERCGnSZ8KfPzxx/HUU0/h7rvvRo8ePZCeno7HHnsM8+fPBwAkJCQAQJ0Ro5KSEnl0KSEhAS6XC1ar9aI1p06dqvP+p0+f9qs5932sVivcbnedkaymRqH1BTtV7dWUSoVApY2LhBIREQVakw5WNTU1UCr9W1SpVPJyC4mJiUhISMD69evl/S6XCxs3bsTAgQMBACkpKdBoNH41RUVFyM3NlWsGDBgAm82G7du3yzXbtm2DzWbzq8nNzUVRUZFck5mZCZ1Oh5SUlAB/8sBS1o6YKVwe1Ajfz1XlJcFsiYiIKCQ16VOBY8eOxSuvvIK2bduie/fu2L17NxYuXIh7770XgO/U3MyZMzFv3jx06tQJnTp1wrx582A0GpGWlgYAMJvNuO+++zB79mzExMQgOjoac+bMQY8ePTB8+HAAQNeuXTF69GhMmTIF77//PgBg6tSpSE1NRVJSEgBg5MiR6NatG9LT0/HGG2+grKwMc+bMwZQpUxARERGEo1N/SoPe94PLhQpFOIxworr8THCbIiIiCkFNOlgtWrQIzzzzDKZNm4aSkhJYLBY88MADePbZZ+WaJ554Ana7HdOmTYPVakW/fv2QmZmJ8PBwueatt96CWq3G+PHjYbfbMWzYMCxbtgyq38wxWr58OWbMmCFfPThu3DgsXrxY3q9SqbB27VpMmzYNgwYNgsFgQFpaGhYsWNAIR+LKKHW+YKVweVCtCge8Z+Cs5I2YiYiIAk0hhBDBbqI5qaiogNlshs1ma7SRru+W/BUt3/kcx5Jj0PY6Bbq7fsbOvgvQZ8yURnl/IiKiq119v7+b9BwrCgyV3gAAUDg9cGrMAABvFSevExERBRqDVTOg1hsBAEq3Bx6tL1hJNQxWREREgcZg1QyoDb5gpXJ74dVHAgAUjvLgNURERBSiGKyaAbXB5PvX5QUM0QAAlZM3YiYiIgo0BqtmQFt7KlDlkaA0RAIA1C4GKyIiokBjsGoGNMYwAIDaLaAJ841Y6d0MVkRERIHGYNUM6Iy+Nb00bgna8BgAgMFbEcyWiIiIQhKDVTOgM/hGrDQewBARCwAIkyqD2RIREVFIYrBqBuQRKy+gC/MttxAuqiFq77lIREREgcFg1QzojL+uEKutvb2NTuGGw14drJaIiIhCEoNVM6A3/nrfRJVSCbfw3SOxwloSrJaIiIhCEoNVM6DWaOGp/Us77VWoUPjmXFWXnwliV0RERKGHwaqZcGl8/zprKlGl9I1g2W0MVkRERIHEYNVMeNQKAIDLXgW7yjfnyskbMRMREQUUg1Uz4dH4/tSummo41b4RK09VaTBbIiIiCjkMVs2EHKzsVXBpfUsuSDUcsSIiIgokBqtmwqvxXQnoddTAq4sEAAi7NYgdERERhR4Gq2bCq/UFK7e9GkIfBQBQOsqD2BEREVHoYbBqJrwaNQDAY6+B0ugLVhoXb8RMREQUSAxWzYSoHbHyOh1Q1QYrrZvBioiIKJAYrJoJSetbyMprt0MTHgMA0Ht4I2YiIqJAYrBqJoTOF6wkpx362mBl8lYEsyUiIqKQw2DVXGi1AADJ6YQxsgUAIExUBbMjIiKikMNg1VzoaoOVw4Hw2mAVrrDD7XIGsysiIqKQwmDVTChqg5VwOhEeGStvr+SNmImIiAKGwaqZUOh0vh+cLqjUalTACACoKj8dxK6IiIhCC4NVM/FrsHIDAKoUvvsF1tg4YkVERBQoDFbNhEpvAAAoXC4AQLXSF6yclbxfIBERUaAwWDUTytoRK4XLAwBwqCMAAO6q0qD1REREFGoYrJoJlcE3p0rh8p0KdGl8wcpTzRErIiKiQGGwaiZUel+wUtaOWHl0kQAAUWMNVktEREQhh8GqmVDXzrFSub0AAEkfCQBQOhisiIiIAqXJB6vCwkJMnDgRMTExMBqNuPbaa5GdnS3vF0Lg+eefh8VigcFgwNChQ7F3716/13A6nXjkkUcQGxsLk8mEcePG4cSJE341VqsV6enpMJvNMJvNSE9PR3l5uV9Nfn4+xo4dC5PJhNjYWMyYMQOu2sngTZ2m9lSgyuULVgqD70bMKidvxExERBQoTTpYWa1WDBo0CBqNBv/973+xb98+vPnmm4iMjJRrXn/9dSxcuBCLFy/Gjh07kJCQgBEjRqCy8tcbDM+cOROrVq1CRkYGNm/ejKqqKqSmpsLr9co1aWlpyMnJwbp167Bu3Trk5OQgPT1d3u/1ejFmzBhUV1dj8+bNyMjIwMqVKzF79uxGORZXSmMMA/DriJXSFO3b7mawIiIiChjRhD355JNi8ODBF9wvSZJISEgQr776qrzN4XAIs9ks3nvvPSGEEOXl5UKj0YiMjAy5prCwUCiVSrFu3TohhBD79u0TAMTWrVvlmqysLAFAHDhwQAghxFdffSWUSqUoLCyUa1asWCF0Op2w2WwX7NHhcAibzSY/CgoKBICLPqch5G7+f2JfUhfxY9/uQgghdn39sRDPRYgDL/2hUfsgIiK6Gtlstnp9fzfpEavVq1ejT58+uPPOOxEXF4fevXvjww8/lPfn5eWhuLgYI0eOlLfpdDoMGTIEW7ZsAQBkZ2fD7Xb71VgsFiQnJ8s1WVlZMJvN6Nevn1zTv39/mM1mv5rk5GRYLBa5ZtSoUXA6nX6nJs81f/58+fSi2WxGmzZtrvCoXB6d0bdulcYt+X4PjwEAGL0VQemHiIgoFDXpYPXLL7/g3XffRadOnfD111/jwQcfxIwZM/DRRx8BAIqLiwEA8fHxfs+Lj4+X9xUXF0Or1SIqKuqiNXFxcXXePy4uzq/m3PeJioqCVquVa85n7ty5sNls8qOgoOBSDkHAaA2+U4EajwAAGMy++wWGiaqg9ENERBSK1MFu4GIkSUKfPn0wb948AEDv3r2xd+9evPvuu7jnnnvkOoVC4fc8IUSdbec6t+Z89ZdTcy6dTgfd2dvJBJHOEIZqABqP77iGRbYAAISLKghJgkLZpDM2ERHRVaFJf5u2bNkS3bp189vWtWtX5OfnAwASEhIAoM6IUUlJiTy6lJCQAJfLBavVetGaU6dO1Xn/06dP+9Wc+z5WqxVut7vOSFZTpDP5FgRVCsDjdCA80jdipVZIqKosD2JnREREoaNJB6tBgwbh4MGDftsOHTqEdu3aAQASExORkJCA9evXy/tdLhc2btyIgQMHAgBSUlKg0Wj8aoqKipCbmyvXDBgwADabDdu3b5drtm3bBpvN5leTm5uLoqIiuSYzMxM6nQ4pKSkB/uSBZzCZ5Z/tNTbojWFwCA0AoNJ6OlhtERERhZQmfSrwsccew8CBAzFv3jyMHz8e27dvxwcffIAPPvgAgO/U3MyZMzFv3jx06tQJnTp1wrx582A0GpGWlgYAMJvNuO+++zB79mzExMQgOjoac+bMQY8ePTB8+HAAvlGw0aNHY8qUKXj//fcBAFOnTkVqaiqSkpIAACNHjkS3bt2Qnp6ON954A2VlZZgzZw6mTJmCiIiIIBydS6PRGSHBl6Sd9koALVGhCIceZaixnQaQFNwGiYiIQkCTDlZ9+/bFqlWrMHfuXLz44otITEzE22+/jQkTJsg1TzzxBOx2O6ZNmwar1Yp+/fohMzMT4eHhcs1bb70FtVqN8ePHw263Y9iwYVi2bBlUKpVcs3z5csyYMUO+enDcuHFYvHixvF+lUmHt2rWYNm0aBg0aBIPBgLS0NCxYsKARjsSVUyqVcKsBnQdw1vjW+KpWhgNSGew23oiZiIgoEBRCCBHsJpqTiooKmM1m2Gy2Rh/p2tG7G8LsApoV76Jj76HYN28wurn2IPsPbyPl5r80ai9ERERXk/p+fzfpOVYUWB617+pFZ7VvtXWn2vcfhqeaI1ZERESBwGDVjFRF6QEAp555DoVHcuDW+ia0SzVlwWyLiIgoZDBYNSOW556DLUyJlkVOFNw9AUU2OwBAYS8PbmNEREQhgsGqGek+aBzaZCxHUUsdzFUS2v/7IDadioDSWR7s1oiIiEICg1Uz06rjtei7KhPHkmOg9QAtNoSh4PtcbP18CVz2mmC3R0REdFXjVYGNLJhXBf6Wx+3C51NHokfWryvO1+iAot6tETX6Zlw37j4YjE1/fS4iIqLGUN/vbwarRtZUghUAFBccweE3R8F2QomYPDUiq3/dV6MDilLaIW7cbbj2pnRodcbgNUpERBRkDFZNVFMKVgBQXVmOPV8sRMcjS3GiwoMTJ02I/kWDqMpfayqNCpT074g2f5qIHkP/BCVv2ExERM0Mg1UT1dSC1Vk1VTb8/MVCdD7yD5hFBfbYTDhxwoQWv6gR8ZupV2ei1ai84Tp0/fMDSEweGLyGiYiIGhGDVRPVVIPVWTVVNuzf+G+Ig/9F54osGKRq7C4PR8lxI1r9ooLe/WttQWIYNLfehL53P4owc0zwmiYiImpgDFZNVFMPVr/ldjlxcEcmqn5ajcSSb2HyWrGzJBz2Ywa0zVdCWftfjl0LnBzYEYkT70f3wbcEt2kiIqIGwGDVRF1Nweq3JK8Xh3ZtQPnO/6D9qW8gnOXIORGBsENaxNoUct3JVnqIW0ai3z2zER4ZF8SOiYiIAofBqom6WoPVbwlJwsHs72DbvgKJJetRUO5BUV4Y2h5VQeP11fhGsa7BNZMfRtf+NwW3YSIioivEYNVEhUKw+i2P24X9WWvh2PUZ4kp+wIGTWhgO6tDC+usoVkEbPdR3pKLfhMdgCo8OYrdERESXh8GqiQq1YPVbTkcN9m/+f3D/9C948neh7Bcd2h5VQS359lfrgZODOqPHQ0/yikIiIrqqMFg1UaEcrH7LUVOFvd9/hpqdH6PySAEiDmoRY/t1/5GORkSlp2PAn6ZDpVIHr1EiIqJ6YLBqoppLsPqtM8X5OJT5f6jY+TnEITfaHlPKN6k8HalAyZBkDJ/zFiJbtApqn0RERBfCYNVENcdg9Vt5e7dh/9p34MrORpsDChidvu0ODXC4ZySSHngCva6/LbhNEhERnYPBqolq7sHqLMnrRc6mVTj874WI+8mKhNJf9x1tp4Lr+v4YNeMNmMKjgtckERFRLQarJorBqi6b9Qy+fXc21Jt34JpfhHyasFoH5HUNR8vxkzHw1gd5j0IiIgoaBqsmisHq4n5c83cU/Od9tNlfieiKX7cftyihmvRnjJj0t+A1R0REzRaDVRPFYFU/VRVWrH/vCWBLFjoc8ULr8W0/0FWF6LT7cf0dM6DgCBYRETUSBqsmisHq0u36/nPkvfMiuu3zzXR3aoBfrlWixZh0/OHWGdDpjUHukIiIQh2DVRPFYHX5tvy/D1DxP++g3UnffXOq9EBRDy/CBo5Er9ufQkx86yB3SEREoYrBqolisLoykiThm/efge6jLxBn9S3pXq0DipPdCOvVC61HzULHXoOC3CUREYUaBqsmisEqMDxuF35YNh/457+RcMY3guXQAIVd3TB3ioJx4APoOSIdGq0uyJ0SEVEoYLBqohisAsvr9eDH5Qvg/vunsJxy+7YpgOMdvYjuLEFxXTp63jITxjBzkDslIqKrGYNVE8Vg1TAkScLONf+HM//3dyQe/nWdhmPtJcR0d8HbayJ63DoLYRFccJSIiC4dg1UTxWDV8A5sW4cjSxag/fZCqGr/6/6lo4RWXe2wd70bXcfNQmRsQnCbJCKiqwqDVRPFYNV48nK3YO/rzyJxeyGUACQAeUledEqqRnm70Whz8+OwJHYJdptERHQVYLBqohisGt+hnd/g8IKX0CGnBADgUQLHu3pwbadynGoxGNE3PY3Ebn2D3CURETVl9f3+vqqWrp4/fz4UCgVmzpwpbxNC4Pnnn4fFYoHBYMDQoUOxd+9ev+c5nU488sgjiI2Nhclkwrhx43DixAm/GqvVivT0dJjNZpjNZqSnp6O8vNyvJj8/H2PHjoXJZEJsbCxmzJgBl8vVUB+XAqRzn+EYk7ER0t9fw7GuUVBLwDV71Sj9MhbF2/fA+PFo7Fx4BwqO7Al2q0REdJW7aoLVjh078MEHH6Bnz55+219//XUsXLgQixcvxo4dO5CQkIARI0agsrJSrpk5cyZWrVqFjIwMbN68GVVVVUhNTYXX65Vr0tLSkJOTg3Xr1mHdunXIyclBenq6vN/r9WLMmDGorq7G5s2bkZGRgZUrV2L27NkN/+EpILoPGoebVm2B/X/+ioLEMGg9QIefNChaE4firJ8hPhyG7W//GSePHQx2q0REdLUSV4HKykrRqVMnsX79ejFkyBDx6KOPCiGEkCRJJCQkiFdffVWudTgcwmw2i/fee08IIUR5ebnQaDQiIyNDriksLBRKpVKsW7dOCCHEvn37BACxdetWuSYrK0sAEAcOHBBCCPHVV18JpVIpCgsL5ZoVK1YInU4nbDZbvT+LzWYTAC7pORR4Xq9XZK38X7F++HViX1IXsS+pi/i5axex5taO4tDj8WLb238WBYf3BLtNIiJqIur7/X1VjFg9/PDDGDNmDIYPH+63PS8vD8XFxRg5cqS8TafTYciQIdiyZQsAIDs7G26326/GYrEgOTlZrsnKyoLZbEa/fv3kmv79+8NsNvvVJCcnw2KxyDWjRo2C0+lEdnb2BXt3Op2oqKjwe1DwKZVK9L99Gm78egeq3piN/E4RvlOE+9VwrYlCycYdEB/egJ0L78Cx/TuD3S4REV0lmnywysjIwK5duzB//vw6+4qLiwEA8fHxftvj4+PlfcXFxdBqtYiKirpoTVxcXJ3Xj4uL86s5932ioqKg1WrlmvOZP3++PG/LbDajTZs2v/eRqREplUr0HXs/Rq3ZBteSF3AsOQZKAVyzT42yL2NxattPiPhkJHa/fhMObF8f7HaJiKiJa9LBqqCgAI8++ig++eQT6PX6C9YpFAq/34UQdbad69ya89VfTs255s6dC5vNJj8KCgou2hcFT68bx+Om/2yGa8kLyL8mHFqvbw5W3pp4nMw+DN1/JmD/KwOQs/5TSL+Zn0dERHRWkw5W2dnZKCkpQUpKCtRqNdRqNTZu3Ih33nkHarVaHkE6d8SopKRE3peQkACXywWr1XrRmlOnTtV5/9OnT/vVnPs+VqsVbre7zkjWb+l0OkRERPg9qGnrdeN4jFizFRXzH0WRRQ+jyxewHKtjcPz7MlR8/hSOvtgTO9e8D6/HE+x2iYioCWnSwWrYsGHYs2cPcnJy5EefPn0wYcIE5OTkoEOHDkhISMD69b+eonG5XNi4cSMGDhwIAEhJSYFGo/GrKSoqQm5urlwzYMAA2Gw2bN++Xa7Ztm0bbDabX01ubi6KiorkmszMTOh0OqSkpDTocaDGp1Qq0e+2BzFk/Q5YX3wIx5JjIAFoV6BEiw0mnPlSgu3/zcPxl3tg5+r3GLCIiAjAVbhA6NChQ3Httdfi7bffBgC89tprmD9/PpYuXYpOnTph3rx5+P7773Hw4EGEh4cDAB566CF8+eWXWLZsGaKjozFnzhyUlpYiOzsbKpUKAHDTTTfh5MmTeP/99wEAU6dORbt27bBmzRoAvuUWrr32WsTHx+ONN95AWVkZJk+ejFtvvRWLFi2qd/9cIPTqVXgkBz/9401Erd+FyEoJAFAUKxB+XQUSYswo7jUd1958PzRaXZA7JSKiQKvv97e6EXtqEE888QTsdjumTZsGq9WKfv36ITMzUw5VAPDWW29BrVZj/PjxsNvtGDZsGJYtWyaHKgBYvnw5ZsyYIV89OG7cOCxevFjer1KpsHbtWkybNg2DBg2CwWBAWloaFixY0HgfloKqVcdr0Wrex3A9U4MN7zyJmBXfouUZAJlm7EmU0L7iJZzJeQv5Xaeg19iHoTeGBbtlIiJqZFfdiNXVjiNWoaOs+Di2zHsM7b7ZD7VvAAsn4wSkTg50bClQ3GkiOo9+CDHxrYPbKBERXTHeK7CJYrAKPb/s2Yx9bzyPttmF0NReLOhSAwXXeHFNp0rY41OgSpmI7n+8HWqNNrjNEhHRZWGwaqIYrEJXWfFx7PzoTWjWbkTCKd89JCUAxzp60amLDVFhBhxtfTs6ps5EbELb4DZLRESXhMGqiWKwCn2SJCF30+coeH8xOuz+dRmPXzp6kZhUgY5hbvwUNQIxwx9Dh+R+F3klIiJqKhismigGq+blwPavcfSt+X4BqzBeQNHJjn4JFThm6omaLn9C0pC7YY5uEcROiYjoYhismigGq+bp4I5MHF70OtrtLJQnutu1wMlOHrRpW4WkcCcOmlLg7DyOIYuIqAlisGqiGKyat9OFR5C9bAGMX/2IFqW/LipaGgHYrnGhU6sqJJrc2G+4Ds7OY9Hp+rsQGZsQxI6JiAhgsGqyGKwIALxeD3av+xjF//4Ull0nYHD9uu9UtEB1Ww8sCTXoEm7HEWMvVLcbDkufVLTp2BMKZZO+YQIRUUhisGqiGKzoXNWVZche9T6q1q5D69wSeckGAKjSA6faeWFKcKB7dDU8+hgURA+AptMNsHQfjPhWHRi0iIgaAYNVE8VgRRdTfqYQP3/5ESo2fIeEnwphcvj/n2dRCwF7Kw9iWjjQIcwOlc6EE4YuqGnRC1HdR6BTyo1Qqa/6GyoQETU5DFZNFIMV1Zfb5UDu9ytxcv0a6HcdhKXQUaem3ASUt5AgRXsQF+tAm0jgROQAKJJGo+PAW2GOim38xomIQhCDVRPFYEWX63ThEexdtwJVP25G+OEixJ5249yTgE41UNRKgsriQqtoBxzmDnB3GIFW/W5Dm069gtI3EVEoYLBqohisKFCqbGdwdOd3KPlpK5y5exGz5wQiK6U6dZUGoCJCoCZCAbvZBBEXh7DEbujwhxHo1HsINFp9ELonIrq6MFg1UQxW1FAkScLh7G+Ql7kK2J6DmHwbwuwX/z9vjxIojVTAFmOA1NaC8C7dYEn5Izr3Hcn7GhIR/QaDVRPFYEWNqaKsGCcP5+Dk/l048/M2oLgYBms1wm1eRNkArff8z6vWAYWtdXBc0xIRPfugY9+R6NB9ACfGE1GzxWDVRDFYUVNhs57GT99l4HTOtxBFx6CzVUNjU6JFsRJGV916pwYoDwcqI9RwG7RQavRQa3VA7XIPCo/X9/B6ofBI8MRGIv62O3HdTfdApWIgI6KrG4NVE8VgRU2VvboSv+RsQmXhPpw6vAv2Y3kwFlaixSkJkdWX/7plZhXKh/ZClwkPIjF5EJRcd4uIrkIMVk0UgxVdjSqsJdi/dR2K922F/cRRKKtKYfTaoBUenP0fEIVCQKkElAoBhRKoPqNFyyNqGJ2/vo5LDVQaFagJ18ITaYIUEwlVawtMbTsg+pquaNmxF6Li2zF8EVGTw2DVRDFYUagQkoTCX/ahKHcjvIW7oaspgslZgkjPGcQIK1QKAbsE7DhtRnWeAW2PK6Gsx//aeJRAjUEBu1ENV5gO7kgT0LolDB2uQUznnmjdrS+0BhNqbKWoqbTCXlEGr8uJmLadEdcmiZPuiahBMFg1UQxW1Bx43C5UV1jhsFfBZa+Cy16N8lPHULLve4iiXBgqiyE5vXDa1ZCqVNBWKhFeoUBk1RW+rxKwmVWojjbC3S4BEX37o/ONtyKhXTe5xuWswS8//YCinC1Q6Y247pb7EWaOucJPTEShjsGqiWKwIgIkrxfH9u+ENT8XnooSSFUlUNWchqg6DVFzGgpHBRQuBxxuBRwONVyVaqgrlAgvVyK6ovY1FIBD65tULxRARDWgrruMFwDgdIwale1ioT9VjhbFDr/7MTo0QGFKa8Td+if0vnkS1/UiovNisGqiGKyI6sfr8cBaUojSk0dRWXQY7jO/QF1+DNrK44hxF8GiLIdS8Wu9RwJK3BqcdmhgtWtQVaaFoViNhBJFnRXqa7TAqTglwqoEWpT/+j+BFSYFytpFwpsQC3UrC8LaXYNwSzvowszQmyKgDzNDbzLDaIqC1mD0e03r6QIU7N2G0kN7YD9+DGEdk9Dv7hnQGcIa8CgRUWNhsGqiGKyIAqO6shzFxw7AVngArjN5ENVlUDlKoXFaYXBZYfacQawoQ41HYL/NhPJKLcJMbrQJd6CN3gWlApAEsKfCiIITYYg7oka4vf7v71ECLg3g1iih8orzLsZaYVLgzLBr0WvK42jdqffvvqbb5eCIGVETxWDVRDFYETUeyetF2akTKCvOQ/WZE5DcDkgeF+B1Q/I4IUp/QWRpDjq4DwPCg9wKE6zVGjiq1RBVKugqlTDUKKB2A1oPoHPjohPwreFK2OKMcLcwo8XeIvkWQxKA/K5RkBJbQ2OxwNSqLSLbdkT16SKU5myH2H8EkXmliKrwoqBDOJSjhiDlz48gKq5t4xwoIvpdDFZNFIMVUdPjsFfjWG4Wyo9sh6gqgdJhhcZphdZtg9lVgnjpFLQKLyQBuCXALpRweFVwSEo4vL7zka31LoT9ZpKX1WvAD9aWUB7y4Jp8zyX35FECBcmxUPXuKS/CCgAKpRKmVu3QonNPtEq6DqbwaACAy16D/EM7UHIgB5V5hwEAKr0BKqMRaoMJ4QltkDz0Dl41SXSZGKyaKAYroquP1+PBqYIjKC3Yj5riw5CqTkNpL4PKYYXWXQ6D2wa9VAODqIFR2GFUOP2ef7RGh6OnTXDVqKCoVkFXpUBYpQIurUBFCwmqaA/CIhVQ6w0oOKVB9FEXWpVcYCb+OawRKnjVCkRZPVD9zv+al4crUTq4K64Z/xck9buJ64URXQIGqyaKwYoo9LmcDpz8JRdnju6C++QeGK0HEOk8CbVwQyUkqOCBGl4YhR06hfu8r3G4Wo9DhWEQVSq/7QpJAV2lApHlCpj88xvsWqA0RouaFmFQaDRQuSWoXB4oXR5EFVX5zQM7FadFVYd4QK8DDDoo9HqowsJgtLSFuW1HtEjsirg2SVAolSgvKUDZyV9QceoEHBVliGrbCW26/QHhkXEBOV57N/8/FCx4DREnK2C/ZyyGPvQSb4NETQ6DVRPFYEVEZwlJgr2mEhVlJaiylsBefgr2M8fhLTsOTeUJGO1FtSvcO6EVLuiEE0Y4oFL4/me7zK3CCbsObkmBVgYX4rRuvyslAaACRtgUkShXmHGkDMAvNehw1H3BG3D/lkcJKAQuOBJmC1OiIs4EV0I0lC3joG/VBuFtr0FMu86ISmiHiOiWFw1Ix/ZmYe/8v6HDzpN+20+0N6HNCy+jS7/Rv9/kb+z9cTWO/e9bSNh7CsUje+GG596FMSzykl6D6EIYrJooBisiuhJejwfF+Qdx5the2Iv2Q1l6GDp7CdTeGmi9duiEHQapBmZRAa3i/OnJ5lZi95lwOBwqSF4FhEcJ4VVAOJXQVCsRVgWYK/3XBavSA1UmJVxaJSJtXkTU/P5XhwTArlfAblTBZdTAbdTCa9JDhBkBlxvtdpyAWvLV5fVvDVWH9oj/z2YYXL51yvJGdkNE7z6oPLgXil8KEHbCCmO1B2famSF6dUX8oBvR9Y/jsHfDSpz54AO0O1ju9/5notXQP/0Y+qbee/kHnKgWg1UTxWBFRI1BSBIqrKdRfroQVaVFcNhK4Kkug2QvB+zlUDmt0NlLEO48hRjpNMzwv9O2RwJOuzVQKgSi1B5oz5mOZXMrccKux5kaDWqq1fBWq6CqVsJQqUBElQIGV/36PNopDNo7xiGhXVdAoUBVtQ1n/vkPdPq5tF7P9yp+HVHzKoDD18bC3T4erb/Zj6jaqzKPDmyLlGfeRHy7bn7zylz2GuzbshpFGzOhyNkHTY0L9nbx0HbpjNiefXFNn2Ewx7Q87/tKkoS9m1Yh/7+fQ6HTIqJzNyR074u23f4Arc543ufQ1Y3BqolisCKipqi6shxlpwrgrLbBWV0Bt70CHnsFvPYKCLsNwlkBpbMCKlcF9M4zCHOXwSxZEYVKAECVMMCmjECVKhIulRFGezGM7jOo9ipR5VbB7lbB6VbC7VbC41ZC8ijQMs6O66Kqz9vP9rJwlOeGAQKoilbCE2WEKi4Omsg41BQWQZd/Bi3z7TBXC7jUwNGuSvTucAaJBgcAoMKjxDcHLUjaI8kLxHqUvlG3mggtvFo14k5UQXf+KW6y07EaVHRMgK5nD7TqfwOUag2OrvwIET/8jNiyuld7epTAmTgdavp2QeubbkfykNuvaL6YJEk4vm8rjmWtR/XPOYBCgcTxk9B98C2X/Zp0eRismigGKyIKJS6nA0JI0OnrjtI47NUo+iUXZcdz4TpzDIrKImjtp2B0nkGEpxSAgBdqeBW+ByBgkKphEtUIEzXyXLILkQRQ4NDCrPEgsva8ZRkiUKqKQwfPUagUAj/ZjDiTbYalRHHe16g0AIVttHC2joDSZIRUWgX96RrEljgRY7v4+zs1wIleLQGtBvoTZxBdXFNnpM4WpsSZ69pD3a4tJIcdwuGAcDgBlxsKkxHKiAiozZHQRcVA8nrgPH0KntIzEGU2qM+UI/a4DSZH3T5OttJD3DIS/Sc9jjBzrO94SBLczhpIQoLBeOXfL26XA8f3bsXJnC2o3J8LxS8FkMKNaDtpCnoO/dMVv/7VhsGqiWKwIiL6fZLXi6rKcpQV5cFWdASO08cgyo5BbT9dW+ELSkKhgMeYAF27FFi6DUJ862ugUCphPV2EIz+uhOrwOnSp2g615MQZjwZWlxqVTjUcHiVahjnR0eSA6vyZC2VuFQ5XGFFapoPijBotipXQuYH8dhJM7ezo06ISYSoJbqFChSIMFYownHSbUFyugLLAgbZ5bhjreUr0Ylwq4FQrI5yd20Bhq0LbXYXy/S4dGsBuUEHrkqBzCXleXI1OgaoINRyRBrijwqHwSlDWOKCucUFb44LaJUFSKSCUCkgqBSSlEgohoHJ7oXYLaNwS9E5xwftvFrY1Qn3XrRiYNrvO7Z38erfXoMp2GmFRLS56itTlrIFao6/XEiBOexVOHN6N04d/RnVxIXTmKBhbtEREXGtEJbRDZFybBrmqNCSC1fz58/H555/jwIEDMBgMGDhwIF577TUkJSXJNUIIvPDCC/jggw9gtVrRr18//O///i+6d+8u1zidTsyZMwcrVqyA3W7HsGHDsGTJErRu3VqusVqtmDFjBlavXg0AGDduHBYtWoTIyEi5Jj8/Hw8//DC+++47GAwGpKWlYcGCBdBq67/gHoMVEVHjcjpqcObkcVSXl8BhOw1X5Rl4a6wQHieE1wV4PYDXBYXXBYXHDoXHAZXXDpXHDqO7DBGeMkQLK1TwwitQZ77Zhbi8QI4tDCVFRsClANQCUAsoVAIKpYBwKyFcCiidSqicCkAh4DEICIMElU6CTu9FfIQTnYx2aGtX3fAIJQrdRvx0Mgzmg0rEWRvuuAG+4Ha6pQH2Ni2gvqYDvIeOoP2OE3KwqzApUBWhBSCgEIAQgNojQeeUYHBI0NaeLZUAVJkUqI7QwRllhKTTQGOrgb7CAVOlB0angF0LWFvo4YiPBNpYoGnRAp7yckhlZVCUV0JTXg1TaQ0ibd469//8LUkBWDZlIqpFm4Aei5AIVqNHj8bdd9+Nvn37wuPx4K9//Sv27NmDffv2wWQyAQBee+01vPLKK1i2bBk6d+6Ml19+GZs2bcLBgwcRHh4OAHjooYewZs0aLFu2DDExMZg9ezbKysqQnZ0Nlcr3X+tNN92EEydO4IMPPgAATJ06Fe3bt8eaNWsAAF6vF9deey1atGiBN998E6WlpZg0aRJuv/12LFq0qN6ficGKiOjqI3m9qLCeRnVFKVRqLdRaHdRqLZRqDRzVFb7lMmxn4Kw8DU+1FZLLDrjtEB4H4K6B4tyvWiFB6bRB4yqH3m2D0VsBtXBBQAFAUfsvoBMOGIUdYYq6N7KUBHCoWg+vUECvkmBUSTCovBAASl0alDvVqHKo4XSqoFACGrUErUaCQe2FViUgAfBKCkgC8AoFFBDQqAS0SgGtUoJeJaGlzl1nRO+0S40dBWZE79PBfP4pcg3OoQHKojWwRxqgrnHCUO2GqVqCyemb59Ztz56Aj1qFRLA61+nTpxEXF4eNGzfi+uuvhxACFosFM2fOxJNPPgnANzoVHx+P1157DQ888ABsNhtatGiBjz/+GHfddRcA4OTJk2jTpg2++uorjBo1Cvv370e3bt2wdetW9OvXDwCwdetWDBgwAAcOHEBSUhL++9//IjU1FQUFBbBYLACAjIwMTJ48GSUlJfUOSQxWRER0qSSvFzXVFaipLIej9gIDZ40NHnuVfA9MyeOC8Lgg3HbAVQPhrobCVQ2lpwYKyQOF8P76r/BCKTy1/3qhlDxQCxe0kh16yQEdHNALJ1SQoIL3vPPdXF4gt8IEj1BCCAGvQgUvlNApvIjQuGBSexGm9sKklGDzqFHqUqPcqUGNQwWPVwG9ToJJ54FZ60GU2gOrR42Sah0qq9VwV6mhsCsh9BKUeglqnRd6nQSz3o2WehditZ46a7ad7ancq4Zp7lGYwiMD+jeo7/f3VbW0rc1mAwBER/vujZWXl4fi4mKMHDlSrtHpdBgyZAi2bNmCBx54ANnZ2XC73X41FosFycnJ2LJlC0aNGoWsrCyYzWY5VAFA//79YTabsWXLFiQlJSErKwvJyclyqAKAUaNGwel0Ijs7GzfccMN5e3Y6nXA6f10euaKiIjAHg4iImg2lSoWwiCiERUQF5f2FJMHr9UCSJAghQUgShBDoIiRotHqo1RooaudHnV3qo6z4GApOn4DDWgjJXgHhqgKc1TC5q6CQ3JDURrg0BpzWGHBGrYfwuqFwVcHsqobSXQ2VpwYKIfmCICQoJA/UkgMV3hq4pGoYhB064UKZKho2TTzsRgu8Ea2hjmqDZKXqdz5Rw7lqgpUQArNmzcLgwYORnJwMACguLgYAxMfH+9XGx8fj+PHjco1Wq0VUVFSdmrPPLy4uRlxc3VszxMXF+dWc+z5RUVHQarVyzfnMnz8fL7zwwqV8VCIioiZFoVRCrazffGKFUglzTDzMMfEA+v1u/ZUKa/B3uDRXzR04p0+fjp9//hkrVqyos0+h8B8PFELU2Xauc2vOV385NeeaO3cubDab/CgoKLhoX0RERHT1uiqC1SOPPILVq1djw4YNflfyJSQkAECdEaOSkhJ5dCkhIQEulwtWq/WiNadOnarzvqdPn/arOfd9rFYr3G53nZGs39LpdIiIiPB7EBERUWhq0sFKCIHp06fj888/x3fffYfExES//YmJiUhISMD69evlbS6XCxs3bsTAgQMBACkpKdBoNH41RUVFyM3NlWsGDBgAm82G7du3yzXbtm2DzWbzq8nNzUVRUZFck5mZCZ1Oh5SUlMB/eCIiIrrqNOmrAqdNm4ZPP/0U/+///T+/tavMZjMMBgMA33IL8+fPx9KlS9GpUyfMmzcP33//fZ3lFr788kssW7YM0dHRmDNnDkpLS+sst3Dy5Em8//77AHzLLbRr167Ocgvx8fF44403UFZWhsmTJ+PWW2/lcgtEREQhrt7f36IJA3Dex9KlS+UaSZLEc889JxISEoROpxPXX3+92LNnj9/r2O12MX36dBEdHS0MBoNITU0V+fn5fjWlpaViwoQJIjw8XISHh4sJEyYIq9XqV3P8+HExZswYYTAYRHR0tJg+fbpwOByX9JlsNpsAIGw22yU9j4iIiIKnvt/fTXrEKhRxxIqIiOjqU9/v7yY9x4qIiIjoasJgRURERBQgDFZEREREAcJgRURERBQgDFZEREREAcJgRURERBQgDFZEREREAcJgRURERBQg6mA30NycXY+1oqIiyJ0QERFRfZ393v69ddUZrBpZZWUlAKBNmzZB7oSIiIguVWVlJcxm8wX385Y2jUySJJw8eRLh4eFQKBQBe92Kigq0adMGBQUFvFVOA+Oxbjw81o2Hx7rx8Fg3rkAdbyEEKisrYbFYoFReeCYVR6wamVKpROvWrRvs9SMiIvh/qI2Ex7rx8Fg3Hh7rxsNj3bgCcbwvNlJ1FievExEREQUIgxURERFRgDBYhQidTofnnnsOOp0u2K2EPB7rxsNj3Xh4rBsPj3XjauzjzcnrRERERAHCESsiIiKiAGGwIiIiIgoQBisiIiKiAGGwIiIiIgoQBqsQsWTJEiQmJkKv1yMlJQU//PBDsFu6qs2fPx99+/ZFeHg44uLicOutt+LgwYN+NUIIPP/887BYLDAYDBg6dCj27t0bpI5Dx/z586FQKDBz5kx5G4914BQWFmLixImIiYmB0WjEtddei+zsbHk/j3XgeDwe/O1vf0NiYiIMBgM6dOiAF198EZIkyTU83pdn06ZNGDt2LCwWCxQKBb744gu//fU5rk6nE4888ghiY2NhMpkwbtw4nDhx4sqbE3TVy8jIEBqNRnz44Ydi37594tFHHxUmk0kcP3482K1dtUaNGiWWLl0qcnNzRU5OjhgzZoxo27atqKqqkmteffVVER4eLlauXCn27Nkj7rrrLtGyZUtRUVERxM6vbtu3bxft27cXPXv2FI8++qi8ncc6MMrKykS7du3E5MmTxbZt20ReXp745ptvxJEjR+QaHuvAefnll0VMTIz48ssvRV5envj3v/8twsLCxNtvvy3X8Hhfnq+++kr89a9/FStXrhQAxKpVq/z21+e4Pvjgg6JVq1Zi/fr1YteuXeKGG24QvXr1Eh6P54p6Y7AKAX/4wx/Egw8+6LetS5cu4qmnngpSR6GnpKREABAbN24UQgghSZJISEgQr776qlzjcDiE2WwW7733XrDavKpVVlaKTp06ifXr14shQ4bIwYrHOnCefPJJMXjw4Avu57EOrDFjxoh7773Xb9vtt98uJk6cKITg8Q6Uc4NVfY5reXm50Gg0IiMjQ64pLCwUSqVSrFu37or64anAq5zL5UJ2djZGjhzpt33kyJHYsmVLkLoKPTabDQAQHR0NAMjLy0NxcbHfcdfpdBgyZAiP+2V6+OGHMWbMGAwfPtxvO4914KxevRp9+vTBnXfeibi4OPTu3RsffvihvJ/HOrAGDx6Mb7/9FocOHQIA/PTTT9i8eTNuvvlmADzeDaU+xzU7Oxtut9uvxmKxIDk5+YqPPW/CfJU7c+YMvF4v4uPj/bbHx8ejuLg4SF2FFiEEZs2ahcGDByM5ORkA5GN7vuN+/PjxRu/xapeRkYFdu3Zhx44ddfbxWAfOL7/8gnfffRezZs3C008/je3bt2PGjBnQ6XS45557eKwD7Mknn4TNZkOXLl2gUqng9Xrxyiuv4M9//jMA/rfdUOpzXIuLi6HVahEVFVWn5kq/OxmsQoRCofD7XQhRZxtdnunTp+Pnn3/G5s2b6+zjcb9yBQUFePTRR5GZmQm9Xn/BOh7rKydJEvr06YN58+YBAHr37o29e/fi3XffxT333CPX8VgHxmeffYZPPvkEn376Kbp3746cnBzMnDkTFosFkyZNkut4vBvG5RzXQBx7ngq8ysXGxkKlUtVJ2CUlJXXSOl26Rx55BKtXr8aGDRvQunVreXtCQgIA8LgHQHZ2NkpKSpCSkgK1Wg21Wo2NGzfinXfegVqtlo8nj/WVa9myJbp16+a3rWvXrsjPzwfA/64D7fHHH8dTTz2Fu+++Gz169EB6ejoee+wxzJ8/HwCPd0Opz3FNSEiAy+WC1Wq9YM3lYrC6ymm1WqSkpGD9+vV+29evX4+BAwcGqaurnxAC06dPx+eff47vvvsOiYmJfvsTExORkJDgd9xdLhc2btzI436Jhg0bhj179iAnJ0d+9OnTBxMmTEBOTg46dOjAYx0ggwYNqrNsyKFDh9CuXTsA/O860GpqaqBU+n/NqlQqebkFHu+GUZ/jmpKSAo1G41dTVFSE3NzcKz/2VzT1nZqEs8st/P3vfxf79u0TM2fOFCaTSRw7dizYrV21HnroIWE2m8X3338vioqK5EdNTY1c8+qrrwqz2Sw+//xzsWfPHvHnP/+Zl0kHyG+vChSCxzpQtm/fLtRqtXjllVfE4cOHxfLly4XRaBSffPKJXMNjHTiTJk0SrVq1kpdb+Pzzz0VsbKx44okn5Boe78tTWVkpdu/eLXbv3i0AiIULF4rdu3fLywzV57g++OCDonXr1uKbb74Ru3btEjfeeCOXW6Bf/e///q9o166d0Gq14rrrrpOXBaDLA+C8j6VLl8o1kiSJ5557TiQkJAidTieuv/56sWfPnuA1HULODVY81oGzZs0akZycLHQ6nejSpYv44IMP/PbzWAdORUWFePTRR0Xbtm2FXq8XHTp0EH/961+F0+mUa3i8L8+GDRvO+7/RkyZNEkLU77ja7XYxffp0ER0dLQwGg0hNTRX5+flX3JtCCCGubMyLiIiIiADOsSIiIiIKGAYrIiIiogBhsCIiIiIKEAYrIiIiogBhsCIiIiIKEAYrIiIiogBhsCIiIiIKEAYrIiIiogBhsCIiCqLvv/8eCoUC5eXlwW6FiAKAwYqIiIgoQBisiIiIiAKEwYqImjUhBF5//XV06NABBoMBvXr1wn/+8x8Av56mW7t2LXr16gW9Xo9+/fphz549fq+xcuVKdO/eHTqdDu3bt8ebb77pt9/pdOKJJ55AmzZtoNPp0KlTJ/z973/3q8nOzkafPn1gNBoxcOBAHDx4sGE/OBE1CAYrImrW/va3v2Hp0qV49913sXfvXjz22GOYOHEiNm7cKNc8/vjjWLBgAXbs2IG4uDiMGzcObrcbgC8QjR8/HnfffTf27NmD559/Hs888wyWLVsmP/+ee+5BRkYG3nnnHezfvx/vvfcewsLC/Pr461//ijfffBM7d+6EWq3Gvffe2yifn4gCSyGEEMFugogoGKqrqxEbG4vvvvsOAwYMkLfff//9qKmpwdSpU3HDDTcgIyMDd911FwCgrKwMrVu3xrJlyzB+/HhMmDABp0+fRmZmpvz8J554AmvXrsXevXtx6NAhJCUlYf369Rg+fHidHr7//nvccMMN+OabbzBs2DAAwFdffYUxY8bAbrdDr9c38FEgokDiiBURNVv79u2Dw+HAiBEjEBYWJj8++ugjHD16VK77beiKjo5GUlIS9u/fDwDYv38/Bg0a5Pe6gwYNwuHDh+H1epGTkwOVSoUhQ4ZctJeePXvKP7ds2RIAUFJScsWfkYgalzrYDRARBYskSQCAtWvXolWrVn77dDqdX7g6l0KhAOCbo3X257N+eyLAYDDUqxeNRlPntc/2R0RXD45YEVGz1a1bN+h0OuTn56Njx45+jzZt2sh1W7dulX+2Wq04dOgQunTpIr/G5s2b/V53y5Yt6Ny5M1QqFXr06AFJkvzmbBFR6OKIFRE1W+Hh4ZgzZw4ee+wxSJKEwYMHo6KiAlu2bEFYWBjatWsHAHjxxRcRExOD+Ph4/PWvf0VsbCxuvfVWAMDs2bPRt29fvPTSS7jrrruQlZWFxYsXY8mSJQCA9u3bY9KkSbj33nvxzjvvoFevXjh+/DhKSkowfvz4YH10ImogDFZE1Ky99NJLiIuLw/z58/HLL78gMjIS1113HZ5++mn5VNyrr76KRx99FIcPH0avXr2wevVqaLVaAMB1112Hf/3rX3j22Wfx0ksvoWXLlnjxxRcxefJk+T3effddPP3005g2bRpKS0vRtm1bPP3008H4uETUwHhVIBHRBZy9Ys9qtSIyMjLY7RDRVYBzrIiIiIgChMGKiIiIKEB4KpCIiIgoQDhiRURERBQgDFZEREREAcJgRURERBQgDFZEREREAcJgRURERBQgDFZEREREAcJgRURERBQgDFZEREREAfL/AY3i0G0am9P+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('epoch')\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили приемлемые ошибки: наша модель в среднем ошибается на ~21 тысячу. Также можно отметить \"рывки\" на графиках обучения, они связаны с тем, что мы \"скачем\" вокруг минимума фукнции потерь, что, естественно, не есть хорошо (это исправляется, например, уменьшением шага). Посмтрим, можно ли лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение параметров `batch_size` (количество данных для измерения градиента на каждом шаге) и `epochs` (количество эпох) напрямую влияет на обучение (`epochs` делает обучение более длительным, помогая с недообучением, возникающим, например, при задании маленького шага; большие же значения `batch_size` увеличивают точность градиента (так как мы \"накапливаем его\"), а также время на обучение модели). Давайте покажем это."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, зададим всю ту же модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_dim=X_train.shape[1], activation='linear'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "random.set_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.05),\n",
    "              loss='mae',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменим `batch_size` с 32 до 128, соответственно, сделав вычисление градиента более точным. Параметр `epochs` же увеличим, ожидая, что модель будет достаточно долго обучаться:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 [==============================] - 1s 22ms/step - loss: 180913.6250 - mae: 180913.6250 - val_loss: 178931.3906 - val_mae: 178931.3906\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 179407.2969 - mae: 179407.2969 - val_loss: 176457.2188 - val_mae: 176457.2188\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 176144.7188 - mae: 176144.7188 - val_loss: 171923.0312 - val_mae: 171923.0312\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 170638.4375 - mae: 170638.4375 - val_loss: 164868.7656 - val_mae: 164868.7656\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 162450.3906 - mae: 162450.3906 - val_loss: 154920.3906 - val_mae: 154920.3906\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 151254.3750 - mae: 151254.3750 - val_loss: 141815.8281 - val_mae: 141815.8281\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 136865.5469 - mae: 136865.5469 - val_loss: 125432.2578 - val_mae: 125432.2578\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 119189.4375 - mae: 119189.4375 - val_loss: 105772.0234 - val_mae: 105772.0234\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 98469.9297 - mae: 98469.9297 - val_loss: 84500.5391 - val_mae: 84500.5391\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 76824.7500 - mae: 76824.7500 - val_loss: 65816.5312 - val_mae: 65816.5312\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 60042.9023 - mae: 60042.9023 - val_loss: 56052.8594 - val_mae: 56052.8594\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 53975.9492 - mae: 53975.9492 - val_loss: 54398.1797 - val_mae: 54398.1797\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 53312.4570 - mae: 53312.4570 - val_loss: 54178.7109 - val_mae: 54178.7109\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 53221.6680 - mae: 53221.6680 - val_loss: 53990.7461 - val_mae: 53990.7461\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 52978.7891 - mae: 52978.7891 - val_loss: 53802.4023 - val_mae: 53802.4023\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 52686.3750 - mae: 52686.3750 - val_loss: 53626.4922 - val_mae: 53626.4922\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 52462.8398 - mae: 52462.8398 - val_loss: 53446.4336 - val_mae: 53446.4336\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 52323.0977 - mae: 52323.0977 - val_loss: 53314.8750 - val_mae: 53314.8750\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 52152.5703 - mae: 52152.5703 - val_loss: 53105.7344 - val_mae: 53105.7344\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 51923.8516 - mae: 51923.8516 - val_loss: 52821.1523 - val_mae: 52821.1523\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 51736.6445 - mae: 51736.6445 - val_loss: 52589.9961 - val_mae: 52589.9961\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 51532.4688 - mae: 51532.4688 - val_loss: 52361.4844 - val_mae: 52361.4844\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 51345.7227 - mae: 51345.7227 - val_loss: 52132.8555 - val_mae: 52132.8555\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 51108.9414 - mae: 51108.9414 - val_loss: 51944.7227 - val_mae: 51944.7227\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 50912.4336 - mae: 50912.4336 - val_loss: 51813.7188 - val_mae: 51813.7188\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 50736.8750 - mae: 50736.8750 - val_loss: 51525.2969 - val_mae: 51525.2969\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 50497.5352 - mae: 50497.5352 - val_loss: 51280.8203 - val_mae: 51280.8203\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 50326.4062 - mae: 50326.4062 - val_loss: 50986.1602 - val_mae: 50986.1602\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 50099.3828 - mae: 50099.3828 - val_loss: 50825.0273 - val_mae: 50825.0273\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 49858.4297 - mae: 49858.4297 - val_loss: 50570.9375 - val_mae: 50570.9375\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 49631.5508 - mae: 49631.5508 - val_loss: 50352.2031 - val_mae: 50352.2031\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 49417.3477 - mae: 49417.3477 - val_loss: 50100.3672 - val_mae: 50100.3672\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 49315.7227 - mae: 49315.7227 - val_loss: 49793.4883 - val_mae: 49793.4883\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 49004.5312 - mae: 49004.5312 - val_loss: 49612.2891 - val_mae: 49612.2891\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 48734.7617 - mae: 48734.7617 - val_loss: 49396.6562 - val_mae: 49396.6562\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 48535.7617 - mae: 48535.7617 - val_loss: 49155.0547 - val_mae: 49155.0547\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 48273.0430 - mae: 48273.0430 - val_loss: 48827.5000 - val_mae: 48827.5000\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 48047.4180 - mae: 48047.4180 - val_loss: 48579.1484 - val_mae: 48579.1484\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 47811.4883 - mae: 47811.4883 - val_loss: 48354.1328 - val_mae: 48354.1328\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 47571.3164 - mae: 47571.3164 - val_loss: 48133.5938 - val_mae: 48133.5938\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 47323.5977 - mae: 47323.5977 - val_loss: 47793.3164 - val_mae: 47793.3164\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 47057.3086 - mae: 47057.3086 - val_loss: 47502.9141 - val_mae: 47502.9141\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 46794.4375 - mae: 46794.4375 - val_loss: 47266.1797 - val_mae: 47266.1797\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 46536.4219 - mae: 46536.4219 - val_loss: 46938.4375 - val_mae: 46938.4375\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 46265.7617 - mae: 46265.7617 - val_loss: 46627.1797 - val_mae: 46627.1797\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 46006.4336 - mae: 46006.4336 - val_loss: 46358.3945 - val_mae: 46358.3945\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 45740.8242 - mae: 45740.8242 - val_loss: 46046.3359 - val_mae: 46046.3359\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 45505.4414 - mae: 45505.4414 - val_loss: 45741.4805 - val_mae: 45741.4805\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 45214.2695 - mae: 45214.2695 - val_loss: 45444.3359 - val_mae: 45444.3359\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 44914.0156 - mae: 44914.0156 - val_loss: 45148.2461 - val_mae: 45148.2461\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 44634.2227 - mae: 44634.2227 - val_loss: 44823.9023 - val_mae: 44823.9023\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 44337.4414 - mae: 44337.4414 - val_loss: 44545.3086 - val_mae: 44545.3086\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 44046.8125 - mae: 44046.8125 - val_loss: 44211.6406 - val_mae: 44211.6406\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 43759.3516 - mae: 43759.3516 - val_loss: 43887.8789 - val_mae: 43887.8789\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 43449.4570 - mae: 43449.4570 - val_loss: 43632.0547 - val_mae: 43632.0547\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 43121.5000 - mae: 43121.5000 - val_loss: 43234.9492 - val_mae: 43234.9492\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 42858.2109 - mae: 42858.2109 - val_loss: 42946.0352 - val_mae: 42946.0391\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 42586.8398 - mae: 42586.8398 - val_loss: 42526.5195 - val_mae: 42526.5195\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 42284.6562 - mae: 42284.6562 - val_loss: 42214.4727 - val_mae: 42214.4727\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 41951.6406 - mae: 41951.6406 - val_loss: 42135.9609 - val_mae: 42135.9609\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 41603.7969 - mae: 41603.7969 - val_loss: 41651.4922 - val_mae: 41651.4922\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 41265.6055 - mae: 41265.6055 - val_loss: 41223.1602 - val_mae: 41223.1602\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 40938.8633 - mae: 40938.8633 - val_loss: 40892.0898 - val_mae: 40892.0898\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 40605.7656 - mae: 40605.7656 - val_loss: 40569.0703 - val_mae: 40569.0703\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 40351.6992 - mae: 40351.6992 - val_loss: 40522.6797 - val_mae: 40522.6797\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 40023.1328 - mae: 40023.1328 - val_loss: 39961.7812 - val_mae: 39961.7812\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 39626.4844 - mae: 39626.4844 - val_loss: 39588.9023 - val_mae: 39588.9023\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 39334.8945 - mae: 39334.8945 - val_loss: 39204.5156 - val_mae: 39204.5156\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 38996.0234 - mae: 38996.0234 - val_loss: 38885.7031 - val_mae: 38885.7031\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 38656.2070 - mae: 38656.2070 - val_loss: 38560.6445 - val_mae: 38560.6445\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 38321.8281 - mae: 38321.8281 - val_loss: 38271.9453 - val_mae: 38271.9453\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 38072.0273 - mae: 38072.0273 - val_loss: 37968.1758 - val_mae: 37968.1758\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 37698.9961 - mae: 37698.9961 - val_loss: 37533.6953 - val_mae: 37533.6953\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 37381.1562 - mae: 37381.1562 - val_loss: 37204.1094 - val_mae: 37204.1094\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 37044.1836 - mae: 37044.1836 - val_loss: 36922.3906 - val_mae: 36922.3906\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 36700.0703 - mae: 36700.0703 - val_loss: 36526.5859 - val_mae: 36526.5859\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 36391.3320 - mae: 36391.3320 - val_loss: 36208.4883 - val_mae: 36208.4883\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 36051.6992 - mae: 36051.6992 - val_loss: 35845.1328 - val_mae: 35845.1328\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 35722.8867 - mae: 35722.8867 - val_loss: 35561.3750 - val_mae: 35561.3750\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 35431.4453 - mae: 35431.4453 - val_loss: 35247.2344 - val_mae: 35247.2344\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 35207.4727 - mae: 35207.4727 - val_loss: 34982.0547 - val_mae: 34982.0547\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 34933.4023 - mae: 34933.4023 - val_loss: 34735.8047 - val_mae: 34735.8047\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 34557.6836 - mae: 34557.6836 - val_loss: 34434.9102 - val_mae: 34434.9102\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 34350.7344 - mae: 34350.7344 - val_loss: 34149.5664 - val_mae: 34149.5664\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 34066.1602 - mae: 34066.1602 - val_loss: 33926.5625 - val_mae: 33926.5625\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 33825.3750 - mae: 33825.3750 - val_loss: 33657.9336 - val_mae: 33657.9336\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 33571.2539 - mae: 33571.2539 - val_loss: 33437.3477 - val_mae: 33437.3477\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 33352.5977 - mae: 33352.5977 - val_loss: 33185.0586 - val_mae: 33185.0586\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 33115.3789 - mae: 33115.3789 - val_loss: 32960.3086 - val_mae: 32960.3086\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 32920.3750 - mae: 32920.3750 - val_loss: 32764.9785 - val_mae: 32764.9785\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 32706.6953 - mae: 32706.6953 - val_loss: 32517.5762 - val_mae: 32517.5762\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 32468.8496 - mae: 32468.8496 - val_loss: 32319.7773 - val_mae: 32319.7773\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 32266.0449 - mae: 32266.0449 - val_loss: 32140.8867 - val_mae: 32140.8867\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 32091.6582 - mae: 32091.6582 - val_loss: 31930.4082 - val_mae: 31930.4082\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 31816.0781 - mae: 31816.0781 - val_loss: 31755.5684 - val_mae: 31755.5684\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 31642.3730 - mae: 31642.3730 - val_loss: 31587.5449 - val_mae: 31587.5449\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 31453.0996 - mae: 31453.0996 - val_loss: 31432.1582 - val_mae: 31432.1582\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 31254.5000 - mae: 31254.5000 - val_loss: 31268.6602 - val_mae: 31268.6602\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 31097.8145 - mae: 31097.8145 - val_loss: 31146.5234 - val_mae: 31146.5234\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 30943.6367 - mae: 30943.6367 - val_loss: 31004.5586 - val_mae: 31004.5586\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 30781.3828 - mae: 30781.3828 - val_loss: 30834.6445 - val_mae: 30834.6445\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 30602.7188 - mae: 30602.7188 - val_loss: 30738.7051 - val_mae: 30738.7051\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 30431.8633 - mae: 30431.8633 - val_loss: 30586.8320 - val_mae: 30586.8320\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 30269.0684 - mae: 30269.0684 - val_loss: 30440.4238 - val_mae: 30440.4238\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 30174.8555 - mae: 30174.8555 - val_loss: 30309.7324 - val_mae: 30309.7324\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29948.2676 - mae: 29948.2676 - val_loss: 30214.2500 - val_mae: 30214.2500\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29818.2148 - mae: 29818.2148 - val_loss: 30052.6738 - val_mae: 30052.6738\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29688.5410 - mae: 29688.5410 - val_loss: 29925.7734 - val_mae: 29925.7734\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29565.4375 - mae: 29565.4375 - val_loss: 29825.0762 - val_mae: 29825.0762\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29591.0488 - mae: 29591.0488 - val_loss: 29738.5312 - val_mae: 29738.5312\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29639.3496 - mae: 29639.3496 - val_loss: 29685.2324 - val_mae: 29685.2324\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 29323.4180 - mae: 29323.4180 - val_loss: 29746.4453 - val_mae: 29746.4453\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29182.5234 - mae: 29182.5234 - val_loss: 29466.2012 - val_mae: 29466.2012\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 29006.2422 - mae: 29006.2422 - val_loss: 29466.1309 - val_mae: 29466.1309\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 28876.1406 - mae: 28876.1406 - val_loss: 29265.6992 - val_mae: 29265.6992\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28788.6230 - mae: 28788.6230 - val_loss: 29191.1445 - val_mae: 29191.1445\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28648.3750 - mae: 28648.3750 - val_loss: 29081.8770 - val_mae: 29081.8770\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28606.1484 - mae: 28606.1484 - val_loss: 28992.7871 - val_mae: 28992.7871\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28466.9180 - mae: 28466.9180 - val_loss: 28964.2715 - val_mae: 28964.2715\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28452.5723 - mae: 28452.5723 - val_loss: 28810.5625 - val_mae: 28810.5625\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28331.5410 - mae: 28331.5410 - val_loss: 28823.0957 - val_mae: 28823.0957\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 28162.7715 - mae: 28162.7715 - val_loss: 28632.5840 - val_mae: 28632.5840\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28064.5352 - mae: 28064.5352 - val_loss: 28636.8047 - val_mae: 28636.8047\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 27974.9395 - mae: 27974.9395 - val_loss: 28531.5859 - val_mae: 28531.5859\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 27951.4824 - mae: 27951.4824 - val_loss: 28448.9238 - val_mae: 28448.9238\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 28165.4082 - mae: 28165.4082 - val_loss: 28306.7207 - val_mae: 28306.7207\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 27723.8691 - mae: 27723.8691 - val_loss: 28354.8418 - val_mae: 28354.8418\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 27629.9531 - mae: 27629.9531 - val_loss: 28133.7676 - val_mae: 28133.7676\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 27527.6797 - mae: 27527.6797 - val_loss: 28149.9590 - val_mae: 28149.9590\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 27458.3027 - mae: 27458.3027 - val_loss: 27957.0332 - val_mae: 27957.0332\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 27326.2715 - mae: 27326.2715 - val_loss: 28031.4277 - val_mae: 28031.4277\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 27426.1289 - mae: 27426.1289 - val_loss: 27841.4570 - val_mae: 27841.4570\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 27169.5781 - mae: 27169.5781 - val_loss: 27795.5859 - val_mae: 27795.5859\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 27067.2344 - mae: 27067.2344 - val_loss: 27776.8262 - val_mae: 27776.8262\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 27017.7480 - mae: 27017.7480 - val_loss: 27625.6699 - val_mae: 27625.6699\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 26935.8477 - mae: 26935.8477 - val_loss: 27605.6660 - val_mae: 27605.6660\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26837.6172 - mae: 26837.6172 - val_loss: 27511.2129 - val_mae: 27511.2129\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26751.8809 - mae: 26751.8809 - val_loss: 27473.7832 - val_mae: 27473.7832\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 26657.0156 - mae: 26657.0156 - val_loss: 27419.4004 - val_mae: 27419.4004\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26585.4141 - mae: 26585.4141 - val_loss: 27250.1309 - val_mae: 27250.1309\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26544.3262 - mae: 26544.3262 - val_loss: 27230.9004 - val_mae: 27230.9004\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 26517.5801 - mae: 26517.5801 - val_loss: 27204.5957 - val_mae: 27204.5957\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26338.9785 - mae: 26338.9785 - val_loss: 27042.4668 - val_mae: 27042.4668\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26402.0586 - mae: 26402.0586 - val_loss: 26998.7539 - val_mae: 26998.7539\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26187.3730 - mae: 26187.3730 - val_loss: 26882.6660 - val_mae: 26882.6660\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 26180.9668 - mae: 26180.9668 - val_loss: 26820.1875 - val_mae: 26820.1875\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26136.4180 - mae: 26136.4180 - val_loss: 26801.0508 - val_mae: 26801.0508\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 26001.8477 - mae: 26001.8477 - val_loss: 26783.9297 - val_mae: 26783.9297\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 25959.5215 - mae: 25959.5215 - val_loss: 26710.7070 - val_mae: 26710.7070\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 25842.3965 - mae: 25842.3965 - val_loss: 26641.3594 - val_mae: 26641.3594\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 25725.0859 - mae: 25725.0859 - val_loss: 26599.1914 - val_mae: 26599.1914\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25660.6797 - mae: 25660.6797 - val_loss: 26444.9023 - val_mae: 26444.9023\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25611.2520 - mae: 25611.2520 - val_loss: 26403.9355 - val_mae: 26403.9355\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 25683.9941 - mae: 25683.9941 - val_loss: 26404.6934 - val_mae: 26404.6934\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 25454.7793 - mae: 25454.7793 - val_loss: 26185.1621 - val_mae: 26185.1621\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 25463.5879 - mae: 25463.5879 - val_loss: 26299.5957 - val_mae: 26299.5957\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25285.9785 - mae: 25285.9785 - val_loss: 26043.7852 - val_mae: 26043.7852\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25208.3223 - mae: 25208.3223 - val_loss: 26219.8535 - val_mae: 26219.8535\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25120.5801 - mae: 25120.5801 - val_loss: 25916.5488 - val_mae: 25916.5488\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25117.7148 - mae: 25117.7148 - val_loss: 25975.8848 - val_mae: 25975.8848\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 24991.1855 - mae: 24991.1855 - val_loss: 25911.7422 - val_mae: 25911.7422\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24977.1484 - mae: 24977.1484 - val_loss: 25749.3496 - val_mae: 25749.3496\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 25091.9648 - mae: 25091.9648 - val_loss: 25657.1680 - val_mae: 25657.1680\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24804.9414 - mae: 24804.9414 - val_loss: 25730.2637 - val_mae: 25730.2637\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24828.5723 - mae: 24828.5723 - val_loss: 25487.2285 - val_mae: 25487.2285\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24622.4785 - mae: 24622.4785 - val_loss: 25588.7617 - val_mae: 25588.7617\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24573.8223 - mae: 24573.8223 - val_loss: 25360.7949 - val_mae: 25360.7949\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24518.2949 - mae: 24518.2949 - val_loss: 25354.3691 - val_mae: 25354.3691\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24465.7871 - mae: 24465.7871 - val_loss: 25334.1855 - val_mae: 25334.1855\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24370.6035 - mae: 24370.6035 - val_loss: 25229.3848 - val_mae: 25229.3848\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 24279.9062 - mae: 24279.9062 - val_loss: 25109.0703 - val_mae: 25109.0703\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24349.9766 - mae: 24349.9766 - val_loss: 25062.5762 - val_mae: 25062.5762\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24137.4570 - mae: 24137.4570 - val_loss: 25052.0879 - val_mae: 25052.0879\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 24064.2520 - mae: 24064.2520 - val_loss: 24981.1992 - val_mae: 24981.1992\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23990.7656 - mae: 23990.7656 - val_loss: 24921.1426 - val_mae: 24921.1426\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23921.6465 - mae: 23921.6465 - val_loss: 24978.9629 - val_mae: 24978.9629\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23856.6465 - mae: 23856.6465 - val_loss: 24705.9863 - val_mae: 24705.9863\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23933.3203 - mae: 23933.3203 - val_loss: 25032.4551 - val_mae: 25032.4551\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 23920.5410 - mae: 23920.5410 - val_loss: 24564.6367 - val_mae: 24564.6367\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23798.7988 - mae: 23798.7988 - val_loss: 24682.1523 - val_mae: 24682.1523\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23634.7285 - mae: 23634.7285 - val_loss: 24460.2910 - val_mae: 24460.2910\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23650.7441 - mae: 23650.7441 - val_loss: 24562.1035 - val_mae: 24562.1035\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 23534.6758 - mae: 23534.6758 - val_loss: 24477.4297 - val_mae: 24477.4297\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23450.5156 - mae: 23450.5156 - val_loss: 24323.4512 - val_mae: 24323.4512\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 23365.9902 - mae: 23365.9902 - val_loss: 24273.2441 - val_mae: 24273.2441\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23300.4160 - mae: 23300.4160 - val_loss: 24252.7480 - val_mae: 24252.7480\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23279.6465 - mae: 23279.6465 - val_loss: 24360.5605 - val_mae: 24360.5605\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23386.8828 - mae: 23386.8828 - val_loss: 24058.6309 - val_mae: 24058.6309\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23162.6875 - mae: 23162.6875 - val_loss: 24127.6367 - val_mae: 24127.6367\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23134.9238 - mae: 23134.9238 - val_loss: 24061.5977 - val_mae: 24061.5977\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23139.3398 - mae: 23139.3398 - val_loss: 23885.1621 - val_mae: 23885.1621\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23128.7891 - mae: 23128.7891 - val_loss: 24035.6875 - val_mae: 24035.6875\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22974.7578 - mae: 22974.7578 - val_loss: 23730.6602 - val_mae: 23730.6602\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 23210.2012 - mae: 23210.2012 - val_loss: 23823.5723 - val_mae: 23823.5723\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22865.4922 - mae: 22865.4922 - val_loss: 23747.8379 - val_mae: 23747.8379\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 22820.0352 - mae: 22820.0352 - val_loss: 23576.4570 - val_mae: 23576.4570\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 22789.0938 - mae: 22789.0938 - val_loss: 23847.5293 - val_mae: 23847.5293\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22760.9863 - mae: 22760.9863 - val_loss: 23474.8945 - val_mae: 23474.8945\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22881.2812 - mae: 22881.2812 - val_loss: 23969.6855 - val_mae: 23969.6855\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23194.3359 - mae: 23194.3359 - val_loss: 23318.9062 - val_mae: 23318.9062\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 23021.6230 - mae: 23021.6230 - val_loss: 23517.0645 - val_mae: 23517.0645\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 22489.3828 - mae: 22489.3828 - val_loss: 23348.9961 - val_mae: 23348.9961\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22484.2383 - mae: 22484.2383 - val_loss: 23318.7383 - val_mae: 23318.7383\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22441.3242 - mae: 22441.3242 - val_loss: 23257.4492 - val_mae: 23257.4492\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22412.8398 - mae: 22412.8398 - val_loss: 23267.6309 - val_mae: 23267.6309\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22351.7344 - mae: 22351.7344 - val_loss: 23177.0840 - val_mae: 23177.0840\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22288.6504 - mae: 22288.6504 - val_loss: 23333.5156 - val_mae: 23333.5156\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22320.5703 - mae: 22320.5703 - val_loss: 22970.1406 - val_mae: 22970.1406\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 22387.2344 - mae: 22387.2344 - val_loss: 23301.7246 - val_mae: 23301.7246\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22151.3477 - mae: 22151.3477 - val_loss: 22877.9414 - val_mae: 22877.9414\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22164.7168 - mae: 22164.7168 - val_loss: 23049.4414 - val_mae: 23049.4414\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22182.8789 - mae: 22182.8789 - val_loss: 22978.0801 - val_mae: 22978.0801\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 22131.2402 - mae: 22131.2402 - val_loss: 22791.0801 - val_mae: 22791.0801\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22035.6094 - mae: 22035.6094 - val_loss: 22883.4160 - val_mae: 22883.4160\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21987.9766 - mae: 21987.9766 - val_loss: 22867.7715 - val_mae: 22867.7715\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21962.3086 - mae: 21962.3086 - val_loss: 22977.6191 - val_mae: 22977.6191\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21969.7734 - mae: 21969.7734 - val_loss: 22894.0801 - val_mae: 22894.0801\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21880.3398 - mae: 21880.3398 - val_loss: 22733.4668 - val_mae: 22733.4668\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21840.0859 - mae: 21840.0859 - val_loss: 22982.7129 - val_mae: 22982.7129\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21857.5957 - mae: 21857.5957 - val_loss: 22529.9102 - val_mae: 22529.9102\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21779.3184 - mae: 21779.3184 - val_loss: 22762.9746 - val_mae: 22762.9746\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21761.6152 - mae: 21761.6152 - val_loss: 22396.4570 - val_mae: 22396.4570\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 21945.1914 - mae: 21945.1914 - val_loss: 22687.8398 - val_mae: 22687.8398\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21953.0273 - mae: 21953.0273 - val_loss: 22525.1328 - val_mae: 22525.1328\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 21667.6133 - mae: 21667.6133 - val_loss: 22686.5625 - val_mae: 22686.5625\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21734.4336 - mae: 21734.4336 - val_loss: 22224.9551 - val_mae: 22224.9551\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21799.1328 - mae: 21799.1328 - val_loss: 22362.8672 - val_mae: 22362.8672\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21745.8613 - mae: 21745.8613 - val_loss: 22284.6309 - val_mae: 22284.6309\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21509.5449 - mae: 21509.5449 - val_loss: 22360.7285 - val_mae: 22360.7285\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21543.2285 - mae: 21543.2285 - val_loss: 22157.4277 - val_mae: 22157.4277\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21493.4355 - mae: 21493.4355 - val_loss: 22407.0195 - val_mae: 22407.0195\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21436.2266 - mae: 21436.2266 - val_loss: 22061.5684 - val_mae: 22061.5684\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 21426.3613 - mae: 21426.3613 - val_loss: 22478.3672 - val_mae: 22478.3672\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21523.4648 - mae: 21523.4648 - val_loss: 21979.8535 - val_mae: 21979.8535\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21407.8320 - mae: 21407.8320 - val_loss: 22277.4941 - val_mae: 22277.4941\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21343.4551 - mae: 21343.4551 - val_loss: 22047.1094 - val_mae: 22047.1094\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 21327.5664 - mae: 21327.5664 - val_loss: 22033.4688 - val_mae: 22033.4688\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21263.1602 - mae: 21263.1602 - val_loss: 22067.5215 - val_mae: 22067.5215\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21233.7051 - mae: 21233.7051 - val_loss: 22080.7559 - val_mae: 22080.7559\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21204.4414 - mae: 21204.4414 - val_loss: 21986.7578 - val_mae: 21986.7578\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21194.0781 - mae: 21194.0781 - val_loss: 21819.1758 - val_mae: 21819.1758\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 21253.1152 - mae: 21253.1152 - val_loss: 22035.3223 - val_mae: 22035.3223\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21214.7988 - mae: 21214.7988 - val_loss: 21783.0449 - val_mae: 21783.0449\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21247.8125 - mae: 21247.8125 - val_loss: 22055.7617 - val_mae: 22055.7617\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21118.2285 - mae: 21118.2285 - val_loss: 21820.8047 - val_mae: 21820.8047\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21137.1094 - mae: 21137.1094 - val_loss: 21767.6055 - val_mae: 21767.6055\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21045.5059 - mae: 21045.5059 - val_loss: 21851.2559 - val_mae: 21851.2559\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 21024.4102 - mae: 21024.4102 - val_loss: 21802.3809 - val_mae: 21802.3809\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20991.2910 - mae: 20991.2910 - val_loss: 22008.2207 - val_mae: 22008.2207\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21023.8672 - mae: 21023.8672 - val_loss: 21561.9102 - val_mae: 21561.9102\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 21244.0508 - mae: 21244.0508 - val_loss: 21988.2129 - val_mae: 21988.2129\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 21088.7637 - mae: 21088.7637 - val_loss: 21553.4219 - val_mae: 21553.4219\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20947.5352 - mae: 20947.5352 - val_loss: 21988.6504 - val_mae: 21988.6504\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20936.1758 - mae: 20936.1758 - val_loss: 21713.1328 - val_mae: 21713.1328\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20857.4316 - mae: 20857.4316 - val_loss: 21657.0625 - val_mae: 21657.0625\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20833.7773 - mae: 20833.7773 - val_loss: 21781.8926 - val_mae: 21781.8926\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20844.7578 - mae: 20844.7578 - val_loss: 21700.4590 - val_mae: 21700.4590\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20807.4160 - mae: 20807.4160 - val_loss: 21886.8789 - val_mae: 21886.8789\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20889.8457 - mae: 20889.8457 - val_loss: 21584.7598 - val_mae: 21584.7598\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20773.5781 - mae: 20773.5781 - val_loss: 21565.7734 - val_mae: 21565.7734\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20747.5664 - mae: 20747.5664 - val_loss: 21771.9375 - val_mae: 21771.9375\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20841.7207 - mae: 20841.7207 - val_loss: 21397.0352 - val_mae: 21397.0352\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 20821.1641 - mae: 20821.1641 - val_loss: 21726.5332 - val_mae: 21726.5332\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20737.5000 - mae: 20737.5000 - val_loss: 21409.6465 - val_mae: 21409.6465\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20708.7012 - mae: 20708.7012 - val_loss: 21380.4375 - val_mae: 21380.4375\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20648.8047 - mae: 20648.8047 - val_loss: 21434.0625 - val_mae: 21434.0625\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 20614.8008 - mae: 20614.8008 - val_loss: 21348.7090 - val_mae: 21348.7090\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20669.9961 - mae: 20669.9961 - val_loss: 21506.8340 - val_mae: 21506.8340\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20645.9980 - mae: 20645.9980 - val_loss: 21209.4746 - val_mae: 21209.4746\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20544.6602 - mae: 20544.6602 - val_loss: 21585.2031 - val_mae: 21585.2031\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20599.2656 - mae: 20599.2656 - val_loss: 21211.6465 - val_mae: 21211.6465\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 20505.8184 - mae: 20505.8184 - val_loss: 21411.9180 - val_mae: 21411.9180\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20470.1230 - mae: 20470.1230 - val_loss: 21261.6133 - val_mae: 21261.6133\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 20505.5039 - mae: 20505.5039 - val_loss: 21246.2930 - val_mae: 21246.2930\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20462.2676 - mae: 20462.2676 - val_loss: 21364.5215 - val_mae: 21364.5215\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20462.4160 - mae: 20462.4160 - val_loss: 21202.7207 - val_mae: 21202.7207\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20408.9844 - mae: 20408.9844 - val_loss: 21514.3359 - val_mae: 21514.3359\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20462.0410 - mae: 20462.0410 - val_loss: 21130.6035 - val_mae: 21130.6035\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20396.8223 - mae: 20396.8223 - val_loss: 21212.1016 - val_mae: 21212.1016\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20349.5781 - mae: 20349.5781 - val_loss: 21112.8125 - val_mae: 21112.8125\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20347.0840 - mae: 20347.0840 - val_loss: 21250.5625 - val_mae: 21250.5625\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20312.4785 - mae: 20312.4785 - val_loss: 21097.4219 - val_mae: 21097.4219\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20301.9746 - mae: 20301.9746 - val_loss: 21204.1602 - val_mae: 21204.1602\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20281.2285 - mae: 20281.2285 - val_loss: 21096.4023 - val_mae: 21096.4023\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 20292.0078 - mae: 20292.0078 - val_loss: 20970.8594 - val_mae: 20970.8594\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20463.8906 - mae: 20463.8906 - val_loss: 21578.7559 - val_mae: 21578.7559\n",
      "Epoch 287/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20449.2871 - mae: 20449.2871 - val_loss: 20920.6172 - val_mae: 20920.6172\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20296.6934 - mae: 20296.6934 - val_loss: 21108.1250 - val_mae: 21108.1250\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20249.9297 - mae: 20249.9297 - val_loss: 20945.1582 - val_mae: 20945.1582\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20305.2422 - mae: 20305.2422 - val_loss: 21243.8477 - val_mae: 21243.8477\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20187.7520 - mae: 20187.7520 - val_loss: 20980.2852 - val_mae: 20980.2852\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 20184.0820 - mae: 20184.0820 - val_loss: 21222.8457 - val_mae: 21222.8457\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20230.8672 - mae: 20230.8672 - val_loss: 20961.2070 - val_mae: 20961.2070\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 20160.1289 - mae: 20160.1289 - val_loss: 21004.4883 - val_mae: 21004.4883\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 20153.2441 - mae: 20153.2441 - val_loss: 20869.2051 - val_mae: 20869.2051\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20195.7207 - mae: 20195.7207 - val_loss: 21151.6035 - val_mae: 21151.6035\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 20168.4707 - mae: 20168.4707 - val_loss: 20914.9961 - val_mae: 20914.9961\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 20191.2520 - mae: 20191.2520 - val_loss: 20875.8984 - val_mae: 20875.8984\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 20078.2109 - mae: 20078.2109 - val_loss: 21273.6289 - val_mae: 21273.6289\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 20388.9102 - mae: 20388.9102 - val_loss: 20733.9727 - val_mae: 20733.9727\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=300, batch_size=128, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [180913.625, 179407.296875, 176144.71875, 170638.4375, 162450.390625, 151254.375, 136865.546875, 119189.4375, 98469.9296875, 76824.75, 60042.90234375, 53975.94921875, 53312.45703125, 53221.66796875, 52978.7890625, 52686.375, 52462.83984375, 52323.09765625, 52152.5703125, 51923.8515625, 51736.64453125, 51532.46875, 51345.72265625, 51108.94140625, 50912.43359375, 50736.875, 50497.53515625, 50326.40625, 50099.3828125, 49858.4296875, 49631.55078125, 49417.34765625, 49315.72265625, 49004.53125, 48734.76171875, 48535.76171875, 48273.04296875, 48047.41796875, 47811.48828125, 47571.31640625, 47323.59765625, 47057.30859375, 46794.4375, 46536.421875, 46265.76171875, 46006.43359375, 45740.82421875, 45505.44140625, 45214.26953125, 44914.015625, 44634.22265625, 44337.44140625, 44046.8125, 43759.3515625, 43449.45703125, 43121.5, 42858.2109375, 42586.83984375, 42284.65625, 41951.640625, 41603.796875, 41265.60546875, 40938.86328125, 40605.765625, 40351.69921875, 40023.1328125, 39626.484375, 39334.89453125, 38996.0234375, 38656.20703125, 38321.828125, 38072.02734375, 37698.99609375, 37381.15625, 37044.18359375, 36700.0703125, 36391.33203125, 36051.69921875, 35722.88671875, 35431.4453125, 35207.47265625, 34933.40234375, 34557.68359375, 34350.734375, 34066.16015625, 33825.375, 33571.25390625, 33352.59765625, 33115.37890625, 32920.375, 32706.6953125, 32468.849609375, 32266.044921875, 32091.658203125, 31816.078125, 31642.373046875, 31453.099609375, 31254.5, 31097.814453125, 30943.63671875, 30781.3828125, 30602.71875, 30431.86328125, 30269.068359375, 30174.85546875, 29948.267578125, 29818.21484375, 29688.541015625, 29565.4375, 29591.048828125, 29639.349609375, 29323.41796875, 29182.5234375, 29006.2421875, 28876.140625, 28788.623046875, 28648.375, 28606.1484375, 28466.91796875, 28452.572265625, 28331.541015625, 28162.771484375, 28064.53515625, 27974.939453125, 27951.482421875, 28165.408203125, 27723.869140625, 27629.953125, 27527.6796875, 27458.302734375, 27326.271484375, 27426.12890625, 27169.578125, 27067.234375, 27017.748046875, 26935.84765625, 26837.6171875, 26751.880859375, 26657.015625, 26585.4140625, 26544.326171875, 26517.580078125, 26338.978515625, 26402.05859375, 26187.373046875, 26180.966796875, 26136.41796875, 26001.84765625, 25959.521484375, 25842.396484375, 25725.0859375, 25660.6796875, 25611.251953125, 25683.994140625, 25454.779296875, 25463.587890625, 25285.978515625, 25208.322265625, 25120.580078125, 25117.71484375, 24991.185546875, 24977.1484375, 25091.96484375, 24804.94140625, 24828.572265625, 24622.478515625, 24573.822265625, 24518.294921875, 24465.787109375, 24370.603515625, 24279.90625, 24349.9765625, 24137.45703125, 24064.251953125, 23990.765625, 23921.646484375, 23856.646484375, 23933.3203125, 23920.541015625, 23798.798828125, 23634.728515625, 23650.744140625, 23534.67578125, 23450.515625, 23365.990234375, 23300.416015625, 23279.646484375, 23386.8828125, 23162.6875, 23134.923828125, 23139.33984375, 23128.7890625, 22974.7578125, 23210.201171875, 22865.4921875, 22820.03515625, 22789.09375, 22760.986328125, 22881.28125, 23194.3359375, 23021.623046875, 22489.3828125, 22484.23828125, 22441.32421875, 22412.83984375, 22351.734375, 22288.650390625, 22320.5703125, 22387.234375, 22151.34765625, 22164.716796875, 22182.87890625, 22131.240234375, 22035.609375, 21987.9765625, 21962.30859375, 21969.7734375, 21880.33984375, 21840.0859375, 21857.595703125, 21779.318359375, 21761.615234375, 21945.19140625, 21953.02734375, 21667.61328125, 21734.43359375, 21799.1328125, 21745.861328125, 21509.544921875, 21543.228515625, 21493.435546875, 21436.2265625, 21426.361328125, 21523.46484375, 21407.83203125, 21343.455078125, 21327.56640625, 21263.16015625, 21233.705078125, 21204.44140625, 21194.078125, 21253.115234375, 21214.798828125, 21247.8125, 21118.228515625, 21137.109375, 21045.505859375, 21024.41015625, 20991.291015625, 21023.8671875, 21244.05078125, 21088.763671875, 20947.53515625, 20936.17578125, 20857.431640625, 20833.77734375, 20844.7578125, 20807.416015625, 20889.845703125, 20773.578125, 20747.56640625, 20841.720703125, 20821.1640625, 20737.5, 20708.701171875, 20648.8046875, 20614.80078125, 20669.99609375, 20645.998046875, 20544.66015625, 20599.265625, 20505.818359375, 20470.123046875, 20505.50390625, 20462.267578125, 20462.416015625, 20408.984375, 20462.041015625, 20396.822265625, 20349.578125, 20347.083984375, 20312.478515625, 20301.974609375, 20281.228515625, 20292.0078125, 20463.890625, 20449.287109375, 20296.693359375, 20249.9296875, 20305.2421875, 20187.751953125, 20184.08203125, 20230.8671875, 20160.12890625, 20153.244140625, 20195.720703125, 20168.470703125, 20191.251953125, 20078.2109375, 20388.91015625], 'mae': [180913.625, 179407.296875, 176144.71875, 170638.4375, 162450.390625, 151254.375, 136865.546875, 119189.4375, 98469.9296875, 76824.75, 60042.90234375, 53975.94921875, 53312.45703125, 53221.66796875, 52978.7890625, 52686.375, 52462.83984375, 52323.09765625, 52152.5703125, 51923.8515625, 51736.64453125, 51532.46875, 51345.72265625, 51108.94140625, 50912.43359375, 50736.875, 50497.53515625, 50326.40625, 50099.3828125, 49858.4296875, 49631.55078125, 49417.34765625, 49315.72265625, 49004.53125, 48734.76171875, 48535.76171875, 48273.04296875, 48047.41796875, 47811.48828125, 47571.31640625, 47323.59765625, 47057.30859375, 46794.4375, 46536.421875, 46265.76171875, 46006.43359375, 45740.82421875, 45505.44140625, 45214.26953125, 44914.015625, 44634.22265625, 44337.44140625, 44046.8125, 43759.3515625, 43449.45703125, 43121.5, 42858.2109375, 42586.83984375, 42284.65625, 41951.640625, 41603.796875, 41265.60546875, 40938.86328125, 40605.765625, 40351.69921875, 40023.1328125, 39626.484375, 39334.89453125, 38996.0234375, 38656.20703125, 38321.828125, 38072.02734375, 37698.99609375, 37381.15625, 37044.18359375, 36700.0703125, 36391.33203125, 36051.69921875, 35722.88671875, 35431.4453125, 35207.47265625, 34933.40234375, 34557.68359375, 34350.734375, 34066.16015625, 33825.375, 33571.25390625, 33352.59765625, 33115.37890625, 32920.375, 32706.6953125, 32468.849609375, 32266.044921875, 32091.658203125, 31816.078125, 31642.373046875, 31453.099609375, 31254.5, 31097.814453125, 30943.63671875, 30781.3828125, 30602.71875, 30431.86328125, 30269.068359375, 30174.85546875, 29948.267578125, 29818.21484375, 29688.541015625, 29565.4375, 29591.048828125, 29639.349609375, 29323.41796875, 29182.5234375, 29006.2421875, 28876.140625, 28788.623046875, 28648.375, 28606.1484375, 28466.91796875, 28452.572265625, 28331.541015625, 28162.771484375, 28064.53515625, 27974.939453125, 27951.482421875, 28165.408203125, 27723.869140625, 27629.953125, 27527.6796875, 27458.302734375, 27326.271484375, 27426.12890625, 27169.578125, 27067.234375, 27017.748046875, 26935.84765625, 26837.6171875, 26751.880859375, 26657.015625, 26585.4140625, 26544.326171875, 26517.580078125, 26338.978515625, 26402.05859375, 26187.373046875, 26180.966796875, 26136.41796875, 26001.84765625, 25959.521484375, 25842.396484375, 25725.0859375, 25660.6796875, 25611.251953125, 25683.994140625, 25454.779296875, 25463.587890625, 25285.978515625, 25208.322265625, 25120.580078125, 25117.71484375, 24991.185546875, 24977.1484375, 25091.96484375, 24804.94140625, 24828.572265625, 24622.478515625, 24573.822265625, 24518.294921875, 24465.787109375, 24370.603515625, 24279.90625, 24349.9765625, 24137.45703125, 24064.251953125, 23990.765625, 23921.646484375, 23856.646484375, 23933.3203125, 23920.541015625, 23798.798828125, 23634.728515625, 23650.744140625, 23534.67578125, 23450.515625, 23365.990234375, 23300.416015625, 23279.646484375, 23386.8828125, 23162.6875, 23134.923828125, 23139.33984375, 23128.7890625, 22974.7578125, 23210.201171875, 22865.4921875, 22820.03515625, 22789.09375, 22760.986328125, 22881.28125, 23194.3359375, 23021.623046875, 22489.3828125, 22484.23828125, 22441.32421875, 22412.83984375, 22351.734375, 22288.650390625, 22320.5703125, 22387.234375, 22151.34765625, 22164.716796875, 22182.87890625, 22131.240234375, 22035.609375, 21987.9765625, 21962.30859375, 21969.7734375, 21880.33984375, 21840.0859375, 21857.595703125, 21779.318359375, 21761.615234375, 21945.19140625, 21953.02734375, 21667.61328125, 21734.43359375, 21799.1328125, 21745.861328125, 21509.544921875, 21543.228515625, 21493.435546875, 21436.2265625, 21426.361328125, 21523.46484375, 21407.83203125, 21343.455078125, 21327.56640625, 21263.16015625, 21233.705078125, 21204.44140625, 21194.078125, 21253.115234375, 21214.798828125, 21247.8125, 21118.228515625, 21137.109375, 21045.505859375, 21024.41015625, 20991.291015625, 21023.8671875, 21244.05078125, 21088.763671875, 20947.53515625, 20936.17578125, 20857.431640625, 20833.77734375, 20844.7578125, 20807.416015625, 20889.845703125, 20773.578125, 20747.56640625, 20841.720703125, 20821.1640625, 20737.5, 20708.701171875, 20648.8046875, 20614.80078125, 20669.99609375, 20645.998046875, 20544.66015625, 20599.265625, 20505.818359375, 20470.123046875, 20505.50390625, 20462.267578125, 20462.416015625, 20408.984375, 20462.041015625, 20396.822265625, 20349.578125, 20347.083984375, 20312.478515625, 20301.974609375, 20281.228515625, 20292.0078125, 20463.890625, 20449.287109375, 20296.693359375, 20249.9296875, 20305.2421875, 20187.751953125, 20184.08203125, 20230.8671875, 20160.12890625, 20153.244140625, 20195.720703125, 20168.470703125, 20191.251953125, 20078.2109375, 20388.91015625], 'val_loss': [178931.390625, 176457.21875, 171923.03125, 164868.765625, 154920.390625, 141815.828125, 125432.2578125, 105772.0234375, 84500.5390625, 65816.53125, 56052.859375, 54398.1796875, 54178.7109375, 53990.74609375, 53802.40234375, 53626.4921875, 53446.43359375, 53314.875, 53105.734375, 52821.15234375, 52589.99609375, 52361.484375, 52132.85546875, 51944.72265625, 51813.71875, 51525.296875, 51280.8203125, 50986.16015625, 50825.02734375, 50570.9375, 50352.203125, 50100.3671875, 49793.48828125, 49612.2890625, 49396.65625, 49155.0546875, 48827.5, 48579.1484375, 48354.1328125, 48133.59375, 47793.31640625, 47502.9140625, 47266.1796875, 46938.4375, 46627.1796875, 46358.39453125, 46046.3359375, 45741.48046875, 45444.3359375, 45148.24609375, 44823.90234375, 44545.30859375, 44211.640625, 43887.87890625, 43632.0546875, 43234.94921875, 42946.03515625, 42526.51953125, 42214.47265625, 42135.9609375, 41651.4921875, 41223.16015625, 40892.08984375, 40569.0703125, 40522.6796875, 39961.78125, 39588.90234375, 39204.515625, 38885.703125, 38560.64453125, 38271.9453125, 37968.17578125, 37533.6953125, 37204.109375, 36922.390625, 36526.5859375, 36208.48828125, 35845.1328125, 35561.375, 35247.234375, 34982.0546875, 34735.8046875, 34434.91015625, 34149.56640625, 33926.5625, 33657.93359375, 33437.34765625, 33185.05859375, 32960.30859375, 32764.978515625, 32517.576171875, 32319.77734375, 32140.88671875, 31930.408203125, 31755.568359375, 31587.544921875, 31432.158203125, 31268.66015625, 31146.5234375, 31004.55859375, 30834.64453125, 30738.705078125, 30586.83203125, 30440.423828125, 30309.732421875, 30214.25, 30052.673828125, 29925.7734375, 29825.076171875, 29738.53125, 29685.232421875, 29746.4453125, 29466.201171875, 29466.130859375, 29265.69921875, 29191.14453125, 29081.876953125, 28992.787109375, 28964.271484375, 28810.5625, 28823.095703125, 28632.583984375, 28636.8046875, 28531.5859375, 28448.923828125, 28306.720703125, 28354.841796875, 28133.767578125, 28149.958984375, 27957.033203125, 28031.427734375, 27841.45703125, 27795.5859375, 27776.826171875, 27625.669921875, 27605.666015625, 27511.212890625, 27473.783203125, 27419.400390625, 27250.130859375, 27230.900390625, 27204.595703125, 27042.466796875, 26998.75390625, 26882.666015625, 26820.1875, 26801.05078125, 26783.9296875, 26710.70703125, 26641.359375, 26599.19140625, 26444.90234375, 26403.935546875, 26404.693359375, 26185.162109375, 26299.595703125, 26043.78515625, 26219.853515625, 25916.548828125, 25975.884765625, 25911.7421875, 25749.349609375, 25657.16796875, 25730.263671875, 25487.228515625, 25588.76171875, 25360.794921875, 25354.369140625, 25334.185546875, 25229.384765625, 25109.0703125, 25062.576171875, 25052.087890625, 24981.19921875, 24921.142578125, 24978.962890625, 24705.986328125, 25032.455078125, 24564.63671875, 24682.15234375, 24460.291015625, 24562.103515625, 24477.4296875, 24323.451171875, 24273.244140625, 24252.748046875, 24360.560546875, 24058.630859375, 24127.63671875, 24061.59765625, 23885.162109375, 24035.6875, 23730.66015625, 23823.572265625, 23747.837890625, 23576.45703125, 23847.529296875, 23474.89453125, 23969.685546875, 23318.90625, 23517.064453125, 23348.99609375, 23318.73828125, 23257.44921875, 23267.630859375, 23177.083984375, 23333.515625, 22970.140625, 23301.724609375, 22877.94140625, 23049.44140625, 22978.080078125, 22791.080078125, 22883.416015625, 22867.771484375, 22977.619140625, 22894.080078125, 22733.466796875, 22982.712890625, 22529.91015625, 22762.974609375, 22396.45703125, 22687.83984375, 22525.1328125, 22686.5625, 22224.955078125, 22362.8671875, 22284.630859375, 22360.728515625, 22157.427734375, 22407.01953125, 22061.568359375, 22478.3671875, 21979.853515625, 22277.494140625, 22047.109375, 22033.46875, 22067.521484375, 22080.755859375, 21986.7578125, 21819.17578125, 22035.322265625, 21783.044921875, 22055.76171875, 21820.8046875, 21767.60546875, 21851.255859375, 21802.380859375, 22008.220703125, 21561.91015625, 21988.212890625, 21553.421875, 21988.650390625, 21713.1328125, 21657.0625, 21781.892578125, 21700.458984375, 21886.87890625, 21584.759765625, 21565.7734375, 21771.9375, 21397.03515625, 21726.533203125, 21409.646484375, 21380.4375, 21434.0625, 21348.708984375, 21506.833984375, 21209.474609375, 21585.203125, 21211.646484375, 21411.91796875, 21261.61328125, 21246.29296875, 21364.521484375, 21202.720703125, 21514.3359375, 21130.603515625, 21212.1015625, 21112.8125, 21250.5625, 21097.421875, 21204.16015625, 21096.40234375, 20970.859375, 21578.755859375, 20920.6171875, 21108.125, 20945.158203125, 21243.84765625, 20980.28515625, 21222.845703125, 20961.20703125, 21004.48828125, 20869.205078125, 21151.603515625, 20914.99609375, 20875.8984375, 21273.62890625, 20733.97265625], 'val_mae': [178931.390625, 176457.21875, 171923.03125, 164868.765625, 154920.390625, 141815.828125, 125432.2578125, 105772.0234375, 84500.5390625, 65816.53125, 56052.859375, 54398.1796875, 54178.7109375, 53990.74609375, 53802.40234375, 53626.4921875, 53446.43359375, 53314.875, 53105.734375, 52821.15234375, 52589.99609375, 52361.484375, 52132.85546875, 51944.72265625, 51813.71875, 51525.296875, 51280.8203125, 50986.16015625, 50825.02734375, 50570.9375, 50352.203125, 50100.3671875, 49793.48828125, 49612.2890625, 49396.65625, 49155.0546875, 48827.5, 48579.1484375, 48354.1328125, 48133.59375, 47793.31640625, 47502.9140625, 47266.1796875, 46938.4375, 46627.1796875, 46358.39453125, 46046.3359375, 45741.48046875, 45444.3359375, 45148.24609375, 44823.90234375, 44545.30859375, 44211.640625, 43887.87890625, 43632.0546875, 43234.94921875, 42946.0390625, 42526.51953125, 42214.47265625, 42135.9609375, 41651.4921875, 41223.16015625, 40892.08984375, 40569.0703125, 40522.6796875, 39961.78125, 39588.90234375, 39204.515625, 38885.703125, 38560.64453125, 38271.9453125, 37968.17578125, 37533.6953125, 37204.109375, 36922.390625, 36526.5859375, 36208.48828125, 35845.1328125, 35561.375, 35247.234375, 34982.0546875, 34735.8046875, 34434.91015625, 34149.56640625, 33926.5625, 33657.93359375, 33437.34765625, 33185.05859375, 32960.30859375, 32764.978515625, 32517.576171875, 32319.77734375, 32140.88671875, 31930.408203125, 31755.568359375, 31587.544921875, 31432.158203125, 31268.66015625, 31146.5234375, 31004.55859375, 30834.64453125, 30738.705078125, 30586.83203125, 30440.423828125, 30309.732421875, 30214.25, 30052.673828125, 29925.7734375, 29825.076171875, 29738.53125, 29685.232421875, 29746.4453125, 29466.201171875, 29466.130859375, 29265.69921875, 29191.14453125, 29081.876953125, 28992.787109375, 28964.271484375, 28810.5625, 28823.095703125, 28632.583984375, 28636.8046875, 28531.5859375, 28448.923828125, 28306.720703125, 28354.841796875, 28133.767578125, 28149.958984375, 27957.033203125, 28031.427734375, 27841.45703125, 27795.5859375, 27776.826171875, 27625.669921875, 27605.666015625, 27511.212890625, 27473.783203125, 27419.400390625, 27250.130859375, 27230.900390625, 27204.595703125, 27042.466796875, 26998.75390625, 26882.666015625, 26820.1875, 26801.05078125, 26783.9296875, 26710.70703125, 26641.359375, 26599.19140625, 26444.90234375, 26403.935546875, 26404.693359375, 26185.162109375, 26299.595703125, 26043.78515625, 26219.853515625, 25916.548828125, 25975.884765625, 25911.7421875, 25749.349609375, 25657.16796875, 25730.263671875, 25487.228515625, 25588.76171875, 25360.794921875, 25354.369140625, 25334.185546875, 25229.384765625, 25109.0703125, 25062.576171875, 25052.087890625, 24981.19921875, 24921.142578125, 24978.962890625, 24705.986328125, 25032.455078125, 24564.63671875, 24682.15234375, 24460.291015625, 24562.103515625, 24477.4296875, 24323.451171875, 24273.244140625, 24252.748046875, 24360.560546875, 24058.630859375, 24127.63671875, 24061.59765625, 23885.162109375, 24035.6875, 23730.66015625, 23823.572265625, 23747.837890625, 23576.45703125, 23847.529296875, 23474.89453125, 23969.685546875, 23318.90625, 23517.064453125, 23348.99609375, 23318.73828125, 23257.44921875, 23267.630859375, 23177.083984375, 23333.515625, 22970.140625, 23301.724609375, 22877.94140625, 23049.44140625, 22978.080078125, 22791.080078125, 22883.416015625, 22867.771484375, 22977.619140625, 22894.080078125, 22733.466796875, 22982.712890625, 22529.91015625, 22762.974609375, 22396.45703125, 22687.83984375, 22525.1328125, 22686.5625, 22224.955078125, 22362.8671875, 22284.630859375, 22360.728515625, 22157.427734375, 22407.01953125, 22061.568359375, 22478.3671875, 21979.853515625, 22277.494140625, 22047.109375, 22033.46875, 22067.521484375, 22080.755859375, 21986.7578125, 21819.17578125, 22035.322265625, 21783.044921875, 22055.76171875, 21820.8046875, 21767.60546875, 21851.255859375, 21802.380859375, 22008.220703125, 21561.91015625, 21988.212890625, 21553.421875, 21988.650390625, 21713.1328125, 21657.0625, 21781.892578125, 21700.458984375, 21886.87890625, 21584.759765625, 21565.7734375, 21771.9375, 21397.03515625, 21726.533203125, 21409.646484375, 21380.4375, 21434.0625, 21348.708984375, 21506.833984375, 21209.474609375, 21585.203125, 21211.646484375, 21411.91796875, 21261.61328125, 21246.29296875, 21364.521484375, 21202.720703125, 21514.3359375, 21130.603515625, 21212.1015625, 21112.8125, 21250.5625, 21097.421875, 21204.16015625, 21096.40234375, 20970.859375, 21578.755859375, 20920.6171875, 21108.125, 20945.158203125, 21243.84765625, 20980.28515625, 21222.845703125, 20961.20703125, 21004.48828125, 20869.205078125, 21151.603515625, 20914.99609375, 20875.8984375, 21273.62890625, 20733.97265625]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('epoch')\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения незначительно улучшились!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление нейронов на начальном слое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь увеличить количество нейронов на входном слое с 16 до 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='linear'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "random.set_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.05),\n",
    "              loss='mae',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 1s 10ms/step - loss: 167899.7969 - mae: 167899.7969 - val_loss: 133323.6406 - val_mae: 133323.6406\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 80744.1562 - mae: 80744.1562 - val_loss: 55496.6094 - val_mae: 55496.6094\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 53149.1602 - mae: 53149.1602 - val_loss: 53053.7930 - val_mae: 53053.7930\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 51412.7930 - mae: 51412.7930 - val_loss: 51650.5859 - val_mae: 51650.5859\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 50021.3281 - mae: 50021.3281 - val_loss: 49993.4414 - val_mae: 49993.4414\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 48621.5820 - mae: 48621.5820 - val_loss: 48298.2617 - val_mae: 48298.2617\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 46946.4336 - mae: 46946.4336 - val_loss: 46511.2930 - val_mae: 46511.2930\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 45216.7578 - mae: 45216.7578 - val_loss: 44586.9453 - val_mae: 44586.9453\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 43431.7891 - mae: 43431.7891 - val_loss: 42500.1797 - val_mae: 42500.1797\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 41500.7109 - mae: 41500.7109 - val_loss: 40529.4180 - val_mae: 40529.4180\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 39603.1133 - mae: 39603.1133 - val_loss: 38598.5508 - val_mae: 38598.5508\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 37541.1211 - mae: 37541.1211 - val_loss: 37358.4453 - val_mae: 37358.4453\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 36249.8008 - mae: 36249.8008 - val_loss: 34662.4102 - val_mae: 34662.4102\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 34414.0273 - mae: 34414.0273 - val_loss: 33227.5859 - val_mae: 33227.5859\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 33133.5039 - mae: 33133.5039 - val_loss: 32062.9277 - val_mae: 32062.9277\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 31938.5898 - mae: 31938.5898 - val_loss: 31332.4824 - val_mae: 31332.4824\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 30811.8262 - mae: 30811.8262 - val_loss: 30626.2734 - val_mae: 30626.2734\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 30149.6465 - mae: 30149.6465 - val_loss: 29901.5488 - val_mae: 29901.5488\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 29872.4141 - mae: 29872.4141 - val_loss: 29356.8691 - val_mae: 29356.8691\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 29042.5000 - mae: 29042.5000 - val_loss: 29039.2812 - val_mae: 29039.2812\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 28602.6836 - mae: 28602.6836 - val_loss: 28455.6816 - val_mae: 28455.6816\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 27863.5840 - mae: 27863.5840 - val_loss: 28186.3828 - val_mae: 28186.3828\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 27568.7051 - mae: 27568.7051 - val_loss: 27988.5918 - val_mae: 27988.5918\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 27001.9922 - mae: 27001.9922 - val_loss: 27298.4414 - val_mae: 27298.4414\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 26461.2480 - mae: 26461.2480 - val_loss: 26905.7910 - val_mae: 26905.7910\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 26369.2324 - mae: 26369.2324 - val_loss: 26485.5176 - val_mae: 26485.5176\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 25964.4570 - mae: 25964.4570 - val_loss: 26783.1680 - val_mae: 26783.1680\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 25430.1738 - mae: 25430.1738 - val_loss: 25710.2773 - val_mae: 25710.2773\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 25222.9512 - mae: 25222.9512 - val_loss: 26043.1602 - val_mae: 26043.1602\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 24699.2051 - mae: 24699.2051 - val_loss: 25011.9902 - val_mae: 25011.9902\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 24225.3066 - mae: 24225.3066 - val_loss: 24794.5312 - val_mae: 24794.5312\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23933.5488 - mae: 23933.5488 - val_loss: 24582.6152 - val_mae: 24582.6152\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23598.6055 - mae: 23598.6055 - val_loss: 24119.7871 - val_mae: 24119.7871\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23641.0352 - mae: 23641.0352 - val_loss: 23819.0547 - val_mae: 23819.0547\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23397.2148 - mae: 23397.2148 - val_loss: 23508.8613 - val_mae: 23508.8613\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22728.0723 - mae: 22728.0723 - val_loss: 23936.0078 - val_mae: 23936.0078\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22677.9316 - mae: 22677.9316 - val_loss: 23993.8516 - val_mae: 23993.8516\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22472.6133 - mae: 22472.6133 - val_loss: 23898.5000 - val_mae: 23898.5000\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22278.5488 - mae: 22278.5488 - val_loss: 22885.6836 - val_mae: 22885.6836\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21929.8066 - mae: 21929.8066 - val_loss: 22818.7949 - val_mae: 22818.7949\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21809.9766 - mae: 21809.9766 - val_loss: 22238.0293 - val_mae: 22238.0293\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22242.2812 - mae: 22242.2812 - val_loss: 22144.9648 - val_mae: 22144.9648\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21474.0234 - mae: 21474.0234 - val_loss: 21864.0820 - val_mae: 21864.0820\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21882.6426 - mae: 21882.6426 - val_loss: 21863.0762 - val_mae: 21863.0762\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21385.1738 - mae: 21385.1738 - val_loss: 21831.1465 - val_mae: 21831.1465\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21195.0488 - mae: 21195.0488 - val_loss: 21515.9727 - val_mae: 21515.9727\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21178.2852 - mae: 21178.2852 - val_loss: 21477.4785 - val_mae: 21477.4785\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21016.6035 - mae: 21016.6035 - val_loss: 21641.5566 - val_mae: 21641.5566\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20838.4375 - mae: 20838.4375 - val_loss: 21494.0586 - val_mae: 21494.0586\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20926.0527 - mae: 20926.0527 - val_loss: 21392.7637 - val_mae: 21392.7637\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20685.2539 - mae: 20685.2539 - val_loss: 21696.1836 - val_mae: 21696.1836\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20701.5645 - mae: 20701.5645 - val_loss: 21081.0840 - val_mae: 21081.0840\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20619.1602 - mae: 20619.1602 - val_loss: 20866.1484 - val_mae: 20866.1484\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20821.7871 - mae: 20821.7871 - val_loss: 20821.6035 - val_mae: 20821.6035\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20360.3398 - mae: 20360.3398 - val_loss: 21004.5742 - val_mae: 21004.5742\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20525.9297 - mae: 20525.9297 - val_loss: 22305.8809 - val_mae: 22305.8809\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20642.0625 - mae: 20642.0625 - val_loss: 21797.7090 - val_mae: 21797.7090\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20827.6855 - mae: 20827.6855 - val_loss: 21175.0605 - val_mae: 21175.0605\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20277.0547 - mae: 20277.0547 - val_loss: 21485.4512 - val_mae: 21485.4512\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20126.3613 - mae: 20126.3613 - val_loss: 20594.1992 - val_mae: 20594.1992\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20166.5742 - mae: 20166.5742 - val_loss: 20558.6406 - val_mae: 20558.6406\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20025.5918 - mae: 20025.5918 - val_loss: 20592.6875 - val_mae: 20592.6875\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20152.2734 - mae: 20152.2734 - val_loss: 20302.2754 - val_mae: 20302.2754\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20003.5020 - mae: 20003.5020 - val_loss: 21079.3184 - val_mae: 21079.3184\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20042.8770 - mae: 20042.8770 - val_loss: 20272.5020 - val_mae: 20272.5020\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19954.2012 - mae: 19954.2012 - val_loss: 20330.6973 - val_mae: 20330.6973\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19961.0586 - mae: 19961.0586 - val_loss: 21001.2324 - val_mae: 21001.2324\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20192.7285 - mae: 20192.7285 - val_loss: 20433.4824 - val_mae: 20433.4824\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20347.6504 - mae: 20347.6504 - val_loss: 20255.6562 - val_mae: 20255.6562\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20046.5625 - mae: 20046.5625 - val_loss: 20127.7598 - val_mae: 20127.7598\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19694.8496 - mae: 19694.8496 - val_loss: 20077.2012 - val_mae: 20077.2012\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19709.1973 - mae: 19709.1973 - val_loss: 20232.4219 - val_mae: 20232.4219\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19791.6016 - mae: 19791.6016 - val_loss: 20008.5176 - val_mae: 20008.5176\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19678.8574 - mae: 19678.8574 - val_loss: 20069.7012 - val_mae: 20069.7012\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19577.5469 - mae: 19577.5469 - val_loss: 20281.8691 - val_mae: 20281.8691\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19823.1367 - mae: 19823.1367 - val_loss: 20249.3535 - val_mae: 20249.3535\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19742.0820 - mae: 19742.0820 - val_loss: 19885.3242 - val_mae: 19885.3242\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19620.9004 - mae: 19620.9004 - val_loss: 19914.9961 - val_mae: 19914.9961\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19593.0215 - mae: 19593.0215 - val_loss: 19825.9805 - val_mae: 19825.9805\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19525.8496 - mae: 19525.8496 - val_loss: 19797.8848 - val_mae: 19797.8848\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19486.3125 - mae: 19486.3125 - val_loss: 19916.4219 - val_mae: 19916.4219\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19496.3379 - mae: 19496.3379 - val_loss: 19780.4023 - val_mae: 19780.4023\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19638.3574 - mae: 19638.3574 - val_loss: 20065.1465 - val_mae: 20065.1465\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19908.7285 - mae: 19908.7285 - val_loss: 19640.3477 - val_mae: 19640.3477\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19480.0684 - mae: 19480.0684 - val_loss: 19601.0938 - val_mae: 19601.0938\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19408.0723 - mae: 19408.0723 - val_loss: 19687.4766 - val_mae: 19687.4766\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19377.9922 - mae: 19377.9922 - val_loss: 19653.5371 - val_mae: 19653.5371\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19315.9043 - mae: 19315.9043 - val_loss: 19794.2422 - val_mae: 19794.2422\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19319.7500 - mae: 19319.7500 - val_loss: 19996.7910 - val_mae: 19996.7910\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19287.1738 - mae: 19287.1738 - val_loss: 19557.7168 - val_mae: 19557.7168\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19290.1348 - mae: 19290.1348 - val_loss: 20786.6426 - val_mae: 20786.6426\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19394.5020 - mae: 19394.5020 - val_loss: 19823.4180 - val_mae: 19823.4180\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19504.7871 - mae: 19504.7871 - val_loss: 19889.7832 - val_mae: 19889.7832\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19485.1406 - mae: 19485.1406 - val_loss: 19547.5098 - val_mae: 19547.5098\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19098.8828 - mae: 19098.8828 - val_loss: 19368.0352 - val_mae: 19368.0352\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19389.0859 - mae: 19389.0859 - val_loss: 19945.9961 - val_mae: 19945.9961\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 19110.8418 - mae: 19110.8418 - val_loss: 19319.6602 - val_mae: 19319.6602\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19169.0234 - mae: 19169.0234 - val_loss: 20144.2148 - val_mae: 20144.2148\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19114.5723 - mae: 19114.5723 - val_loss: 19849.6074 - val_mae: 19849.6074\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19047.0156 - mae: 19047.0156 - val_loss: 19272.9082 - val_mae: 19272.9082\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [167899.796875, 80744.15625, 53149.16015625, 51412.79296875, 50021.328125, 48621.58203125, 46946.43359375, 45216.7578125, 43431.7890625, 41500.7109375, 39603.11328125, 37541.12109375, 36249.80078125, 34414.02734375, 33133.50390625, 31938.58984375, 30811.826171875, 30149.646484375, 29872.4140625, 29042.5, 28602.68359375, 27863.583984375, 27568.705078125, 27001.9921875, 26461.248046875, 26369.232421875, 25964.45703125, 25430.173828125, 25222.951171875, 24699.205078125, 24225.306640625, 23933.548828125, 23598.60546875, 23641.03515625, 23397.21484375, 22728.072265625, 22677.931640625, 22472.61328125, 22278.548828125, 21929.806640625, 21809.9765625, 22242.28125, 21474.0234375, 21882.642578125, 21385.173828125, 21195.048828125, 21178.28515625, 21016.603515625, 20838.4375, 20926.052734375, 20685.25390625, 20701.564453125, 20619.16015625, 20821.787109375, 20360.33984375, 20525.9296875, 20642.0625, 20827.685546875, 20277.0546875, 20126.361328125, 20166.57421875, 20025.591796875, 20152.2734375, 20003.501953125, 20042.876953125, 19954.201171875, 19961.05859375, 20192.728515625, 20347.650390625, 20046.5625, 19694.849609375, 19709.197265625, 19791.6015625, 19678.857421875, 19577.546875, 19823.13671875, 19742.08203125, 19620.900390625, 19593.021484375, 19525.849609375, 19486.3125, 19496.337890625, 19638.357421875, 19908.728515625, 19480.068359375, 19408.072265625, 19377.9921875, 19315.904296875, 19319.75, 19287.173828125, 19290.134765625, 19394.501953125, 19504.787109375, 19485.140625, 19098.8828125, 19389.0859375, 19110.841796875, 19169.0234375, 19114.572265625, 19047.015625], 'mae': [167899.796875, 80744.15625, 53149.16015625, 51412.79296875, 50021.328125, 48621.58203125, 46946.43359375, 45216.7578125, 43431.7890625, 41500.7109375, 39603.11328125, 37541.12109375, 36249.80078125, 34414.02734375, 33133.50390625, 31938.58984375, 30811.826171875, 30149.646484375, 29872.4140625, 29042.5, 28602.68359375, 27863.583984375, 27568.705078125, 27001.9921875, 26461.248046875, 26369.232421875, 25964.45703125, 25430.173828125, 25222.951171875, 24699.205078125, 24225.306640625, 23933.548828125, 23598.60546875, 23641.03515625, 23397.21484375, 22728.072265625, 22677.931640625, 22472.61328125, 22278.548828125, 21929.806640625, 21809.9765625, 22242.28125, 21474.0234375, 21882.642578125, 21385.173828125, 21195.048828125, 21178.28515625, 21016.603515625, 20838.4375, 20926.052734375, 20685.25390625, 20701.564453125, 20619.16015625, 20821.787109375, 20360.33984375, 20525.9296875, 20642.0625, 20827.685546875, 20277.0546875, 20126.361328125, 20166.57421875, 20025.591796875, 20152.2734375, 20003.501953125, 20042.876953125, 19954.201171875, 19961.05859375, 20192.728515625, 20347.650390625, 20046.5625, 19694.849609375, 19709.197265625, 19791.6015625, 19678.857421875, 19577.546875, 19823.13671875, 19742.08203125, 19620.900390625, 19593.021484375, 19525.849609375, 19486.3125, 19496.337890625, 19638.357421875, 19908.728515625, 19480.068359375, 19408.072265625, 19377.9921875, 19315.904296875, 19319.75, 19287.173828125, 19290.134765625, 19394.501953125, 19504.787109375, 19485.140625, 19098.8828125, 19389.0859375, 19110.841796875, 19169.0234375, 19114.572265625, 19047.015625], 'val_loss': [133323.640625, 55496.609375, 53053.79296875, 51650.5859375, 49993.44140625, 48298.26171875, 46511.29296875, 44586.9453125, 42500.1796875, 40529.41796875, 38598.55078125, 37358.4453125, 34662.41015625, 33227.5859375, 32062.927734375, 31332.482421875, 30626.2734375, 29901.548828125, 29356.869140625, 29039.28125, 28455.681640625, 28186.3828125, 27988.591796875, 27298.44140625, 26905.791015625, 26485.517578125, 26783.16796875, 25710.27734375, 26043.16015625, 25011.990234375, 24794.53125, 24582.615234375, 24119.787109375, 23819.0546875, 23508.861328125, 23936.0078125, 23993.8515625, 23898.5, 22885.68359375, 22818.794921875, 22238.029296875, 22144.96484375, 21864.08203125, 21863.076171875, 21831.146484375, 21515.97265625, 21477.478515625, 21641.556640625, 21494.05859375, 21392.763671875, 21696.18359375, 21081.083984375, 20866.1484375, 20821.603515625, 21004.57421875, 22305.880859375, 21797.708984375, 21175.060546875, 21485.451171875, 20594.19921875, 20558.640625, 20592.6875, 20302.275390625, 21079.318359375, 20272.501953125, 20330.697265625, 21001.232421875, 20433.482421875, 20255.65625, 20127.759765625, 20077.201171875, 20232.421875, 20008.517578125, 20069.701171875, 20281.869140625, 20249.353515625, 19885.32421875, 19914.99609375, 19825.98046875, 19797.884765625, 19916.421875, 19780.40234375, 20065.146484375, 19640.34765625, 19601.09375, 19687.4765625, 19653.537109375, 19794.2421875, 19996.791015625, 19557.716796875, 20786.642578125, 19823.41796875, 19889.783203125, 19547.509765625, 19368.03515625, 19945.99609375, 19319.66015625, 20144.21484375, 19849.607421875, 19272.908203125], 'val_mae': [133323.640625, 55496.609375, 53053.79296875, 51650.5859375, 49993.44140625, 48298.26171875, 46511.29296875, 44586.9453125, 42500.1796875, 40529.41796875, 38598.55078125, 37358.4453125, 34662.41015625, 33227.5859375, 32062.927734375, 31332.482421875, 30626.2734375, 29901.548828125, 29356.869140625, 29039.28125, 28455.681640625, 28186.3828125, 27988.591796875, 27298.44140625, 26905.791015625, 26485.517578125, 26783.16796875, 25710.27734375, 26043.16015625, 25011.990234375, 24794.53125, 24582.615234375, 24119.787109375, 23819.0546875, 23508.861328125, 23936.0078125, 23993.8515625, 23898.5, 22885.68359375, 22818.794921875, 22238.029296875, 22144.96484375, 21864.08203125, 21863.076171875, 21831.146484375, 21515.97265625, 21477.478515625, 21641.556640625, 21494.05859375, 21392.763671875, 21696.18359375, 21081.083984375, 20866.1484375, 20821.603515625, 21004.57421875, 22305.880859375, 21797.708984375, 21175.060546875, 21485.451171875, 20594.19921875, 20558.640625, 20592.6875, 20302.275390625, 21079.318359375, 20272.501953125, 20330.697265625, 21001.232421875, 20433.482421875, 20255.65625, 20127.759765625, 20077.201171875, 20232.421875, 20008.517578125, 20069.701171875, 20281.869140625, 20249.353515625, 19885.32421875, 19914.99609375, 19825.98046875, 19797.884765625, 19916.421875, 19780.40234375, 20065.146484375, 19640.34765625, 19601.09375, 19687.4765625, 19653.537109375, 19794.2421875, 19996.791015625, 19557.716796875, 20786.642578125, 19823.41796875, 19889.783203125, 19547.509765625, 19368.03515625, 19945.99609375, 19319.66015625, 20144.21484375, 19849.607421875, 19272.908203125]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel('value')\n",
    "plt.xlabel('epoch')\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель стала сложнее, но начала давать лучшие результаты (однако больше - не всегда лучше, ведь, увеличия сложность модели, мы увеличиваем и количество времени, нужное на обучение, а также склоняем к переобучению)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление скрытого слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в нашу модель скрытый слой с 64 нейронами и линейной функцией активации `relu`, отсекающей отрицательные значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='linear'),\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "random.set_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.05),\n",
    "              loss='mae',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "12/12 [==============================] - 1s 19ms/step - loss: 172725.8438 - mae: 172725.8438 - val_loss: 134872.9375 - val_mae: 134872.9375\n",
      "Epoch 2/75\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 84424.8359 - mae: 84424.8359 - val_loss: 66311.6797 - val_mae: 66311.6719\n",
      "Epoch 3/75\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 58895.6836 - mae: 58895.6836 - val_loss: 53333.4062 - val_mae: 53333.4062\n",
      "Epoch 4/75\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 53099.6680 - mae: 53099.6680 - val_loss: 52270.5000 - val_mae: 52270.5000\n",
      "Epoch 5/75\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 50493.0312 - mae: 50493.0312 - val_loss: 49780.2148 - val_mae: 49780.2148\n",
      "Epoch 6/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 48188.8750 - mae: 48188.8750 - val_loss: 46549.9453 - val_mae: 46549.9453\n",
      "Epoch 7/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 45204.4688 - mae: 45204.4688 - val_loss: 44227.4375 - val_mae: 44227.4375\n",
      "Epoch 8/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42273.6914 - mae: 42273.6914 - val_loss: 40593.6719 - val_mae: 40593.6719\n",
      "Epoch 9/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 38816.7734 - mae: 38816.7734 - val_loss: 36552.0977 - val_mae: 36552.0977\n",
      "Epoch 10/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 35364.9766 - mae: 35364.9805 - val_loss: 33020.4688 - val_mae: 33020.4688\n",
      "Epoch 11/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32377.3223 - mae: 32377.3223 - val_loss: 30987.3281 - val_mae: 30987.3281\n",
      "Epoch 12/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 30493.2852 - mae: 30493.2852 - val_loss: 30185.1270 - val_mae: 30185.1270\n",
      "Epoch 13/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 29469.0449 - mae: 29469.0449 - val_loss: 28729.2676 - val_mae: 28729.2676\n",
      "Epoch 14/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28401.6074 - mae: 28401.6074 - val_loss: 28451.1445 - val_mae: 28451.1445\n",
      "Epoch 15/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26933.2852 - mae: 26933.2852 - val_loss: 26756.0898 - val_mae: 26756.0898\n",
      "Epoch 16/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 26724.7188 - mae: 26724.7188 - val_loss: 26116.4082 - val_mae: 26116.4082\n",
      "Epoch 17/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25775.4316 - mae: 25775.4316 - val_loss: 28582.7539 - val_mae: 28582.7539\n",
      "Epoch 18/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24974.2188 - mae: 24974.2188 - val_loss: 24238.2930 - val_mae: 24238.2930\n",
      "Epoch 19/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25199.6191 - mae: 25199.6191 - val_loss: 24984.1543 - val_mae: 24984.1543\n",
      "Epoch 20/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 24520.0215 - mae: 24520.0215 - val_loss: 24509.9160 - val_mae: 24509.9160\n",
      "Epoch 21/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 22958.4082 - mae: 22958.4082 - val_loss: 22680.3906 - val_mae: 22680.3906\n",
      "Epoch 22/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 22092.6133 - mae: 22092.6133 - val_loss: 22305.4160 - val_mae: 22305.4160\n",
      "Epoch 23/75\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 21905.4199 - mae: 21905.4199 - val_loss: 21846.2402 - val_mae: 21846.2402\n",
      "Epoch 24/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21788.7656 - mae: 21788.7656 - val_loss: 22034.6562 - val_mae: 22034.6562\n",
      "Epoch 25/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21405.2324 - mae: 21405.2324 - val_loss: 21265.6309 - val_mae: 21265.6309\n",
      "Epoch 26/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 21179.4805 - mae: 21179.4805 - val_loss: 21530.5645 - val_mae: 21530.5645\n",
      "Epoch 27/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21440.1309 - mae: 21440.1309 - val_loss: 21282.1172 - val_mae: 21282.1172\n",
      "Epoch 28/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20831.2500 - mae: 20831.2500 - val_loss: 20768.5898 - val_mae: 20768.5898\n",
      "Epoch 29/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 20272.8965 - mae: 20272.8965 - val_loss: 20991.6172 - val_mae: 20991.6172\n",
      "Epoch 30/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 20339.9434 - mae: 20339.9434 - val_loss: 20979.0605 - val_mae: 20979.0605\n",
      "Epoch 31/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20198.0762 - mae: 20198.0762 - val_loss: 22389.6504 - val_mae: 22389.6504\n",
      "Epoch 32/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20910.3398 - mae: 20910.3398 - val_loss: 23059.8535 - val_mae: 23059.8535\n",
      "Epoch 33/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 21228.7715 - mae: 21228.7715 - val_loss: 22408.5957 - val_mae: 22408.5957\n",
      "Epoch 34/75\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 21422.2715 - mae: 21422.2715 - val_loss: 20232.1348 - val_mae: 20232.1348\n",
      "Epoch 35/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 20634.5137 - mae: 20634.5137 - val_loss: 20187.9609 - val_mae: 20187.9609\n",
      "Epoch 36/75\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 20624.3535 - mae: 20624.3535 - val_loss: 20030.6328 - val_mae: 20030.6328\n",
      "Epoch 37/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19806.7539 - mae: 19806.7539 - val_loss: 20272.3828 - val_mae: 20272.3828\n",
      "Epoch 38/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20067.0039 - mae: 20067.0059 - val_loss: 21075.3320 - val_mae: 21075.3320\n",
      "Epoch 39/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19930.2480 - mae: 19930.2480 - val_loss: 20540.4375 - val_mae: 20540.4395\n",
      "Epoch 40/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19557.7559 - mae: 19557.7559 - val_loss: 20653.0449 - val_mae: 20653.0469\n",
      "Epoch 41/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19830.2676 - mae: 19830.2676 - val_loss: 19939.6094 - val_mae: 19939.6094\n",
      "Epoch 42/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19684.0293 - mae: 19684.0273 - val_loss: 19838.3770 - val_mae: 19838.3770\n",
      "Epoch 43/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19913.7070 - mae: 19913.7070 - val_loss: 19733.6602 - val_mae: 19733.6602\n",
      "Epoch 44/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 20037.3203 - mae: 20037.3203 - val_loss: 19690.5762 - val_mae: 19690.5762\n",
      "Epoch 45/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19371.2422 - mae: 19371.2422 - val_loss: 19657.8398 - val_mae: 19657.8398\n",
      "Epoch 46/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19593.9766 - mae: 19593.9766 - val_loss: 19869.1172 - val_mae: 19869.1172\n",
      "Epoch 47/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19776.2148 - mae: 19776.2148 - val_loss: 19413.5215 - val_mae: 19413.5234\n",
      "Epoch 48/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19869.6777 - mae: 19869.6777 - val_loss: 19370.5625 - val_mae: 19370.5625\n",
      "Epoch 49/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19763.1582 - mae: 19763.1582 - val_loss: 19491.3887 - val_mae: 19491.3887\n",
      "Epoch 50/75\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 19259.0117 - mae: 19259.0117 - val_loss: 19822.1582 - val_mae: 19822.1582\n",
      "Epoch 51/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19155.6289 - mae: 19155.6289 - val_loss: 19762.2480 - val_mae: 19762.2480\n",
      "Epoch 52/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19465.1895 - mae: 19465.1875 - val_loss: 19825.6465 - val_mae: 19825.6465\n",
      "Epoch 53/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 20306.1309 - mae: 20306.1309 - val_loss: 19661.1875 - val_mae: 19661.1875\n",
      "Epoch 54/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19300.2090 - mae: 19300.2090 - val_loss: 19213.2305 - val_mae: 19213.2305\n",
      "Epoch 55/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19186.0957 - mae: 19186.0957 - val_loss: 19377.3203 - val_mae: 19377.3203\n",
      "Epoch 56/75\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19092.4902 - mae: 19092.4902 - val_loss: 20060.0000 - val_mae: 20060.0000\n",
      "Epoch 57/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 20041.1230 - mae: 20041.1230 - val_loss: 21491.4922 - val_mae: 21491.4922\n",
      "Epoch 58/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19531.1328 - mae: 19531.1348 - val_loss: 21151.0664 - val_mae: 21151.0664\n",
      "Epoch 59/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19083.1992 - mae: 19083.1973 - val_loss: 20339.2129 - val_mae: 20339.2129\n",
      "Epoch 60/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18857.6035 - mae: 18857.6035 - val_loss: 18938.0059 - val_mae: 18938.0059\n",
      "Epoch 61/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18884.7910 - mae: 18884.7910 - val_loss: 19173.4102 - val_mae: 19173.4102\n",
      "Epoch 62/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18711.4453 - mae: 18711.4453 - val_loss: 18962.1660 - val_mae: 18962.1660\n",
      "Epoch 63/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18957.4785 - mae: 18957.4785 - val_loss: 18871.7402 - val_mae: 18871.7402\n",
      "Epoch 64/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18995.5078 - mae: 18995.5078 - val_loss: 20306.1504 - val_mae: 20306.1504\n",
      "Epoch 65/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19659.4473 - mae: 19659.4473 - val_loss: 18913.7188 - val_mae: 18913.7188\n",
      "Epoch 66/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19034.2305 - mae: 19034.2305 - val_loss: 18762.7051 - val_mae: 18762.7051\n",
      "Epoch 67/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18755.2715 - mae: 18755.2715 - val_loss: 19832.2891 - val_mae: 19832.2891\n",
      "Epoch 68/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18994.0547 - mae: 18994.0547 - val_loss: 18769.6113 - val_mae: 18769.6113\n",
      "Epoch 69/75\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 21204.2793 - mae: 21204.2793 - val_loss: 19290.2871 - val_mae: 19290.2871\n",
      "Epoch 70/75\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 18995.8789 - mae: 18995.8789 - val_loss: 19254.4785 - val_mae: 19254.4785\n",
      "Epoch 71/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18768.8125 - mae: 18768.8125 - val_loss: 18601.5840 - val_mae: 18601.5820\n",
      "Epoch 72/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18994.3906 - mae: 18994.3906 - val_loss: 19217.0371 - val_mae: 19217.0371\n",
      "Epoch 73/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 18793.9727 - mae: 18793.9707 - val_loss: 18640.5410 - val_mae: 18640.5410\n",
      "Epoch 74/75\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 19033.6543 - mae: 19033.6543 - val_loss: 19105.6484 - val_mae: 19105.6484\n",
      "Epoch 75/75\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 19191.3086 - mae: 19191.3086 - val_loss: 19012.6855 - val_mae: 19012.6855\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=75, batch_size=100, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В принципе ошибка осталась на прежнем уровне. Посмотрим, что можно сделать ещё!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимизаторы и функции потерь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого мы использовали универсальный и достаточно эффективный оптимизатор `Adam`, посмотрим, что изменится, если мы сменим его на `Adamax`, модификацию предыдущего (модель оставим при этом прежней, по сути задев только часть с её обучением):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='linear'),\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "random.set_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "model.compile(optimizer=Adamax(learning_rate=0.05),\n",
    "              loss='mae',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 1s 11ms/step - loss: 126226.4922 - mae: 126226.4922 - val_loss: 65264.0469 - val_mae: 65264.0469\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 53084.8906 - mae: 53084.8906 - val_loss: 51884.8008 - val_mae: 51884.8008\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 49935.4883 - mae: 49935.4883 - val_loss: 48272.0938 - val_mae: 48272.0938\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 46463.8203 - mae: 46463.8203 - val_loss: 44705.0664 - val_mae: 44705.0664\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 43053.5508 - mae: 43053.5508 - val_loss: 40329.5977 - val_mae: 40329.5977\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 38405.2344 - mae: 38405.2344 - val_loss: 35475.9258 - val_mae: 35475.9258\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 33907.8789 - mae: 33907.8789 - val_loss: 31783.5000 - val_mae: 31783.5000\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 31368.1230 - mae: 31368.1230 - val_loss: 30286.6445 - val_mae: 30286.6445\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 30123.6367 - mae: 30123.6367 - val_loss: 30036.0488 - val_mae: 30036.0488\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 28989.1602 - mae: 28989.1602 - val_loss: 28605.7148 - val_mae: 28605.7148\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 27995.3145 - mae: 27995.3145 - val_loss: 29203.1055 - val_mae: 29203.1055\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 27828.9102 - mae: 27828.9102 - val_loss: 27064.7285 - val_mae: 27064.7285\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 26651.8828 - mae: 26651.8828 - val_loss: 26514.2773 - val_mae: 26514.2773\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 25678.0566 - mae: 25678.0566 - val_loss: 26926.5293 - val_mae: 26926.5293\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 25176.2617 - mae: 25176.2617 - val_loss: 24936.2988 - val_mae: 24936.2988\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 24630.9043 - mae: 24630.9043 - val_loss: 24122.5703 - val_mae: 24122.5703\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23631.4238 - mae: 23631.4238 - val_loss: 24233.4785 - val_mae: 24233.4785\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 23392.2246 - mae: 23392.2246 - val_loss: 23298.0820 - val_mae: 23298.0820\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 22915.4316 - mae: 22915.4316 - val_loss: 23008.9531 - val_mae: 23008.9531\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 22340.2207 - mae: 22340.2207 - val_loss: 22127.2988 - val_mae: 22127.2988\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 21736.4727 - mae: 21736.4727 - val_loss: 22837.5020 - val_mae: 22837.5020\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 22083.2598 - mae: 22083.2598 - val_loss: 23311.1387 - val_mae: 23311.1387\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21838.3457 - mae: 21838.3457 - val_loss: 21313.0469 - val_mae: 21313.0469\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 21190.9805 - mae: 21190.9805 - val_loss: 21564.4355 - val_mae: 21564.4355\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 21597.5312 - mae: 21597.5312 - val_loss: 21209.9199 - val_mae: 21209.9199\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20526.9531 - mae: 20526.9531 - val_loss: 21004.3887 - val_mae: 21004.3887\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20740.9336 - mae: 20740.9336 - val_loss: 20737.9121 - val_mae: 20737.9121\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20467.6289 - mae: 20467.6289 - val_loss: 20591.0645 - val_mae: 20591.0645\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20327.1504 - mae: 20327.1504 - val_loss: 20848.3086 - val_mae: 20848.3086\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 21002.7461 - mae: 21002.7461 - val_loss: 21119.3438 - val_mae: 21119.3438\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20155.1543 - mae: 20155.1543 - val_loss: 20765.2422 - val_mae: 20765.2422\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20444.2012 - mae: 20444.2012 - val_loss: 20299.6660 - val_mae: 20299.6660\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20255.4219 - mae: 20255.4219 - val_loss: 21189.0762 - val_mae: 21189.0762\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19875.5527 - mae: 19875.5527 - val_loss: 21109.2051 - val_mae: 21109.2051\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19975.2422 - mae: 19975.2422 - val_loss: 20088.0859 - val_mae: 20088.0859\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20026.3398 - mae: 20026.3398 - val_loss: 19979.5137 - val_mae: 19979.5137\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20244.9766 - mae: 20244.9766 - val_loss: 19819.1738 - val_mae: 19819.1738\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20910.9375 - mae: 20910.9375 - val_loss: 20028.0059 - val_mae: 20028.0059\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20159.9785 - mae: 20159.9785 - val_loss: 19778.4297 - val_mae: 19778.4297\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19852.8086 - mae: 19852.8086 - val_loss: 20478.6543 - val_mae: 20478.6543\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19733.9082 - mae: 19733.9082 - val_loss: 20015.4102 - val_mae: 20015.4102\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20460.6328 - mae: 20460.6328 - val_loss: 20817.5020 - val_mae: 20817.5020\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20274.4375 - mae: 20274.4375 - val_loss: 19772.6348 - val_mae: 19772.6348\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19694.5918 - mae: 19694.5918 - val_loss: 19467.0977 - val_mae: 19467.0977\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19692.6328 - mae: 19692.6328 - val_loss: 20096.7539 - val_mae: 20096.7539\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19334.8496 - mae: 19334.8496 - val_loss: 19396.6250 - val_mae: 19396.6250\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 20282.9238 - mae: 20282.9238 - val_loss: 20732.8535 - val_mae: 20732.8535\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19949.7988 - mae: 19949.7988 - val_loss: 21149.2402 - val_mae: 21149.2402\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 21318.9219 - mae: 21318.9219 - val_loss: 19731.0215 - val_mae: 19731.0215\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20091.6543 - mae: 20091.6543 - val_loss: 20180.3125 - val_mae: 20180.3125\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19882.5215 - mae: 19882.5215 - val_loss: 19259.2148 - val_mae: 19259.2148\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19139.1074 - mae: 19139.1074 - val_loss: 19877.2266 - val_mae: 19877.2266\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19149.5664 - mae: 19149.5664 - val_loss: 22256.2031 - val_mae: 22256.2031\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19821.8750 - mae: 19821.8750 - val_loss: 19073.5762 - val_mae: 19073.5762\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19512.1094 - mae: 19512.1094 - val_loss: 19237.9863 - val_mae: 19237.9863\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19686.9180 - mae: 19686.9180 - val_loss: 23507.9062 - val_mae: 23507.9062\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19662.8418 - mae: 19662.8418 - val_loss: 18930.8789 - val_mae: 18930.8789\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18936.5410 - mae: 18936.5410 - val_loss: 19176.7520 - val_mae: 19176.7520\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18971.9707 - mae: 18971.9707 - val_loss: 20620.0352 - val_mae: 20620.0352\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18933.4492 - mae: 18933.4492 - val_loss: 18777.5195 - val_mae: 18777.5195\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19174.1172 - mae: 19174.1172 - val_loss: 19038.2715 - val_mae: 19038.2715\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20018.8066 - mae: 20018.8066 - val_loss: 19209.5000 - val_mae: 19209.5000\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19382.7520 - mae: 19382.7520 - val_loss: 19922.6895 - val_mae: 19922.6895\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19321.1426 - mae: 19321.1426 - val_loss: 19860.5820 - val_mae: 19860.5820\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18900.4355 - mae: 18900.4355 - val_loss: 18710.3320 - val_mae: 18710.3320\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19000.0508 - mae: 19000.0508 - val_loss: 18607.6641 - val_mae: 18607.6641\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18974.3535 - mae: 18974.3535 - val_loss: 18673.0098 - val_mae: 18673.0098\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19595.8828 - mae: 19595.8828 - val_loss: 19538.4902 - val_mae: 19538.4902\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19254.2344 - mae: 19254.2344 - val_loss: 18724.1016 - val_mae: 18724.1016\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19829.8008 - mae: 19829.8008 - val_loss: 19812.7539 - val_mae: 19812.7539\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 20475.8047 - mae: 20475.8047 - val_loss: 18889.1465 - val_mae: 18889.1465\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18569.8535 - mae: 18569.8535 - val_loss: 18596.8047 - val_mae: 18596.8047\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19395.0195 - mae: 19395.0195 - val_loss: 20838.6719 - val_mae: 20838.6719\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 19054.8789 - mae: 19054.8789 - val_loss: 18556.7109 - val_mae: 18556.7109\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19015.8262 - mae: 19015.8262 - val_loss: 20017.4102 - val_mae: 20017.4102\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19238.3984 - mae: 19238.3984 - val_loss: 19609.9277 - val_mae: 19609.9277\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18890.9785 - mae: 18890.9785 - val_loss: 18755.2461 - val_mae: 18755.2461\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18912.3887 - mae: 18912.3887 - val_loss: 18816.6016 - val_mae: 18816.6016\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18606.8887 - mae: 18606.8887 - val_loss: 18520.9277 - val_mae: 18520.9277\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18720.3496 - mae: 18720.3496 - val_loss: 18487.2891 - val_mae: 18487.2891\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19475.9395 - mae: 19475.9395 - val_loss: 19442.8906 - val_mae: 19442.8906\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18693.0742 - mae: 18693.0742 - val_loss: 18821.2578 - val_mae: 18821.2578\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18902.3965 - mae: 18902.3965 - val_loss: 19228.5664 - val_mae: 19228.5664\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18896.4512 - mae: 18896.4512 - val_loss: 19541.6367 - val_mae: 19541.6367\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18518.5000 - mae: 18518.5000 - val_loss: 18440.9102 - val_mae: 18440.9102\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18532.3828 - mae: 18532.3828 - val_loss: 19048.8398 - val_mae: 19048.8398\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18382.2266 - mae: 18382.2266 - val_loss: 18932.8516 - val_mae: 18932.8516\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18582.9238 - mae: 18582.9238 - val_loss: 18955.3887 - val_mae: 18955.3887\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18710.4043 - mae: 18710.4043 - val_loss: 18425.1289 - val_mae: 18425.1289\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18821.2637 - mae: 18821.2637 - val_loss: 18189.5547 - val_mae: 18189.5547\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 19459.8320 - mae: 19459.8320 - val_loss: 21697.6328 - val_mae: 21697.6328\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18648.7383 - mae: 18648.7383 - val_loss: 18203.7793 - val_mae: 18203.7793\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18592.6504 - mae: 18592.6504 - val_loss: 18142.2500 - val_mae: 18142.2500\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18526.0352 - mae: 18526.0352 - val_loss: 18484.4238 - val_mae: 18484.4238\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18676.6133 - mae: 18676.6133 - val_loss: 18405.0625 - val_mae: 18405.0625\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18397.9512 - mae: 18397.9512 - val_loss: 18901.5879 - val_mae: 18901.5879\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18612.8184 - mae: 18612.8184 - val_loss: 19006.1621 - val_mae: 19006.1621\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18919.3320 - mae: 18919.3320 - val_loss: 18194.4375 - val_mae: 18194.4375\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 18393.0156 - mae: 18393.0156 - val_loss: 18073.3047 - val_mae: 18073.3047\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 18700.6562 - mae: 18700.6562 - val_loss: 18025.5508 - val_mae: 18025.5508\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выиграли существенный кусок в точности!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом у оптимизатора существует множество параметров, но самым важны, пожалуй, является `learning_rate`, регулирующий величину шага в градиентном спуске (получается, чем меньше - тем более точно, но медленнее). Посмотрим на результаты, изменив `learning_rate` с 0.05 до 0.001 (при этом увеличив batch_size до 64 для быстротродействия):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='linear'),\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "random.set_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "model.compile(optimizer=Adamax(learning_rate=0.001),\n",
    "              loss='mae',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 16ms/step - loss: 181177.2812 - mae: 181177.2812 - val_loss: 179842.9844 - val_mae: 179842.9844\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 181151.1406 - mae: 181151.1406 - val_loss: 179810.4062 - val_mae: 179810.4062\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 181108.6250 - mae: 181108.6250 - val_loss: 179753.4844 - val_mae: 179753.4844\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181036.7500 - mae: 181036.7500 - val_loss: 179661.7812 - val_mae: 179661.7812\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 180926.5000 - mae: 180926.5000 - val_loss: 179527.2812 - val_mae: 179527.2812\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 180769.4062 - mae: 180769.4062 - val_loss: 179340.9844 - val_mae: 179340.9844\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 180556.1719 - mae: 180556.1719 - val_loss: 179092.5625 - val_mae: 179092.5625\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 180277.1562 - mae: 180277.1562 - val_loss: 178774.0938 - val_mae: 178774.0938\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 179924.4688 - mae: 179924.4688 - val_loss: 178376.0469 - val_mae: 178376.0469\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 179487.7812 - mae: 179487.7812 - val_loss: 177890.2969 - val_mae: 177890.2969\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 178958.7969 - mae: 178958.7969 - val_loss: 177306.4062 - val_mae: 177306.4062\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 178329.6094 - mae: 178329.6094 - val_loss: 176617.0469 - val_mae: 176617.0469\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 177590.7500 - mae: 177590.7500 - val_loss: 175809.1875 - val_mae: 175809.1875\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 176727.1875 - mae: 176727.1875 - val_loss: 174877.1719 - val_mae: 174877.1719\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 175738.8281 - mae: 175738.8281 - val_loss: 173811.0000 - val_mae: 173811.0000\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 174606.3594 - mae: 174606.3594 - val_loss: 172597.7344 - val_mae: 172597.7344\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 173323.6719 - mae: 173323.6719 - val_loss: 171232.5000 - val_mae: 171232.5000\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 171890.5000 - mae: 171890.5000 - val_loss: 169699.7344 - val_mae: 169699.7344\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 170286.6562 - mae: 170286.6562 - val_loss: 167998.4844 - val_mae: 167998.4844\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 168509.0625 - mae: 168509.0625 - val_loss: 166116.9688 - val_mae: 166116.9688\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 166541.3281 - mae: 166541.3281 - val_loss: 164046.1719 - val_mae: 164046.1719\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 164384.7188 - mae: 164384.7188 - val_loss: 161767.5000 - val_mae: 161767.5000\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 162017.5156 - mae: 162017.5156 - val_loss: 159278.6094 - val_mae: 159278.6094\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 159433.5156 - mae: 159433.5156 - val_loss: 156571.7031 - val_mae: 156571.7031\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 156631.1250 - mae: 156631.1250 - val_loss: 153644.1719 - val_mae: 153644.1719\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 153600.5000 - mae: 153600.5000 - val_loss: 150477.5000 - val_mae: 150477.5000\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 150326.3906 - mae: 150326.3906 - val_loss: 147055.1562 - val_mae: 147055.1562\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 146796.9844 - mae: 146796.9844 - val_loss: 143364.4062 - val_mae: 143364.4062\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 142992.0781 - mae: 142992.0781 - val_loss: 139415.6719 - val_mae: 139415.6719\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 138929.7188 - mae: 138929.7188 - val_loss: 135189.1094 - val_mae: 135189.1094\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 134613.5000 - mae: 134613.5000 - val_loss: 130722.1250 - val_mae: 130722.1250\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 130010.6016 - mae: 130010.6016 - val_loss: 125951.9688 - val_mae: 125951.9688\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 125108.4141 - mae: 125108.4141 - val_loss: 120864.2500 - val_mae: 120864.2500\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 119925.4922 - mae: 119925.4922 - val_loss: 115485.3438 - val_mae: 115485.3438\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 114467.8594 - mae: 114467.8594 - val_loss: 109870.4766 - val_mae: 109870.4766\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 108762.7500 - mae: 108762.7500 - val_loss: 103996.4531 - val_mae: 103996.4531\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 102802.3359 - mae: 102802.3359 - val_loss: 97981.0938 - val_mae: 97981.0938\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 96638.1406 - mae: 96638.1406 - val_loss: 91912.1250 - val_mae: 91912.1250\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 90330.2500 - mae: 90330.2500 - val_loss: 85883.0234 - val_mae: 85883.0234\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 83979.5781 - mae: 83979.5781 - val_loss: 79941.0312 - val_mae: 79941.0312\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 77751.7344 - mae: 77751.7344 - val_loss: 74166.4297 - val_mae: 74166.4297\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 72206.5625 - mae: 72206.5625 - val_loss: 69465.0312 - val_mae: 69465.0312\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 67450.6406 - mae: 67450.6406 - val_loss: 65380.6172 - val_mae: 65380.6172\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 63395.5430 - mae: 63395.5430 - val_loss: 61962.1562 - val_mae: 61962.1562\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 60083.5156 - mae: 60083.5156 - val_loss: 59456.4531 - val_mae: 59456.4531\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 57706.1523 - mae: 57706.1523 - val_loss: 57590.8086 - val_mae: 57590.8086\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 56153.4375 - mae: 56153.4375 - val_loss: 56349.3828 - val_mae: 56349.3828\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 55078.2344 - mae: 55078.2344 - val_loss: 55594.7812 - val_mae: 55594.7812\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 54371.0273 - mae: 54371.0273 - val_loss: 55155.4844 - val_mae: 55155.4844\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 53916.4375 - mae: 53916.4375 - val_loss: 54864.7617 - val_mae: 54864.7617\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 53607.7969 - mae: 53607.7969 - val_loss: 54666.3633 - val_mae: 54666.3633\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 53415.8398 - mae: 53415.8398 - val_loss: 54527.7422 - val_mae: 54527.7422\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 53289.2031 - mae: 53289.2031 - val_loss: 54436.3984 - val_mae: 54436.3984\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 53195.2695 - mae: 53195.2695 - val_loss: 54362.5977 - val_mae: 54362.5977\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 53126.2617 - mae: 53126.2617 - val_loss: 54307.2695 - val_mae: 54307.2695\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 53061.3047 - mae: 53061.3047 - val_loss: 54248.3281 - val_mae: 54248.3281\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 53016.8359 - mae: 53016.8359 - val_loss: 54201.7344 - val_mae: 54201.7344\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 52969.2383 - mae: 52969.2383 - val_loss: 54138.6758 - val_mae: 54138.6758\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52923.5352 - mae: 52923.5352 - val_loss: 54091.4727 - val_mae: 54091.4727\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 52890.7109 - mae: 52890.7109 - val_loss: 54058.1680 - val_mae: 54058.1680\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52843.8203 - mae: 52843.8203 - val_loss: 54012.0352 - val_mae: 54012.0352\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52805.6875 - mae: 52805.6875 - val_loss: 53970.2852 - val_mae: 53970.2852\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52767.4297 - mae: 52767.4297 - val_loss: 53926.8438 - val_mae: 53926.8438\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52734.6875 - mae: 52734.6875 - val_loss: 53878.4922 - val_mae: 53878.4922\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52686.2148 - mae: 52686.2148 - val_loss: 53842.0352 - val_mae: 53842.0352\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52646.2383 - mae: 52646.2383 - val_loss: 53801.6094 - val_mae: 53801.6094\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52611.7812 - mae: 52611.7812 - val_loss: 53763.9844 - val_mae: 53763.9844\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 52571.2109 - mae: 52571.2109 - val_loss: 53718.9609 - val_mae: 53718.9609\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 52528.8750 - mae: 52528.8750 - val_loss: 53671.4805 - val_mae: 53671.4805\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52493.5430 - mae: 52493.5430 - val_loss: 53624.8242 - val_mae: 53624.8242\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 52446.0039 - mae: 52446.0039 - val_loss: 53583.2539 - val_mae: 53583.2539\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52405.6211 - mae: 52405.6211 - val_loss: 53539.4453 - val_mae: 53539.4453\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52364.7383 - mae: 52364.7383 - val_loss: 53494.6953 - val_mae: 53494.6953\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52324.4102 - mae: 52324.4102 - val_loss: 53446.0273 - val_mae: 53446.0273\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52275.3398 - mae: 52275.3398 - val_loss: 53401.2344 - val_mae: 53401.2344\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 52234.9297 - mae: 52234.9297 - val_loss: 53357.1094 - val_mae: 53357.1094\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 52186.0703 - mae: 52186.0703 - val_loss: 53305.2656 - val_mae: 53305.2656\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52140.6836 - mae: 52140.6836 - val_loss: 53255.8555 - val_mae: 53255.8555\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52094.0195 - mae: 52094.0195 - val_loss: 53204.7539 - val_mae: 53204.7539\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52048.3711 - mae: 52048.3711 - val_loss: 53155.6523 - val_mae: 53155.6523\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52002.7227 - mae: 52002.7227 - val_loss: 53094.9180 - val_mae: 53094.9180\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51959.9453 - mae: 51959.9453 - val_loss: 53058.6719 - val_mae: 53058.6719\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51914.5078 - mae: 51914.5078 - val_loss: 53000.1758 - val_mae: 53000.1758\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51872.0430 - mae: 51872.0430 - val_loss: 52952.4570 - val_mae: 52952.4570\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51830.4844 - mae: 51830.4844 - val_loss: 52902.0703 - val_mae: 52902.0703\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51785.3008 - mae: 51785.3008 - val_loss: 52858.3516 - val_mae: 52858.3516\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51747.7266 - mae: 51747.7266 - val_loss: 52822.6133 - val_mae: 52822.6133\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51700.3750 - mae: 51700.3750 - val_loss: 52769.4805 - val_mae: 52769.4805\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51655.4609 - mae: 51655.4609 - val_loss: 52724.3750 - val_mae: 52724.3750\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51610.5859 - mae: 51610.5859 - val_loss: 52682.5586 - val_mae: 52682.5586\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51567.8438 - mae: 51567.8438 - val_loss: 52627.5430 - val_mae: 52627.5430\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51527.5742 - mae: 51527.5742 - val_loss: 52584.5977 - val_mae: 52584.5977\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51467.6680 - mae: 51467.6680 - val_loss: 52524.9375 - val_mae: 52524.9375\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51424.3945 - mae: 51424.3945 - val_loss: 52473.8086 - val_mae: 52473.8086\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51374.1055 - mae: 51374.1055 - val_loss: 52413.5156 - val_mae: 52413.5156\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51333.7305 - mae: 51333.7305 - val_loss: 52359.8398 - val_mae: 52359.8398\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51286.6445 - mae: 51286.6445 - val_loss: 52313.3945 - val_mae: 52313.3945\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51243.3945 - mae: 51243.3945 - val_loss: 52276.4727 - val_mae: 52276.4727\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51200.0898 - mae: 51200.0898 - val_loss: 52245.6094 - val_mae: 52245.6094\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51168.1094 - mae: 51168.1094 - val_loss: 52211.9414 - val_mae: 52211.9414\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что не хватает количества эпох, происходит недообучение, исправим это, увеличением параметра `epochs` до 500:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='linear'),\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "random.set_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "model.compile(optimizer=Adamax(learning_rate=0.001),\n",
    "              loss='mae',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "19/19 [==============================] - 1s 16ms/step - loss: 181175.3750 - mae: 181175.3750 - val_loss: 179840.3906 - val_mae: 179840.3906\n",
      "Epoch 2/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 181147.3281 - mae: 181147.3281 - val_loss: 179805.3438 - val_mae: 179805.3438\n",
      "Epoch 3/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 181102.7656 - mae: 181102.7656 - val_loss: 179747.4844 - val_mae: 179747.4844\n",
      "Epoch 4/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 181031.3281 - mae: 181031.3281 - val_loss: 179657.9219 - val_mae: 179657.9219\n",
      "Epoch 5/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 180924.0156 - mae: 180924.0156 - val_loss: 179527.5156 - val_mae: 179527.5156\n",
      "Epoch 6/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 180772.1250 - mae: 180772.1250 - val_loss: 179348.4062 - val_mae: 179348.4062\n",
      "Epoch 7/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 180567.7656 - mae: 180567.7656 - val_loss: 179111.0469 - val_mae: 179111.0469\n",
      "Epoch 8/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 180301.5000 - mae: 180301.5000 - val_loss: 178807.7344 - val_mae: 178807.7344\n",
      "Epoch 9/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 179965.7344 - mae: 179965.7344 - val_loss: 178429.2656 - val_mae: 178429.2656\n",
      "Epoch 10/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 179550.5469 - mae: 179550.5469 - val_loss: 177967.9219 - val_mae: 177967.9219\n",
      "Epoch 11/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 179047.9844 - mae: 179047.9844 - val_loss: 177413.5781 - val_mae: 177413.5781\n",
      "Epoch 12/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 178450.5156 - mae: 178450.5156 - val_loss: 176759.3750 - val_mae: 176759.3750\n",
      "Epoch 13/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 177749.1719 - mae: 177749.1719 - val_loss: 175992.5000 - val_mae: 175992.5000\n",
      "Epoch 14/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 176929.1094 - mae: 176929.1094 - val_loss: 175107.8438 - val_mae: 175107.8438\n",
      "Epoch 15/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 175990.6875 - mae: 175990.6875 - val_loss: 174095.7500 - val_mae: 174095.7500\n",
      "Epoch 16/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 174915.0938 - mae: 174915.0938 - val_loss: 172943.5938 - val_mae: 172943.5938\n",
      "Epoch 17/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 173696.5625 - mae: 173696.5625 - val_loss: 171646.9062 - val_mae: 171646.9062\n",
      "Epoch 18/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 172335.0156 - mae: 172335.0156 - val_loss: 170190.8281 - val_mae: 170190.8281\n",
      "Epoch 19/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 170810.9844 - mae: 170810.9844 - val_loss: 168574.2500 - val_mae: 168574.2500\n",
      "Epoch 20/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 169121.2969 - mae: 169121.2969 - val_loss: 166786.3906 - val_mae: 166786.3906\n",
      "Epoch 21/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 167251.0469 - mae: 167251.0469 - val_loss: 164818.1562 - val_mae: 164818.1562\n",
      "Epoch 22/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 165200.3438 - mae: 165200.3438 - val_loss: 162651.3906 - val_mae: 162651.3906\n",
      "Epoch 23/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 162948.9531 - mae: 162948.9531 - val_loss: 160284.4688 - val_mae: 160284.4688\n",
      "Epoch 24/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 160490.5156 - mae: 160490.5156 - val_loss: 157709.0938 - val_mae: 157709.0938\n",
      "Epoch 25/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 157823.8906 - mae: 157823.8906 - val_loss: 154923.7031 - val_mae: 154923.7031\n",
      "Epoch 26/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 154939.4844 - mae: 154939.4844 - val_loss: 151910.0625 - val_mae: 151910.0625\n",
      "Epoch 27/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 151822.9688 - mae: 151822.9688 - val_loss: 148653.0312 - val_mae: 148653.0312\n",
      "Epoch 28/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 148463.0938 - mae: 148463.0938 - val_loss: 145138.5000 - val_mae: 145138.5000\n",
      "Epoch 29/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 144839.0625 - mae: 144839.0625 - val_loss: 141378.8594 - val_mae: 141378.8594\n",
      "Epoch 30/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 140965.1562 - mae: 140965.1562 - val_loss: 137348.0625 - val_mae: 137348.0625\n",
      "Epoch 31/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 136842.8281 - mae: 136842.8281 - val_loss: 133079.2188 - val_mae: 133079.2188\n",
      "Epoch 32/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 132456.8906 - mae: 132456.8906 - val_loss: 128533.7812 - val_mae: 128533.7812\n",
      "Epoch 33/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 127784.4922 - mae: 127784.4922 - val_loss: 123684.2734 - val_mae: 123684.2734\n",
      "Epoch 34/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 122821.1250 - mae: 122821.1250 - val_loss: 118530.8750 - val_mae: 118530.8750\n",
      "Epoch 35/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 117595.8359 - mae: 117595.8359 - val_loss: 113172.3203 - val_mae: 113172.3203\n",
      "Epoch 36/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 112148.4453 - mae: 112148.4453 - val_loss: 107530.5859 - val_mae: 107530.5859\n",
      "Epoch 37/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 106416.3125 - mae: 106416.3125 - val_loss: 101662.6250 - val_mae: 101662.6250\n",
      "Epoch 38/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 100439.9609 - mae: 100439.9609 - val_loss: 95668.3828 - val_mae: 95668.3828\n",
      "Epoch 39/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 94248.0781 - mae: 94248.0781 - val_loss: 89637.3281 - val_mae: 89637.3281\n",
      "Epoch 40/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 87968.6172 - mae: 87968.6172 - val_loss: 83741.4219 - val_mae: 83741.4219\n",
      "Epoch 41/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 81766.2812 - mae: 81766.2812 - val_loss: 77895.0391 - val_mae: 77895.0391\n",
      "Epoch 42/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 75914.3828 - mae: 75914.3828 - val_loss: 72695.9609 - val_mae: 72695.9609\n",
      "Epoch 43/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 70715.5938 - mae: 70715.5938 - val_loss: 68164.7344 - val_mae: 68164.7344\n",
      "Epoch 44/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 66062.4766 - mae: 66062.4766 - val_loss: 64100.3203 - val_mae: 64100.3203\n",
      "Epoch 45/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 62028.1016 - mae: 62028.1016 - val_loss: 60914.7539 - val_mae: 60914.7539\n",
      "Epoch 46/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 58959.0820 - mae: 58959.0820 - val_loss: 58544.1641 - val_mae: 58544.1641\n",
      "Epoch 47/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 56887.1523 - mae: 56887.1523 - val_loss: 56886.4961 - val_mae: 56886.4961\n",
      "Epoch 48/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 55508.1055 - mae: 55508.1055 - val_loss: 55848.0234 - val_mae: 55848.0234\n",
      "Epoch 49/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 54632.8789 - mae: 54632.8789 - val_loss: 55283.7070 - val_mae: 55283.7070\n",
      "Epoch 50/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 54084.4023 - mae: 54084.4023 - val_loss: 54933.4141 - val_mae: 54933.4141\n",
      "Epoch 51/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 53699.1406 - mae: 53699.1406 - val_loss: 54684.5391 - val_mae: 54684.5391\n",
      "Epoch 52/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 53457.2383 - mae: 53457.2383 - val_loss: 54505.9844 - val_mae: 54505.9844\n",
      "Epoch 53/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 53300.5781 - mae: 53300.5781 - val_loss: 54390.8789 - val_mae: 54390.8789\n",
      "Epoch 54/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 53188.0508 - mae: 53188.0508 - val_loss: 54305.1172 - val_mae: 54305.1172\n",
      "Epoch 55/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 53111.7656 - mae: 53111.7656 - val_loss: 54244.3984 - val_mae: 54244.3984\n",
      "Epoch 56/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 53043.5977 - mae: 53043.5977 - val_loss: 54182.2500 - val_mae: 54182.2500\n",
      "Epoch 57/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52994.5312 - mae: 52994.5312 - val_loss: 54134.9922 - val_mae: 54134.9922\n",
      "Epoch 58/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52947.2852 - mae: 52947.2852 - val_loss: 54070.3906 - val_mae: 54070.3906\n",
      "Epoch 59/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52899.3516 - mae: 52899.3516 - val_loss: 54018.9648 - val_mae: 54018.9648\n",
      "Epoch 60/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52866.7656 - mae: 52866.7656 - val_loss: 53990.9219 - val_mae: 53990.9219\n",
      "Epoch 61/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52820.4180 - mae: 52820.4180 - val_loss: 53943.8281 - val_mae: 53943.8281\n",
      "Epoch 62/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52782.7656 - mae: 52782.7656 - val_loss: 53902.0898 - val_mae: 53902.0898\n",
      "Epoch 63/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52744.6289 - mae: 52744.6289 - val_loss: 53859.6680 - val_mae: 53859.6680\n",
      "Epoch 64/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 52712.5938 - mae: 52712.5938 - val_loss: 53807.7070 - val_mae: 53807.7070\n",
      "Epoch 65/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 52664.7656 - mae: 52664.7656 - val_loss: 53774.5391 - val_mae: 53774.5391\n",
      "Epoch 66/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52625.4570 - mae: 52625.4570 - val_loss: 53735.9844 - val_mae: 53735.9844\n",
      "Epoch 67/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52590.9766 - mae: 52590.9766 - val_loss: 53702.0703 - val_mae: 53702.0703\n",
      "Epoch 68/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52551.2383 - mae: 52551.2383 - val_loss: 53656.6875 - val_mae: 53656.6875\n",
      "Epoch 69/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52510.0195 - mae: 52510.0195 - val_loss: 53607.8086 - val_mae: 53607.8086\n",
      "Epoch 70/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52474.6602 - mae: 52474.6602 - val_loss: 53560.2656 - val_mae: 53560.2656\n",
      "Epoch 71/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52427.6016 - mae: 52427.6016 - val_loss: 53521.4766 - val_mae: 53521.4766\n",
      "Epoch 72/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52388.1523 - mae: 52388.1523 - val_loss: 53477.7148 - val_mae: 53477.7148\n",
      "Epoch 73/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52347.4258 - mae: 52347.4258 - val_loss: 53433.1250 - val_mae: 53433.1250\n",
      "Epoch 74/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52307.1523 - mae: 52307.1523 - val_loss: 53384.7852 - val_mae: 53384.7852\n",
      "Epoch 75/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 52259.6914 - mae: 52259.6914 - val_loss: 53339.2539 - val_mae: 53339.2539\n",
      "Epoch 76/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 52219.2852 - mae: 52219.2852 - val_loss: 53294.9570 - val_mae: 53294.9570\n",
      "Epoch 77/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 52171.0703 - mae: 52171.0703 - val_loss: 53243.3164 - val_mae: 53243.3164\n",
      "Epoch 78/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 52126.1523 - mae: 52126.1523 - val_loss: 53194.5352 - val_mae: 53194.5352\n",
      "Epoch 79/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 52080.2500 - mae: 52080.2500 - val_loss: 53144.1289 - val_mae: 53144.1289\n",
      "Epoch 80/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52034.8711 - mae: 52034.8711 - val_loss: 53095.7344 - val_mae: 53095.7344\n",
      "Epoch 81/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51989.3086 - mae: 51989.3086 - val_loss: 53037.6328 - val_mae: 53037.6328\n",
      "Epoch 82/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51949.6523 - mae: 51949.6523 - val_loss: 53005.3086 - val_mae: 53005.3086\n",
      "Epoch 83/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51903.3164 - mae: 51903.3164 - val_loss: 52947.3750 - val_mae: 52947.3750\n",
      "Epoch 84/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51861.5625 - mae: 51861.5625 - val_loss: 52902.6523 - val_mae: 52902.6523\n",
      "Epoch 85/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51820.5078 - mae: 51820.5078 - val_loss: 52854.1602 - val_mae: 52854.1602\n",
      "Epoch 86/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51776.5312 - mae: 51776.5312 - val_loss: 52810.2344 - val_mae: 52810.2344\n",
      "Epoch 87/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51738.5547 - mae: 51738.5547 - val_loss: 52773.8359 - val_mae: 52773.8359\n",
      "Epoch 88/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51691.7070 - mae: 51691.7070 - val_loss: 52724.9961 - val_mae: 52724.9961\n",
      "Epoch 89/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51647.4336 - mae: 51647.4336 - val_loss: 52682.6758 - val_mae: 52682.6758\n",
      "Epoch 90/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51604.5156 - mae: 51604.5156 - val_loss: 52643.6836 - val_mae: 52643.6836\n",
      "Epoch 91/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51563.6523 - mae: 51563.6523 - val_loss: 52587.4727 - val_mae: 52587.4727\n",
      "Epoch 92/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51524.1562 - mae: 51524.1562 - val_loss: 52546.3477 - val_mae: 52546.3477\n",
      "Epoch 93/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51464.2461 - mae: 51464.2461 - val_loss: 52487.5234 - val_mae: 52487.5234\n",
      "Epoch 94/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51422.0273 - mae: 51422.0273 - val_loss: 52437.3281 - val_mae: 52437.3281\n",
      "Epoch 95/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51372.4023 - mae: 51372.4023 - val_loss: 52377.9844 - val_mae: 52377.9844\n",
      "Epoch 96/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51333.1523 - mae: 51333.1523 - val_loss: 52325.6055 - val_mae: 52325.6055\n",
      "Epoch 97/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51287.7891 - mae: 51287.7891 - val_loss: 52279.2461 - val_mae: 52279.2461\n",
      "Epoch 98/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51245.2695 - mae: 51245.2695 - val_loss: 52242.0859 - val_mae: 52242.0859\n",
      "Epoch 99/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51204.1641 - mae: 51204.1641 - val_loss: 52215.4805 - val_mae: 52215.4805\n",
      "Epoch 100/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51172.2461 - mae: 51172.2461 - val_loss: 52184.5000 - val_mae: 52184.5000\n",
      "Epoch 101/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51133.7578 - mae: 51133.7578 - val_loss: 52136.6289 - val_mae: 52136.6289\n",
      "Epoch 102/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51095.4258 - mae: 51095.4258 - val_loss: 52098.9570 - val_mae: 52098.9570\n",
      "Epoch 103/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 51056.9805 - mae: 51056.9805 - val_loss: 52044.9492 - val_mae: 52044.9492\n",
      "Epoch 104/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 51014.3594 - mae: 51014.3594 - val_loss: 51998.6172 - val_mae: 51998.6172\n",
      "Epoch 105/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50977.2656 - mae: 50977.2656 - val_loss: 51950.0156 - val_mae: 51950.0156\n",
      "Epoch 106/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50939.0977 - mae: 50939.0977 - val_loss: 51910.8633 - val_mae: 51910.8633\n",
      "Epoch 107/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50896.5625 - mae: 50896.5625 - val_loss: 51865.6523 - val_mae: 51865.6523\n",
      "Epoch 108/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50854.0312 - mae: 50854.0312 - val_loss: 51825.4219 - val_mae: 51825.4219\n",
      "Epoch 109/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50814.9844 - mae: 50814.9844 - val_loss: 51788.0664 - val_mae: 51788.0664\n",
      "Epoch 110/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50775.6289 - mae: 50775.6289 - val_loss: 51747.5977 - val_mae: 51747.5977\n",
      "Epoch 111/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50730.4961 - mae: 50730.4961 - val_loss: 51692.3594 - val_mae: 51692.3594\n",
      "Epoch 112/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50690.6523 - mae: 50690.6523 - val_loss: 51650.9570 - val_mae: 51650.9570\n",
      "Epoch 113/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50650.1836 - mae: 50650.1836 - val_loss: 51604.5234 - val_mae: 51604.5234\n",
      "Epoch 114/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50607.0703 - mae: 50607.0703 - val_loss: 51570.0859 - val_mae: 51570.0859\n",
      "Epoch 115/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50568.3516 - mae: 50568.3516 - val_loss: 51524.8008 - val_mae: 51524.8008\n",
      "Epoch 116/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50527.8008 - mae: 50527.8008 - val_loss: 51472.3477 - val_mae: 51472.3477\n",
      "Epoch 117/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50489.3203 - mae: 50489.3203 - val_loss: 51430.4648 - val_mae: 51430.4648\n",
      "Epoch 118/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50450.8516 - mae: 50450.8516 - val_loss: 51391.1875 - val_mae: 51391.1875\n",
      "Epoch 119/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50412.2578 - mae: 50412.2578 - val_loss: 51334.9023 - val_mae: 51334.9023\n",
      "Epoch 120/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50367.5195 - mae: 50367.5195 - val_loss: 51295.2734 - val_mae: 51295.2734\n",
      "Epoch 121/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50324.8047 - mae: 50324.8047 - val_loss: 51262.4844 - val_mae: 51262.4844\n",
      "Epoch 122/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50282.7227 - mae: 50282.7227 - val_loss: 51205.3984 - val_mae: 51205.3984\n",
      "Epoch 123/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50240.8320 - mae: 50240.8320 - val_loss: 51145.5195 - val_mae: 51145.5195\n",
      "Epoch 124/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50201.2383 - mae: 50201.2383 - val_loss: 51109.0117 - val_mae: 51109.0117\n",
      "Epoch 125/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50154.5820 - mae: 50154.5820 - val_loss: 51083.2930 - val_mae: 51083.2930\n",
      "Epoch 126/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50124.8008 - mae: 50124.8008 - val_loss: 51021.6250 - val_mae: 51021.6250\n",
      "Epoch 127/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 50078.6172 - mae: 50078.6172 - val_loss: 50978.6914 - val_mae: 50978.6914\n",
      "Epoch 128/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 50033.0547 - mae: 50033.0547 - val_loss: 50943.4922 - val_mae: 50943.4922\n",
      "Epoch 129/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49998.4023 - mae: 49998.4023 - val_loss: 50914.7930 - val_mae: 50914.7930\n",
      "Epoch 130/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49960.7969 - mae: 49960.7969 - val_loss: 50873.7656 - val_mae: 50873.7656\n",
      "Epoch 131/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49919.3203 - mae: 49919.3203 - val_loss: 50828.6328 - val_mae: 50828.6328\n",
      "Epoch 132/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49882.9219 - mae: 49882.9219 - val_loss: 50785.3047 - val_mae: 50785.3047\n",
      "Epoch 133/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49847.1836 - mae: 49847.1836 - val_loss: 50737.2148 - val_mae: 50737.2148\n",
      "Epoch 134/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49803.2656 - mae: 49803.2656 - val_loss: 50701.5625 - val_mae: 50701.5625\n",
      "Epoch 135/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49764.9102 - mae: 49764.9102 - val_loss: 50662.4570 - val_mae: 50662.4570\n",
      "Epoch 136/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49723.3086 - mae: 49723.3086 - val_loss: 50614.8555 - val_mae: 50614.8555\n",
      "Epoch 137/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49680.5664 - mae: 49680.5664 - val_loss: 50563.7266 - val_mae: 50563.7266\n",
      "Epoch 138/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49639.0547 - mae: 49639.0547 - val_loss: 50515.7617 - val_mae: 50515.7617\n",
      "Epoch 139/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49601.7344 - mae: 49601.7344 - val_loss: 50456.7539 - val_mae: 50456.7539\n",
      "Epoch 140/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49568.9844 - mae: 49568.9844 - val_loss: 50401.1953 - val_mae: 50401.1953\n",
      "Epoch 141/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49507.2070 - mae: 49507.2070 - val_loss: 50383.0234 - val_mae: 50383.0234\n",
      "Epoch 142/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49477.8164 - mae: 49477.8164 - val_loss: 50358.6055 - val_mae: 50358.6055\n",
      "Epoch 143/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49439.8867 - mae: 49439.8867 - val_loss: 50300.3242 - val_mae: 50300.3242\n",
      "Epoch 144/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49393.6875 - mae: 49393.6875 - val_loss: 50247.1367 - val_mae: 50247.1367\n",
      "Epoch 145/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49354.8672 - mae: 49354.8672 - val_loss: 50190.1211 - val_mae: 50190.1211\n",
      "Epoch 146/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 49312.5156 - mae: 49312.5156 - val_loss: 50162.3633 - val_mae: 50162.3633\n",
      "Epoch 147/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49276.4883 - mae: 49276.4883 - val_loss: 50119.9805 - val_mae: 50119.9805\n",
      "Epoch 148/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49235.2656 - mae: 49235.2656 - val_loss: 50084.2344 - val_mae: 50084.2344\n",
      "Epoch 149/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49201.0703 - mae: 49201.0703 - val_loss: 50028.2500 - val_mae: 50028.2500\n",
      "Epoch 150/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49154.0039 - mae: 49154.0039 - val_loss: 49992.7852 - val_mae: 49992.7852\n",
      "Epoch 151/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 49114.4141 - mae: 49114.4141 - val_loss: 49946.6289 - val_mae: 49946.6289\n",
      "Epoch 152/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 49074.6289 - mae: 49074.6289 - val_loss: 49906.7891 - val_mae: 49906.7891\n",
      "Epoch 153/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 49031.1445 - mae: 49031.1445 - val_loss: 49852.6367 - val_mae: 49852.6367\n",
      "Epoch 154/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 48995.9414 - mae: 48995.9414 - val_loss: 49813.0000 - val_mae: 49813.0000\n",
      "Epoch 155/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48952.5273 - mae: 48952.5273 - val_loss: 49779.6562 - val_mae: 49779.6562\n",
      "Epoch 156/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48908.3438 - mae: 48908.3438 - val_loss: 49724.7266 - val_mae: 49724.7266\n",
      "Epoch 157/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48868.8477 - mae: 48868.8477 - val_loss: 49681.9531 - val_mae: 49681.9531\n",
      "Epoch 158/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 48826.6367 - mae: 48826.6367 - val_loss: 49628.0820 - val_mae: 49628.0820\n",
      "Epoch 159/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48780.0664 - mae: 48780.0664 - val_loss: 49583.1523 - val_mae: 49583.1523\n",
      "Epoch 160/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48734.5117 - mae: 48734.5117 - val_loss: 49528.5469 - val_mae: 49528.5469\n",
      "Epoch 161/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48698.1719 - mae: 48698.1719 - val_loss: 49493.7266 - val_mae: 49493.7266\n",
      "Epoch 162/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48647.9453 - mae: 48647.9453 - val_loss: 49460.5430 - val_mae: 49460.5430\n",
      "Epoch 163/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48609.8789 - mae: 48609.8789 - val_loss: 49390.0078 - val_mae: 49390.0078\n",
      "Epoch 164/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48561.5508 - mae: 48561.5508 - val_loss: 49342.3828 - val_mae: 49342.3828\n",
      "Epoch 165/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 48525.2344 - mae: 48525.2344 - val_loss: 49298.1250 - val_mae: 49298.1250\n",
      "Epoch 166/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48479.5156 - mae: 48479.5156 - val_loss: 49252.5312 - val_mae: 49252.5312\n",
      "Epoch 167/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48441.4648 - mae: 48441.4648 - val_loss: 49215.9883 - val_mae: 49215.9883\n",
      "Epoch 168/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 48395.0742 - mae: 48395.0742 - val_loss: 49171.9570 - val_mae: 49171.9570\n",
      "Epoch 169/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48349.8281 - mae: 48349.8281 - val_loss: 49123.2070 - val_mae: 49123.2070\n",
      "Epoch 170/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 48303.5430 - mae: 48303.5430 - val_loss: 49058.1797 - val_mae: 49058.1797\n",
      "Epoch 171/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48264.5273 - mae: 48264.5273 - val_loss: 48988.4336 - val_mae: 48988.4336\n",
      "Epoch 172/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48219.3203 - mae: 48219.3203 - val_loss: 48944.0234 - val_mae: 48944.0234\n",
      "Epoch 173/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 48167.6992 - mae: 48167.6992 - val_loss: 48928.3906 - val_mae: 48928.3906\n",
      "Epoch 174/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 48117.1836 - mae: 48117.1836 - val_loss: 48878.4102 - val_mae: 48878.4102\n",
      "Epoch 175/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48068.5938 - mae: 48068.5938 - val_loss: 48814.8906 - val_mae: 48814.8906\n",
      "Epoch 176/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 48025.8203 - mae: 48025.8203 - val_loss: 48773.6719 - val_mae: 48773.6719\n",
      "Epoch 177/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47966.8516 - mae: 47966.8516 - val_loss: 48706.8984 - val_mae: 48706.8984\n",
      "Epoch 178/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47946.5156 - mae: 47946.5156 - val_loss: 48626.7344 - val_mae: 48626.7344\n",
      "Epoch 179/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47872.8945 - mae: 47872.8945 - val_loss: 48590.0859 - val_mae: 48590.0859\n",
      "Epoch 180/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47835.7852 - mae: 47835.7852 - val_loss: 48560.4492 - val_mae: 48560.4492\n",
      "Epoch 181/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47769.3242 - mae: 47769.3242 - val_loss: 48488.4727 - val_mae: 48488.4727\n",
      "Epoch 182/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47719.3594 - mae: 47719.3594 - val_loss: 48430.8906 - val_mae: 48430.8906\n",
      "Epoch 183/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47664.4609 - mae: 47664.4609 - val_loss: 48400.2305 - val_mae: 48400.2305\n",
      "Epoch 184/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47614.8672 - mae: 47614.8672 - val_loss: 48334.5117 - val_mae: 48334.5117\n",
      "Epoch 185/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47560.0938 - mae: 47560.0938 - val_loss: 48263.7852 - val_mae: 48263.7852\n",
      "Epoch 186/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47517.1133 - mae: 47517.1133 - val_loss: 48229.4531 - val_mae: 48229.4531\n",
      "Epoch 187/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47454.8555 - mae: 47454.8555 - val_loss: 48139.5039 - val_mae: 48139.5039\n",
      "Epoch 188/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47402.2305 - mae: 47402.2305 - val_loss: 48085.9570 - val_mae: 48085.9570\n",
      "Epoch 189/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47357.0352 - mae: 47357.0352 - val_loss: 48032.0898 - val_mae: 48032.0898\n",
      "Epoch 190/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47310.3750 - mae: 47310.3750 - val_loss: 47990.8828 - val_mae: 47990.8828\n",
      "Epoch 191/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47263.8555 - mae: 47263.8555 - val_loss: 47952.1445 - val_mae: 47952.1445\n",
      "Epoch 192/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47222.9023 - mae: 47222.9023 - val_loss: 47915.6406 - val_mae: 47915.6406\n",
      "Epoch 193/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 47175.2930 - mae: 47175.2930 - val_loss: 47859.3398 - val_mae: 47859.3398\n",
      "Epoch 194/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47136.6523 - mae: 47136.6523 - val_loss: 47798.6250 - val_mae: 47798.6250\n",
      "Epoch 195/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 47081.3633 - mae: 47081.3633 - val_loss: 47760.4883 - val_mae: 47760.4883\n",
      "Epoch 196/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47036.4570 - mae: 47036.4570 - val_loss: 47724.3203 - val_mae: 47724.3203\n",
      "Epoch 197/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 46993.7188 - mae: 46993.7188 - val_loss: 47677.8984 - val_mae: 47677.8984\n",
      "Epoch 198/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 46951.0938 - mae: 46951.0938 - val_loss: 47626.4141 - val_mae: 47626.4141\n",
      "Epoch 199/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 46906.0820 - mae: 46906.0820 - val_loss: 47580.2188 - val_mae: 47580.2148\n",
      "Epoch 200/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 46864.4414 - mae: 46864.4414 - val_loss: 47550.1445 - val_mae: 47550.1445\n",
      "Epoch 201/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 46825.9844 - mae: 46825.9844 - val_loss: 47481.7188 - val_mae: 47481.7188\n",
      "Epoch 202/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 46778.1797 - mae: 46778.1797 - val_loss: 47421.0703 - val_mae: 47421.0703\n",
      "Epoch 203/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 46733.0430 - mae: 46733.0430 - val_loss: 47396.5977 - val_mae: 47396.5977\n",
      "Epoch 204/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 46696.2734 - mae: 46696.2734 - val_loss: 47329.6875 - val_mae: 47329.6875\n",
      "Epoch 205/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 46652.3125 - mae: 46652.3125 - val_loss: 47289.2148 - val_mae: 47289.2148\n",
      "Epoch 206/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 46621.2461 - mae: 46621.2461 - val_loss: 47228.5508 - val_mae: 47228.5508\n",
      "Epoch 207/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 46578.6094 - mae: 46578.6094 - val_loss: 47195.9492 - val_mae: 47195.9492\n",
      "Epoch 208/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 46533.4297 - mae: 46533.4297 - val_loss: 47162.5156 - val_mae: 47162.5156\n",
      "Epoch 209/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 46489.5625 - mae: 46489.5625 - val_loss: 47113.6133 - val_mae: 47113.6133\n",
      "Epoch 210/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 46447.5000 - mae: 46447.5000 - val_loss: 47051.6914 - val_mae: 47051.6914\n",
      "Epoch 211/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 46403.7070 - mae: 46403.7070 - val_loss: 47004.3086 - val_mae: 47004.3086\n",
      "Epoch 212/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 46359.8984 - mae: 46359.8984 - val_loss: 46961.7344 - val_mae: 46961.7344\n",
      "Epoch 213/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 46316.0742 - mae: 46316.0742 - val_loss: 46908.7109 - val_mae: 46908.7109\n",
      "Epoch 214/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 46264.8750 - mae: 46264.8750 - val_loss: 46841.0039 - val_mae: 46841.0039\n",
      "Epoch 215/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 46224.6133 - mae: 46224.6133 - val_loss: 46781.0078 - val_mae: 46781.0078\n",
      "Epoch 216/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 46170.7305 - mae: 46170.7305 - val_loss: 46731.3711 - val_mae: 46731.3711\n",
      "Epoch 217/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 46121.8086 - mae: 46121.8086 - val_loss: 46679.9141 - val_mae: 46679.9141\n",
      "Epoch 218/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 46073.6250 - mae: 46073.6250 - val_loss: 46632.3281 - val_mae: 46632.3281\n",
      "Epoch 219/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 46034.0977 - mae: 46034.0977 - val_loss: 46554.1406 - val_mae: 46554.1406\n",
      "Epoch 220/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45967.8984 - mae: 45967.8984 - val_loss: 46502.6328 - val_mae: 46502.6328\n",
      "Epoch 221/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45919.5547 - mae: 45919.5547 - val_loss: 46463.4297 - val_mae: 46463.4297\n",
      "Epoch 222/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45872.9102 - mae: 45872.9102 - val_loss: 46406.8242 - val_mae: 46406.8242\n",
      "Epoch 223/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45823.3633 - mae: 45823.3633 - val_loss: 46344.6602 - val_mae: 46344.6602\n",
      "Epoch 224/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45780.1211 - mae: 45780.1211 - val_loss: 46300.0742 - val_mae: 46300.0742\n",
      "Epoch 225/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45732.1094 - mae: 45732.1094 - val_loss: 46235.1250 - val_mae: 46235.1250\n",
      "Epoch 226/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 45673.9180 - mae: 45673.9180 - val_loss: 46190.8398 - val_mae: 46190.8398\n",
      "Epoch 227/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 45631.0273 - mae: 45631.0273 - val_loss: 46150.6211 - val_mae: 46150.6211\n",
      "Epoch 228/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 45571.5156 - mae: 45571.5156 - val_loss: 46085.2188 - val_mae: 46085.2188\n",
      "Epoch 229/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45519.1719 - mae: 45519.1719 - val_loss: 46017.7812 - val_mae: 46017.7812\n",
      "Epoch 230/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 45469.9883 - mae: 45469.9883 - val_loss: 45957.0625 - val_mae: 45957.0625\n",
      "Epoch 231/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45419.0703 - mae: 45419.0703 - val_loss: 45893.2031 - val_mae: 45893.2031\n",
      "Epoch 232/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 45370.0195 - mae: 45370.0195 - val_loss: 45869.0117 - val_mae: 45869.0117\n",
      "Epoch 233/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45314.7070 - mae: 45314.7070 - val_loss: 45777.3086 - val_mae: 45777.3086\n",
      "Epoch 234/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 45253.2617 - mae: 45253.2617 - val_loss: 45731.2930 - val_mae: 45731.2930\n",
      "Epoch 235/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 45201.3242 - mae: 45201.3242 - val_loss: 45667.9570 - val_mae: 45667.9570\n",
      "Epoch 236/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45147.7930 - mae: 45147.7930 - val_loss: 45602.2617 - val_mae: 45602.2617\n",
      "Epoch 237/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45101.6445 - mae: 45101.6445 - val_loss: 45581.0820 - val_mae: 45581.0820\n",
      "Epoch 238/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 45055.3555 - mae: 45055.3555 - val_loss: 45512.5742 - val_mae: 45512.5703\n",
      "Epoch 239/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 45011.0820 - mae: 45011.0820 - val_loss: 45482.0234 - val_mae: 45482.0234\n",
      "Epoch 240/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44971.0195 - mae: 44971.0195 - val_loss: 45413.2109 - val_mae: 45413.2109\n",
      "Epoch 241/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44918.3594 - mae: 44918.3594 - val_loss: 45379.8477 - val_mae: 45379.8477\n",
      "Epoch 242/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44871.8359 - mae: 44871.8359 - val_loss: 45298.6523 - val_mae: 45298.6523\n",
      "Epoch 243/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44818.5703 - mae: 44818.5703 - val_loss: 45248.6523 - val_mae: 45248.6523\n",
      "Epoch 244/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44784.1133 - mae: 44784.1133 - val_loss: 45231.8984 - val_mae: 45231.8984\n",
      "Epoch 245/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 44718.7539 - mae: 44718.7539 - val_loss: 45158.0430 - val_mae: 45158.0430\n",
      "Epoch 246/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 44672.7148 - mae: 44672.7148 - val_loss: 45095.8633 - val_mae: 45095.8633\n",
      "Epoch 247/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44627.9258 - mae: 44627.9258 - val_loss: 45043.8672 - val_mae: 45043.8672\n",
      "Epoch 248/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44578.4453 - mae: 44578.4453 - val_loss: 44999.9570 - val_mae: 44999.9570\n",
      "Epoch 249/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44527.4062 - mae: 44527.4062 - val_loss: 44957.8594 - val_mae: 44957.8594\n",
      "Epoch 250/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44483.2070 - mae: 44483.2070 - val_loss: 44886.5742 - val_mae: 44886.5742\n",
      "Epoch 251/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44429.2617 - mae: 44429.2617 - val_loss: 44835.3047 - val_mae: 44835.3047\n",
      "Epoch 252/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44378.3477 - mae: 44378.3477 - val_loss: 44763.1328 - val_mae: 44763.1328\n",
      "Epoch 253/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 44320.7930 - mae: 44320.7930 - val_loss: 44708.7344 - val_mae: 44708.7305\n",
      "Epoch 254/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 44268.2188 - mae: 44268.2188 - val_loss: 44655.1992 - val_mae: 44655.1992\n",
      "Epoch 255/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44212.8438 - mae: 44212.8438 - val_loss: 44592.2070 - val_mae: 44592.2070\n",
      "Epoch 256/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44161.5469 - mae: 44161.5469 - val_loss: 44512.2266 - val_mae: 44512.2266\n",
      "Epoch 257/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44101.8750 - mae: 44101.8750 - val_loss: 44451.6445 - val_mae: 44451.6445\n",
      "Epoch 258/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44048.3086 - mae: 44048.3086 - val_loss: 44376.1328 - val_mae: 44376.1328\n",
      "Epoch 259/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 43984.1406 - mae: 43984.1406 - val_loss: 44319.4141 - val_mae: 44319.4141\n",
      "Epoch 260/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43924.2344 - mae: 43924.2344 - val_loss: 44262.2461 - val_mae: 44262.2461\n",
      "Epoch 261/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43863.8867 - mae: 43863.8867 - val_loss: 44183.2930 - val_mae: 44183.2930\n",
      "Epoch 262/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43812.2656 - mae: 43812.2656 - val_loss: 44149.4961 - val_mae: 44149.4961\n",
      "Epoch 263/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43742.7617 - mae: 43742.7617 - val_loss: 44070.9609 - val_mae: 44070.9609\n",
      "Epoch 264/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43681.1250 - mae: 43681.1250 - val_loss: 43999.1836 - val_mae: 43999.1836\n",
      "Epoch 265/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 43621.0508 - mae: 43621.0508 - val_loss: 43959.3281 - val_mae: 43959.3281\n",
      "Epoch 266/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 43561.9844 - mae: 43561.9844 - val_loss: 43848.5195 - val_mae: 43848.5195\n",
      "Epoch 267/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 43485.3125 - mae: 43485.3125 - val_loss: 43808.1953 - val_mae: 43808.1953\n",
      "Epoch 268/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 43429.4805 - mae: 43429.4805 - val_loss: 43755.7070 - val_mae: 43755.7070\n",
      "Epoch 269/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43356.8516 - mae: 43356.8516 - val_loss: 43686.6523 - val_mae: 43686.6523\n",
      "Epoch 270/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 43297.2539 - mae: 43297.2539 - val_loss: 43592.1484 - val_mae: 43592.1484\n",
      "Epoch 271/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43226.6016 - mae: 43226.6016 - val_loss: 43544.3789 - val_mae: 43544.3789\n",
      "Epoch 272/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43162.5000 - mae: 43162.5000 - val_loss: 43493.6250 - val_mae: 43493.6250\n",
      "Epoch 273/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 43098.4336 - mae: 43098.4336 - val_loss: 43421.1641 - val_mae: 43421.1641\n",
      "Epoch 274/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 43033.1719 - mae: 43033.1719 - val_loss: 43338.1680 - val_mae: 43338.1680\n",
      "Epoch 275/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42972.0859 - mae: 42972.0859 - val_loss: 43233.3516 - val_mae: 43233.3516\n",
      "Epoch 276/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 42906.1719 - mae: 42906.1719 - val_loss: 43173.5039 - val_mae: 43173.5039\n",
      "Epoch 277/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42839.9805 - mae: 42839.9805 - val_loss: 43127.1836 - val_mae: 43127.1836\n",
      "Epoch 278/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 42782.7188 - mae: 42782.7188 - val_loss: 43086.8047 - val_mae: 43086.8047\n",
      "Epoch 279/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42726.0625 - mae: 42726.0625 - val_loss: 43019.3750 - val_mae: 43019.3750\n",
      "Epoch 280/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 42667.3438 - mae: 42667.3438 - val_loss: 42953.5234 - val_mae: 42953.5234\n",
      "Epoch 281/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 42614.9570 - mae: 42614.9570 - val_loss: 42900.1562 - val_mae: 42900.1562\n",
      "Epoch 282/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42553.8906 - mae: 42553.8906 - val_loss: 42824.2734 - val_mae: 42824.2734\n",
      "Epoch 283/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42496.7539 - mae: 42496.7539 - val_loss: 42745.9727 - val_mae: 42745.9727\n",
      "Epoch 284/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42433.5352 - mae: 42433.5352 - val_loss: 42681.1523 - val_mae: 42681.1523\n",
      "Epoch 285/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42378.1523 - mae: 42378.1523 - val_loss: 42629.7812 - val_mae: 42629.7812\n",
      "Epoch 286/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42315.8047 - mae: 42315.8047 - val_loss: 42566.2578 - val_mae: 42566.2578\n",
      "Epoch 287/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42268.5664 - mae: 42268.5664 - val_loss: 42518.0156 - val_mae: 42518.0156\n",
      "Epoch 288/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42194.1016 - mae: 42194.1016 - val_loss: 42419.4219 - val_mae: 42419.4219\n",
      "Epoch 289/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42146.3438 - mae: 42146.3438 - val_loss: 42387.5117 - val_mae: 42387.5117\n",
      "Epoch 290/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 42074.6328 - mae: 42074.6328 - val_loss: 42303.8086 - val_mae: 42303.8086\n",
      "Epoch 291/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 42015.2344 - mae: 42015.2344 - val_loss: 42265.8008 - val_mae: 42265.8008\n",
      "Epoch 292/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41968.2891 - mae: 41968.2891 - val_loss: 42212.2812 - val_mae: 42212.2812\n",
      "Epoch 293/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41902.4141 - mae: 41902.4141 - val_loss: 42140.9180 - val_mae: 42140.9180\n",
      "Epoch 294/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41847.3906 - mae: 41847.3906 - val_loss: 42106.5312 - val_mae: 42106.5312\n",
      "Epoch 295/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41786.8477 - mae: 41786.8477 - val_loss: 42017.2070 - val_mae: 42017.2070\n",
      "Epoch 296/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41731.2656 - mae: 41731.2656 - val_loss: 41954.5234 - val_mae: 41954.5234\n",
      "Epoch 297/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41670.9297 - mae: 41670.9297 - val_loss: 41881.9648 - val_mae: 41881.9648\n",
      "Epoch 298/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41612.7070 - mae: 41612.7070 - val_loss: 41804.1523 - val_mae: 41804.1523\n",
      "Epoch 299/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41549.9883 - mae: 41549.9883 - val_loss: 41755.1250 - val_mae: 41755.1250\n",
      "Epoch 300/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 41489.5547 - mae: 41489.5547 - val_loss: 41716.3633 - val_mae: 41716.3633\n",
      "Epoch 301/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41428.4492 - mae: 41428.4492 - val_loss: 41657.5430 - val_mae: 41657.5430\n",
      "Epoch 302/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41372.5234 - mae: 41372.5234 - val_loss: 41552.7422 - val_mae: 41552.7422\n",
      "Epoch 303/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41303.1250 - mae: 41303.1250 - val_loss: 41489.8086 - val_mae: 41489.8086\n",
      "Epoch 304/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41243.0117 - mae: 41243.0117 - val_loss: 41407.9180 - val_mae: 41407.9180\n",
      "Epoch 305/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41180.0352 - mae: 41180.0352 - val_loss: 41358.4023 - val_mae: 41358.4023\n",
      "Epoch 306/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 41117.2656 - mae: 41117.2656 - val_loss: 41300.2773 - val_mae: 41300.2773\n",
      "Epoch 307/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 41049.5781 - mae: 41049.5781 - val_loss: 41229.2891 - val_mae: 41229.2891\n",
      "Epoch 308/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40986.0039 - mae: 40986.0039 - val_loss: 41162.2383 - val_mae: 41162.2383\n",
      "Epoch 309/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40920.3477 - mae: 40920.3477 - val_loss: 41088.3398 - val_mae: 41088.3398\n",
      "Epoch 310/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40851.7812 - mae: 40851.7812 - val_loss: 41004.5312 - val_mae: 41004.5312\n",
      "Epoch 311/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40781.9727 - mae: 40781.9727 - val_loss: 40934.3711 - val_mae: 40934.3711\n",
      "Epoch 312/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40714.9688 - mae: 40714.9688 - val_loss: 40851.7656 - val_mae: 40851.7656\n",
      "Epoch 313/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40646.0156 - mae: 40646.0156 - val_loss: 40800.5273 - val_mae: 40800.5273\n",
      "Epoch 314/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40567.7656 - mae: 40567.7656 - val_loss: 40722.9023 - val_mae: 40722.9023\n",
      "Epoch 315/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40501.9688 - mae: 40501.9688 - val_loss: 40669.6875 - val_mae: 40669.6875\n",
      "Epoch 316/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 40443.1758 - mae: 40443.1758 - val_loss: 40610.9180 - val_mae: 40610.9180\n",
      "Epoch 317/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 40382.7930 - mae: 40382.7930 - val_loss: 40521.0430 - val_mae: 40521.0430\n",
      "Epoch 318/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 40317.1875 - mae: 40317.1875 - val_loss: 40463.0156 - val_mae: 40463.0156\n",
      "Epoch 319/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40256.7070 - mae: 40256.7070 - val_loss: 40400.5312 - val_mae: 40400.5312\n",
      "Epoch 320/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 40194.4961 - mae: 40194.4961 - val_loss: 40335.5156 - val_mae: 40335.5156\n",
      "Epoch 321/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 40135.4844 - mae: 40135.4844 - val_loss: 40243.8789 - val_mae: 40243.8789\n",
      "Epoch 322/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 40073.5234 - mae: 40073.5234 - val_loss: 40193.9336 - val_mae: 40193.9336\n",
      "Epoch 323/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 40013.0117 - mae: 40013.0117 - val_loss: 40127.8750 - val_mae: 40127.8750\n",
      "Epoch 324/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39952.9688 - mae: 39952.9688 - val_loss: 40061.0000 - val_mae: 40061.0000\n",
      "Epoch 325/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39900.1250 - mae: 39900.1250 - val_loss: 40020.2266 - val_mae: 40020.2266\n",
      "Epoch 326/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39850.5469 - mae: 39850.5469 - val_loss: 39970.9297 - val_mae: 39970.9297\n",
      "Epoch 327/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39798.7812 - mae: 39798.7812 - val_loss: 39905.6992 - val_mae: 39905.6992\n",
      "Epoch 328/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39748.0078 - mae: 39748.0078 - val_loss: 39852.7070 - val_mae: 39852.7070\n",
      "Epoch 329/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39704.2539 - mae: 39704.2539 - val_loss: 39840.3750 - val_mae: 39840.3750\n",
      "Epoch 330/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39651.1484 - mae: 39651.1484 - val_loss: 39775.0273 - val_mae: 39775.0273\n",
      "Epoch 331/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 39597.9570 - mae: 39597.9570 - val_loss: 39714.9688 - val_mae: 39714.9688\n",
      "Epoch 332/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39546.0781 - mae: 39546.0781 - val_loss: 39644.4883 - val_mae: 39644.4883\n",
      "Epoch 333/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39493.7070 - mae: 39493.7070 - val_loss: 39592.2461 - val_mae: 39592.2461\n",
      "Epoch 334/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 39438.1758 - mae: 39438.1758 - val_loss: 39534.1641 - val_mae: 39534.1641\n",
      "Epoch 335/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 39383.2305 - mae: 39383.2305 - val_loss: 39479.3477 - val_mae: 39479.3477\n",
      "Epoch 336/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39338.3516 - mae: 39338.3516 - val_loss: 39441.1914 - val_mae: 39441.1914\n",
      "Epoch 337/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39275.6445 - mae: 39275.6445 - val_loss: 39389.3711 - val_mae: 39389.3711\n",
      "Epoch 338/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39228.4062 - mae: 39228.4062 - val_loss: 39316.4922 - val_mae: 39316.4922\n",
      "Epoch 339/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39168.7891 - mae: 39168.7891 - val_loss: 39260.6680 - val_mae: 39260.6680\n",
      "Epoch 340/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 39112.0977 - mae: 39112.0977 - val_loss: 39202.3984 - val_mae: 39202.3984\n",
      "Epoch 341/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39057.0859 - mae: 39057.0859 - val_loss: 39149.5586 - val_mae: 39149.5586\n",
      "Epoch 342/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 39001.6719 - mae: 39001.6719 - val_loss: 39084.7266 - val_mae: 39084.7266\n",
      "Epoch 343/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38941.8867 - mae: 38941.8867 - val_loss: 39027.3828 - val_mae: 39027.3828\n",
      "Epoch 344/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38880.8164 - mae: 38880.8164 - val_loss: 38962.1602 - val_mae: 38962.1602\n",
      "Epoch 345/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38819.7383 - mae: 38819.7383 - val_loss: 38885.7266 - val_mae: 38885.7305\n",
      "Epoch 346/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38757.2578 - mae: 38757.2578 - val_loss: 38813.8984 - val_mae: 38813.8984\n",
      "Epoch 347/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38692.4727 - mae: 38692.4727 - val_loss: 38750.8594 - val_mae: 38750.8594\n",
      "Epoch 348/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38631.8789 - mae: 38631.8789 - val_loss: 38688.6172 - val_mae: 38688.6172\n",
      "Epoch 349/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38574.3711 - mae: 38574.3711 - val_loss: 38604.0000 - val_mae: 38604.0000\n",
      "Epoch 350/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38495.3359 - mae: 38495.3359 - val_loss: 38542.9688 - val_mae: 38542.9688\n",
      "Epoch 351/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 38430.3477 - mae: 38430.3477 - val_loss: 38493.3750 - val_mae: 38493.3750\n",
      "Epoch 352/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38360.1289 - mae: 38360.1289 - val_loss: 38422.4297 - val_mae: 38422.4297\n",
      "Epoch 353/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38296.5039 - mae: 38296.5039 - val_loss: 38327.6719 - val_mae: 38327.6719\n",
      "Epoch 354/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 38234.7227 - mae: 38234.7227 - val_loss: 38306.8594 - val_mae: 38306.8594\n",
      "Epoch 355/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38198.1211 - mae: 38198.1211 - val_loss: 38267.0117 - val_mae: 38267.0117\n",
      "Epoch 356/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 38155.8477 - mae: 38155.8477 - val_loss: 38228.5430 - val_mae: 38228.5430\n",
      "Epoch 357/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 38109.3242 - mae: 38109.3242 - val_loss: 38173.7891 - val_mae: 38173.7891\n",
      "Epoch 358/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 38068.8125 - mae: 38068.8125 - val_loss: 38131.5703 - val_mae: 38131.5703\n",
      "Epoch 359/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 38026.1797 - mae: 38026.1797 - val_loss: 38085.8242 - val_mae: 38085.8242\n",
      "Epoch 360/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 37980.8086 - mae: 37980.8086 - val_loss: 38023.2422 - val_mae: 38023.2422\n",
      "Epoch 361/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 37934.0859 - mae: 37934.0859 - val_loss: 37982.4062 - val_mae: 37982.4062\n",
      "Epoch 362/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37887.0156 - mae: 37887.0156 - val_loss: 37927.6445 - val_mae: 37927.6445\n",
      "Epoch 363/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37842.0469 - mae: 37842.0469 - val_loss: 37893.1602 - val_mae: 37893.1602\n",
      "Epoch 364/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 37796.7344 - mae: 37796.7344 - val_loss: 37818.2773 - val_mae: 37818.2773\n",
      "Epoch 365/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37741.2188 - mae: 37741.2188 - val_loss: 37766.4258 - val_mae: 37766.4258\n",
      "Epoch 366/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37690.6445 - mae: 37690.6445 - val_loss: 37707.0625 - val_mae: 37707.0625\n",
      "Epoch 367/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37638.6641 - mae: 37638.6641 - val_loss: 37658.5781 - val_mae: 37658.5781\n",
      "Epoch 368/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 37584.6055 - mae: 37584.6055 - val_loss: 37599.5781 - val_mae: 37599.5781\n",
      "Epoch 369/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37533.7852 - mae: 37533.7852 - val_loss: 37542.6914 - val_mae: 37542.6914\n",
      "Epoch 370/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37477.2891 - mae: 37477.2891 - val_loss: 37482.6836 - val_mae: 37482.6836\n",
      "Epoch 371/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37419.4023 - mae: 37419.4023 - val_loss: 37431.0547 - val_mae: 37431.0547\n",
      "Epoch 372/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 37368.6250 - mae: 37368.6250 - val_loss: 37383.2773 - val_mae: 37383.2773\n",
      "Epoch 373/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 37308.5352 - mae: 37308.5352 - val_loss: 37318.1445 - val_mae: 37318.1445\n",
      "Epoch 374/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37247.3203 - mae: 37247.3203 - val_loss: 37250.1914 - val_mae: 37250.1914\n",
      "Epoch 375/500\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 37187.7461 - mae: 37187.7461 - val_loss: 37190.7734 - val_mae: 37190.7734\n",
      "Epoch 376/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37131.4570 - mae: 37131.4570 - val_loss: 37107.8750 - val_mae: 37107.8750\n",
      "Epoch 377/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37064.7578 - mae: 37064.7578 - val_loss: 37036.1250 - val_mae: 37036.1250\n",
      "Epoch 378/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36999.4375 - mae: 36999.4375 - val_loss: 36979.0664 - val_mae: 36979.0664\n",
      "Epoch 379/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36934.9688 - mae: 36934.9688 - val_loss: 36915.0938 - val_mae: 36915.0938\n",
      "Epoch 380/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36870.1016 - mae: 36870.1016 - val_loss: 36856.3438 - val_mae: 36856.3438\n",
      "Epoch 381/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36809.6680 - mae: 36809.6680 - val_loss: 36793.2852 - val_mae: 36793.2852\n",
      "Epoch 382/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36748.6953 - mae: 36748.6953 - val_loss: 36718.1445 - val_mae: 36718.1445\n",
      "Epoch 383/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36691.7070 - mae: 36691.7070 - val_loss: 36647.7109 - val_mae: 36647.7109\n",
      "Epoch 384/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36641.2578 - mae: 36641.2578 - val_loss: 36627.4727 - val_mae: 36627.4727\n",
      "Epoch 385/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36575.1758 - mae: 36575.1758 - val_loss: 36548.7578 - val_mae: 36548.7578\n",
      "Epoch 386/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36515.6016 - mae: 36515.6016 - val_loss: 36488.6406 - val_mae: 36488.6406\n",
      "Epoch 387/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36462.5508 - mae: 36462.5508 - val_loss: 36425.8945 - val_mae: 36425.8945\n",
      "Epoch 388/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36408.4844 - mae: 36408.4844 - val_loss: 36366.7969 - val_mae: 36366.7969\n",
      "Epoch 389/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36347.6992 - mae: 36347.6992 - val_loss: 36317.1836 - val_mae: 36317.1836\n",
      "Epoch 390/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36290.1289 - mae: 36290.1289 - val_loss: 36256.0234 - val_mae: 36256.0234\n",
      "Epoch 391/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36230.1562 - mae: 36230.1562 - val_loss: 36187.1797 - val_mae: 36187.1797\n",
      "Epoch 392/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36168.6992 - mae: 36168.6992 - val_loss: 36120.6250 - val_mae: 36120.6250\n",
      "Epoch 393/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 36107.4023 - mae: 36107.4023 - val_loss: 36049.9023 - val_mae: 36049.9023\n",
      "Epoch 394/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36050.0273 - mae: 36050.0273 - val_loss: 36001.5234 - val_mae: 36001.5234\n",
      "Epoch 395/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35999.6758 - mae: 35999.6758 - val_loss: 35955.9141 - val_mae: 35955.9141\n",
      "Epoch 396/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35947.5117 - mae: 35947.5117 - val_loss: 35898.2070 - val_mae: 35898.2070\n",
      "Epoch 397/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35886.2148 - mae: 35886.2148 - val_loss: 35817.4258 - val_mae: 35817.4258\n",
      "Epoch 398/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 35854.4805 - mae: 35854.4805 - val_loss: 35746.4258 - val_mae: 35746.4258\n",
      "Epoch 399/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35772.3555 - mae: 35772.3555 - val_loss: 35694.5273 - val_mae: 35694.5273\n",
      "Epoch 400/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 35715.1797 - mae: 35715.1797 - val_loss: 35629.2422 - val_mae: 35629.2422\n",
      "Epoch 401/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35649.3008 - mae: 35649.3008 - val_loss: 35573.5547 - val_mae: 35573.5547\n",
      "Epoch 402/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 35592.2695 - mae: 35592.2695 - val_loss: 35520.9570 - val_mae: 35520.9570\n",
      "Epoch 403/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35530.4141 - mae: 35530.4141 - val_loss: 35458.9336 - val_mae: 35458.9336\n",
      "Epoch 404/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35475.5039 - mae: 35475.5039 - val_loss: 35396.3867 - val_mae: 35396.3867\n",
      "Epoch 405/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 35405.6211 - mae: 35405.6211 - val_loss: 35339.3555 - val_mae: 35339.3555\n",
      "Epoch 406/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35344.0039 - mae: 35344.0039 - val_loss: 35276.0078 - val_mae: 35276.0078\n",
      "Epoch 407/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35279.6445 - mae: 35279.6445 - val_loss: 35218.8750 - val_mae: 35218.8750\n",
      "Epoch 408/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35214.4180 - mae: 35214.4180 - val_loss: 35150.0117 - val_mae: 35150.0117\n",
      "Epoch 409/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35143.1055 - mae: 35143.1055 - val_loss: 35091.8047 - val_mae: 35091.8047\n",
      "Epoch 410/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 35094.9062 - mae: 35094.9062 - val_loss: 35050.8711 - val_mae: 35050.8711\n",
      "Epoch 411/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 35051.9922 - mae: 35051.9922 - val_loss: 35016.2383 - val_mae: 35016.2383\n",
      "Epoch 412/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 35020.4805 - mae: 35020.4805 - val_loss: 34977.1641 - val_mae: 34977.1641\n",
      "Epoch 413/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34976.9219 - mae: 34976.9219 - val_loss: 34942.1211 - val_mae: 34942.1211\n",
      "Epoch 414/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34938.0391 - mae: 34938.0391 - val_loss: 34898.8086 - val_mae: 34898.8086\n",
      "Epoch 415/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34895.8398 - mae: 34895.8398 - val_loss: 34866.9414 - val_mae: 34866.9414\n",
      "Epoch 416/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34859.0273 - mae: 34859.0273 - val_loss: 34829.9570 - val_mae: 34829.9570\n",
      "Epoch 417/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34822.6758 - mae: 34822.6758 - val_loss: 34789.8086 - val_mae: 34789.8086\n",
      "Epoch 418/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34780.4961 - mae: 34780.4961 - val_loss: 34749.6250 - val_mae: 34749.6250\n",
      "Epoch 419/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 34742.6953 - mae: 34742.6953 - val_loss: 34708.9062 - val_mae: 34708.9062\n",
      "Epoch 420/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34702.0352 - mae: 34702.0352 - val_loss: 34670.3477 - val_mae: 34670.3477\n",
      "Epoch 421/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34660.7148 - mae: 34660.7148 - val_loss: 34631.3555 - val_mae: 34631.3555\n",
      "Epoch 422/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34621.6016 - mae: 34621.6016 - val_loss: 34589.9688 - val_mae: 34589.9688\n",
      "Epoch 423/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 34581.8945 - mae: 34581.8945 - val_loss: 34551.6602 - val_mae: 34551.6602\n",
      "Epoch 424/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34544.4570 - mae: 34544.4570 - val_loss: 34511.3789 - val_mae: 34511.3789\n",
      "Epoch 425/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 34502.6562 - mae: 34502.6562 - val_loss: 34463.3828 - val_mae: 34463.3828\n",
      "Epoch 426/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34461.5273 - mae: 34461.5273 - val_loss: 34426.4844 - val_mae: 34426.4844\n",
      "Epoch 427/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34423.2891 - mae: 34423.2891 - val_loss: 34381.0078 - val_mae: 34381.0078\n",
      "Epoch 428/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34378.7266 - mae: 34378.7266 - val_loss: 34333.0352 - val_mae: 34333.0352\n",
      "Epoch 429/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 34341.3594 - mae: 34341.3594 - val_loss: 34296.5430 - val_mae: 34296.5430\n",
      "Epoch 430/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34296.7344 - mae: 34296.7344 - val_loss: 34246.2891 - val_mae: 34246.2891\n",
      "Epoch 431/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34275.7734 - mae: 34275.7734 - val_loss: 34195.4258 - val_mae: 34195.4258\n",
      "Epoch 432/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34204.6836 - mae: 34204.6836 - val_loss: 34152.9727 - val_mae: 34152.9727\n",
      "Epoch 433/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34164.8086 - mae: 34164.8086 - val_loss: 34106.2461 - val_mae: 34106.2461\n",
      "Epoch 434/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34122.6953 - mae: 34122.6953 - val_loss: 34061.0273 - val_mae: 34061.0273\n",
      "Epoch 435/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34077.9258 - mae: 34077.9258 - val_loss: 34009.6289 - val_mae: 34009.6289\n",
      "Epoch 436/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 34026.8047 - mae: 34026.8047 - val_loss: 33957.8711 - val_mae: 33957.8711\n",
      "Epoch 437/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 34006.7773 - mae: 34006.7773 - val_loss: 33906.1523 - val_mae: 33906.1523\n",
      "Epoch 438/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33942.2070 - mae: 33942.2070 - val_loss: 33858.4062 - val_mae: 33858.4062\n",
      "Epoch 439/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33893.7695 - mae: 33893.7695 - val_loss: 33820.3359 - val_mae: 33820.3359\n",
      "Epoch 440/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33858.3125 - mae: 33858.3125 - val_loss: 33781.7539 - val_mae: 33781.7539\n",
      "Epoch 441/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 33824.0703 - mae: 33824.0703 - val_loss: 33743.3281 - val_mae: 33743.3281\n",
      "Epoch 442/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33777.8555 - mae: 33777.8555 - val_loss: 33695.9531 - val_mae: 33695.9531\n",
      "Epoch 443/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33738.2773 - mae: 33738.2773 - val_loss: 33645.4531 - val_mae: 33645.4531\n",
      "Epoch 444/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33693.3203 - mae: 33693.3203 - val_loss: 33602.1250 - val_mae: 33602.1250\n",
      "Epoch 445/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33657.1172 - mae: 33657.1172 - val_loss: 33556.5391 - val_mae: 33556.5391\n",
      "Epoch 446/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33609.3789 - mae: 33609.3789 - val_loss: 33512.4453 - val_mae: 33512.4453\n",
      "Epoch 447/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33566.8984 - mae: 33566.8984 - val_loss: 33465.1289 - val_mae: 33465.1289\n",
      "Epoch 448/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33526.2500 - mae: 33526.2500 - val_loss: 33431.8203 - val_mae: 33431.8203\n",
      "Epoch 449/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33495.2266 - mae: 33495.2266 - val_loss: 33398.6758 - val_mae: 33398.6758\n",
      "Epoch 450/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33465.6211 - mae: 33465.6211 - val_loss: 33367.2461 - val_mae: 33367.2461\n",
      "Epoch 451/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33437.4297 - mae: 33437.4297 - val_loss: 33337.9102 - val_mae: 33337.9102\n",
      "Epoch 452/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33413.6250 - mae: 33413.6250 - val_loss: 33307.2578 - val_mae: 33307.2578\n",
      "Epoch 453/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33381.5859 - mae: 33381.5859 - val_loss: 33274.3203 - val_mae: 33274.3203\n",
      "Epoch 454/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33349.3867 - mae: 33349.3867 - val_loss: 33240.3633 - val_mae: 33240.3633\n",
      "Epoch 455/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33314.6992 - mae: 33314.6992 - val_loss: 33208.6367 - val_mae: 33208.6367\n",
      "Epoch 456/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33286.0820 - mae: 33286.0820 - val_loss: 33176.1250 - val_mae: 33176.1250\n",
      "Epoch 457/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 33256.1992 - mae: 33256.1992 - val_loss: 33139.6914 - val_mae: 33139.6914\n",
      "Epoch 458/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33221.5977 - mae: 33221.5977 - val_loss: 33105.2734 - val_mae: 33105.2734\n",
      "Epoch 459/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 33184.6758 - mae: 33184.6758 - val_loss: 33069.7383 - val_mae: 33069.7383\n",
      "Epoch 460/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 33151.6250 - mae: 33151.6250 - val_loss: 33032.7539 - val_mae: 33032.7539\n",
      "Epoch 461/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33119.8477 - mae: 33119.8477 - val_loss: 32998.8750 - val_mae: 32998.8750\n",
      "Epoch 462/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33079.5430 - mae: 33079.5430 - val_loss: 32962.5703 - val_mae: 32962.5703\n",
      "Epoch 463/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 33048.8984 - mae: 33048.8984 - val_loss: 32926.6953 - val_mae: 32926.6953\n",
      "Epoch 464/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 33005.8594 - mae: 33005.8594 - val_loss: 32894.0039 - val_mae: 32894.0039\n",
      "Epoch 465/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32974.7344 - mae: 32974.7344 - val_loss: 32859.3672 - val_mae: 32859.3672\n",
      "Epoch 466/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32935.6797 - mae: 32935.6797 - val_loss: 32817.2539 - val_mae: 32817.2539\n",
      "Epoch 467/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32898.4219 - mae: 32898.4219 - val_loss: 32779.4570 - val_mae: 32779.4570\n",
      "Epoch 468/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32857.1406 - mae: 32857.1406 - val_loss: 32743.4688 - val_mae: 32743.4688\n",
      "Epoch 469/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32817.7695 - mae: 32817.7695 - val_loss: 32708.4961 - val_mae: 32708.4961\n",
      "Epoch 470/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 32777.8555 - mae: 32777.8555 - val_loss: 32664.4902 - val_mae: 32664.4902\n",
      "Epoch 471/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32751.8184 - mae: 32751.8184 - val_loss: 32639.0273 - val_mae: 32639.0273\n",
      "Epoch 472/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32693.3906 - mae: 32693.3906 - val_loss: 32586.5781 - val_mae: 32586.5781\n",
      "Epoch 473/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 32673.0586 - mae: 32673.0586 - val_loss: 32546.8184 - val_mae: 32546.8184\n",
      "Epoch 474/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32630.3691 - mae: 32630.3691 - val_loss: 32512.4785 - val_mae: 32512.4785\n",
      "Epoch 475/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32570.7012 - mae: 32570.7012 - val_loss: 32466.5625 - val_mae: 32466.5625\n",
      "Epoch 476/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32539.0762 - mae: 32539.0762 - val_loss: 32426.1445 - val_mae: 32426.1445\n",
      "Epoch 477/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32489.4648 - mae: 32489.4648 - val_loss: 32386.3398 - val_mae: 32386.3398\n",
      "Epoch 478/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32450.0859 - mae: 32450.0859 - val_loss: 32345.3555 - val_mae: 32345.3555\n",
      "Epoch 479/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32409.7227 - mae: 32409.7227 - val_loss: 32306.2812 - val_mae: 32306.2812\n",
      "Epoch 480/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32365.0762 - mae: 32365.0762 - val_loss: 32264.7871 - val_mae: 32264.7871\n",
      "Epoch 481/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32321.2676 - mae: 32321.2676 - val_loss: 32228.1914 - val_mae: 32228.1914\n",
      "Epoch 482/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32275.5488 - mae: 32275.5488 - val_loss: 32186.3086 - val_mae: 32186.3086\n",
      "Epoch 483/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32235.3691 - mae: 32235.3691 - val_loss: 32151.1191 - val_mae: 32151.1191\n",
      "Epoch 484/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 32205.4590 - mae: 32205.4590 - val_loss: 32114.1328 - val_mae: 32114.1328\n",
      "Epoch 485/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32156.8965 - mae: 32156.8965 - val_loss: 32075.1309 - val_mae: 32075.1309\n",
      "Epoch 486/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32113.4141 - mae: 32113.4141 - val_loss: 32038.6816 - val_mae: 32038.6816\n",
      "Epoch 487/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 32073.1445 - mae: 32073.1445 - val_loss: 31999.1543 - val_mae: 31999.1543\n",
      "Epoch 488/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 32031.1602 - mae: 32031.1602 - val_loss: 31966.4961 - val_mae: 31966.4961\n",
      "Epoch 489/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31994.2734 - mae: 31994.2734 - val_loss: 31926.8965 - val_mae: 31926.8965\n",
      "Epoch 490/500\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 31954.1094 - mae: 31954.1094 - val_loss: 31884.4590 - val_mae: 31884.4590\n",
      "Epoch 491/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 31916.3809 - mae: 31916.3809 - val_loss: 31855.8965 - val_mae: 31855.8965\n",
      "Epoch 492/500\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 31868.2266 - mae: 31868.2266 - val_loss: 31811.3691 - val_mae: 31811.3691\n",
      "Epoch 493/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31852.8457 - mae: 31852.8457 - val_loss: 31782.1875 - val_mae: 31782.1875\n",
      "Epoch 494/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31793.7852 - mae: 31793.7852 - val_loss: 31741.9961 - val_mae: 31741.9961\n",
      "Epoch 495/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31751.0039 - mae: 31751.0039 - val_loss: 31710.5820 - val_mae: 31710.5820\n",
      "Epoch 496/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31714.7500 - mae: 31714.7500 - val_loss: 31671.7129 - val_mae: 31671.7129\n",
      "Epoch 497/500\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 31678.7812 - mae: 31678.7812 - val_loss: 31637.6816 - val_mae: 31637.6816\n",
      "Epoch 498/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31638.3809 - mae: 31638.3809 - val_loss: 31606.9727 - val_mae: 31606.9727\n",
      "Epoch 499/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31603.3145 - mae: 31603.3145 - val_loss: 31574.1230 - val_mae: 31574.1230\n",
      "Epoch 500/500\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 31571.4355 - mae: 31571.4355 - val_loss: 31548.8594 - val_mae: 31548.8594\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=500, batch_size=64, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ж, видимо, ставить маленький шаг всё же не лучшая идея, так как хоть мы и точны, но сходимся ну уж очень медленно (а при больших данных мы и вовсе будем наблюдать скачок во времени обучения с 1-2 дней на целые недели)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем функцию потерь `msle`, логарифмическую модицификацию функции потерь `mse` (зная, что логарифм растёт достаточно медленно, делаем вывод о ключевой особенности этого подхода - он снижает влияние выбросов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='linear'),\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "random.set_seed(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "model.compile(optimizer=Adamax(learning_rate=0.01),\n",
    "              loss='msle',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n",
      "37/37 [==============================] - 1s 9ms/step - loss: 43.1601 - mae: 181580.8281 - val_loss: 22.4318 - val_mae: 174707.5312\n",
      "Epoch 2/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 17.6755 - mae: 179404.4688 - val_loss: 13.4532 - val_mae: 171916.0781\n",
      "Epoch 3/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 11.5248 - mae: 176234.2500 - val_loss: 9.3930 - val_mae: 168373.9375\n",
      "Epoch 4/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 8.3623 - mae: 172454.3594 - val_loss: 7.0311 - val_mae: 164347.1719\n",
      "Epoch 5/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 6.4074 - mae: 168256.9375 - val_loss: 5.4784 - val_mae: 159978.1406\n",
      "Epoch 6/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 5.0765 - mae: 163799.1719 - val_loss: 4.3910 - val_mae: 155406.7188\n",
      "Epoch 7/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 4.1172 - mae: 159135.5000 - val_loss: 3.5807 - val_mae: 150633.3906\n",
      "Epoch 8/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 3.3937 - mae: 154330.9375 - val_loss: 2.9640 - val_mae: 145765.1719\n",
      "Epoch 9/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.8328 - mae: 149409.7969 - val_loss: 2.4792 - val_mae: 140803.6719\n",
      "Epoch 10/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.3872 - mae: 144441.5312 - val_loss: 2.0920 - val_mae: 135796.8281\n",
      "Epoch 11/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 2.0274 - mae: 139434.5469 - val_loss: 1.7779 - val_mae: 130764.2031\n",
      "Epoch 12/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.7328 - mae: 134426.2969 - val_loss: 1.5196 - val_mae: 125743.9844\n",
      "Epoch 13/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.4898 - mae: 129367.6172 - val_loss: 1.3036 - val_mae: 120684.9141\n",
      "Epoch 14/750\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.2860 - mae: 124393.3828 - val_loss: 1.1256 - val_mae: 115728.1641\n",
      "Epoch 15/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.1153 - mae: 119446.9453 - val_loss: 0.9750 - val_mae: 110844.5625\n",
      "Epoch 16/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9709 - mae: 114552.9688 - val_loss: 0.8476 - val_mae: 106011.9766\n",
      "Epoch 17/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.8484 - mae: 109738.5859 - val_loss: 0.7396 - val_mae: 101277.9688\n",
      "Epoch 18/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.7439 - mae: 105007.2422 - val_loss: 0.6488 - val_mae: 96700.4844\n",
      "Epoch 19/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.6551 - mae: 100381.2656 - val_loss: 0.5702 - val_mae: 92244.6875\n",
      "Epoch 20/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.5789 - mae: 95906.6562 - val_loss: 0.5035 - val_mae: 88018.2891\n",
      "Epoch 21/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.5135 - mae: 91600.8672 - val_loss: 0.4463 - val_mae: 83963.3594\n",
      "Epoch 22/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4574 - mae: 87445.7500 - val_loss: 0.3979 - val_mae: 80128.4297\n",
      "Epoch 23/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4093 - mae: 83590.4375 - val_loss: 0.3571 - val_mae: 76480.5625\n",
      "Epoch 24/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3681 - mae: 79925.6797 - val_loss: 0.3220 - val_mae: 73062.9219\n",
      "Epoch 25/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3327 - mae: 76486.8594 - val_loss: 0.2920 - val_mae: 69923.9375\n",
      "Epoch 26/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3024 - mae: 73297.0781 - val_loss: 0.2659 - val_mae: 67046.6250\n",
      "Epoch 27/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2763 - mae: 70402.9141 - val_loss: 0.2444 - val_mae: 64519.6562\n",
      "Epoch 28/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2542 - mae: 67788.9219 - val_loss: 0.2260 - val_mae: 62243.1172\n",
      "Epoch 29/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2352 - mae: 65387.8438 - val_loss: 0.2109 - val_mae: 60295.8438\n",
      "Epoch 30/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2193 - mae: 63259.3164 - val_loss: 0.1977 - val_mae: 58579.2266\n",
      "Epoch 31/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2055 - mae: 61382.0703 - val_loss: 0.1871 - val_mae: 57121.8828\n",
      "Epoch 32/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1941 - mae: 59831.5000 - val_loss: 0.1782 - val_mae: 55812.0625\n",
      "Epoch 33/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1843 - mae: 58456.4805 - val_loss: 0.1707 - val_mae: 54696.1641\n",
      "Epoch 34/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1762 - mae: 57328.6133 - val_loss: 0.1648 - val_mae: 53814.0430\n",
      "Epoch 35/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1694 - mae: 56402.6094 - val_loss: 0.1598 - val_mae: 53126.5938\n",
      "Epoch 36/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1637 - mae: 55638.0703 - val_loss: 0.1558 - val_mae: 52630.3867\n",
      "Epoch 37/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1590 - mae: 54951.8750 - val_loss: 0.1526 - val_mae: 52233.9297\n",
      "Epoch 38/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1551 - mae: 54484.3281 - val_loss: 0.1501 - val_mae: 51935.0195\n",
      "Epoch 39/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1519 - mae: 54103.7695 - val_loss: 0.1481 - val_mae: 51668.5508\n",
      "Epoch 40/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1493 - mae: 53788.2031 - val_loss: 0.1466 - val_mae: 51451.2227\n",
      "Epoch 41/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1472 - mae: 53555.9492 - val_loss: 0.1454 - val_mae: 51283.5977\n",
      "Epoch 42/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1455 - mae: 53406.4023 - val_loss: 0.1445 - val_mae: 51148.6953\n",
      "Epoch 43/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1441 - mae: 53274.2383 - val_loss: 0.1439 - val_mae: 51043.4844\n",
      "Epoch 44/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1430 - mae: 53161.3672 - val_loss: 0.1435 - val_mae: 50977.7734\n",
      "Epoch 45/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1421 - mae: 53113.5547 - val_loss: 0.1431 - val_mae: 50927.5742\n",
      "Epoch 46/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1413 - mae: 53057.8359 - val_loss: 0.1429 - val_mae: 50916.8945\n",
      "Epoch 47/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1408 - mae: 53046.8711 - val_loss: 0.1428 - val_mae: 50921.2930\n",
      "Epoch 48/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1403 - mae: 53006.2148 - val_loss: 0.1426 - val_mae: 50923.5977\n",
      "Epoch 49/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1399 - mae: 52984.0195 - val_loss: 0.1426 - val_mae: 50927.3984\n",
      "Epoch 50/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1396 - mae: 52972.8789 - val_loss: 0.1425 - val_mae: 50943.1953\n",
      "Epoch 51/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1393 - mae: 52972.5977 - val_loss: 0.1425 - val_mae: 50964.0820\n",
      "Epoch 52/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1390 - mae: 52946.7734 - val_loss: 0.1424 - val_mae: 50963.8633\n",
      "Epoch 53/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1388 - mae: 52949.0273 - val_loss: 0.1424 - val_mae: 50980.4297\n",
      "Epoch 54/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1386 - mae: 52919.4102 - val_loss: 0.1422 - val_mae: 50958.5781\n",
      "Epoch 55/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1384 - mae: 52899.2461 - val_loss: 0.1421 - val_mae: 50951.7109\n",
      "Epoch 56/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1382 - mae: 52886.9922 - val_loss: 0.1420 - val_mae: 50952.0000\n",
      "Epoch 57/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1380 - mae: 52877.8867 - val_loss: 0.1420 - val_mae: 50955.4531\n",
      "Epoch 58/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1378 - mae: 52840.8125 - val_loss: 0.1418 - val_mae: 50914.0977\n",
      "Epoch 59/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1376 - mae: 52844.9141 - val_loss: 0.1417 - val_mae: 50921.7617\n",
      "Epoch 60/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1374 - mae: 52796.9688 - val_loss: 0.1415 - val_mae: 50874.5039\n",
      "Epoch 61/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1371 - mae: 52763.3906 - val_loss: 0.1414 - val_mae: 50861.3477\n",
      "Epoch 62/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1369 - mae: 52731.5742 - val_loss: 0.1411 - val_mae: 50808.8359\n",
      "Epoch 63/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1367 - mae: 52684.0156 - val_loss: 0.1409 - val_mae: 50770.3320\n",
      "Epoch 64/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1365 - mae: 52659.6211 - val_loss: 0.1407 - val_mae: 50730.5000\n",
      "Epoch 65/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1363 - mae: 52596.9492 - val_loss: 0.1404 - val_mae: 50672.6758\n",
      "Epoch 66/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1360 - mae: 52554.2344 - val_loss: 0.1402 - val_mae: 50635.7773\n",
      "Epoch 67/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1358 - mae: 52498.0703 - val_loss: 0.1398 - val_mae: 50554.1602\n",
      "Epoch 68/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1355 - mae: 52460.7461 - val_loss: 0.1396 - val_mae: 50519.1250\n",
      "Epoch 69/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1352 - mae: 52396.4180 - val_loss: 0.1392 - val_mae: 50427.6523\n",
      "Epoch 70/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1349 - mae: 52331.1602 - val_loss: 0.1389 - val_mae: 50381.5703\n",
      "Epoch 71/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1347 - mae: 52302.9102 - val_loss: 0.1387 - val_mae: 50339.5156\n",
      "Epoch 72/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1343 - mae: 52220.7344 - val_loss: 0.1383 - val_mae: 50255.2422\n",
      "Epoch 73/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1340 - mae: 52147.6797 - val_loss: 0.1379 - val_mae: 50173.7500\n",
      "Epoch 74/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1337 - mae: 52094.4609 - val_loss: 0.1376 - val_mae: 50128.4297\n",
      "Epoch 75/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1334 - mae: 52035.7031 - val_loss: 0.1374 - val_mae: 50081.8906\n",
      "Epoch 76/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1330 - mae: 51970.7930 - val_loss: 0.1369 - val_mae: 49993.3008\n",
      "Epoch 77/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1327 - mae: 51922.4492 - val_loss: 0.1365 - val_mae: 49913.5234\n",
      "Epoch 78/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1323 - mae: 51827.8438 - val_loss: 0.1361 - val_mae: 49817.3359\n",
      "Epoch 79/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1319 - mae: 51740.4883 - val_loss: 0.1356 - val_mae: 49734.1133\n",
      "Epoch 80/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1315 - mae: 51629.1680 - val_loss: 0.1351 - val_mae: 49609.0664\n",
      "Epoch 81/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1311 - mae: 51563.2344 - val_loss: 0.1348 - val_mae: 49560.0273\n",
      "Epoch 82/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1307 - mae: 51492.1133 - val_loss: 0.1342 - val_mae: 49447.9570\n",
      "Epoch 83/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1302 - mae: 51379.7852 - val_loss: 0.1337 - val_mae: 49339.2266\n",
      "Epoch 84/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1298 - mae: 51276.1211 - val_loss: 0.1333 - val_mae: 49260.4023\n",
      "Epoch 85/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1293 - mae: 51182.0312 - val_loss: 0.1328 - val_mae: 49151.5312\n",
      "Epoch 86/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1288 - mae: 51099.1797 - val_loss: 0.1322 - val_mae: 49049.3047\n",
      "Epoch 87/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1283 - mae: 50992.6250 - val_loss: 0.1317 - val_mae: 48929.3516\n",
      "Epoch 88/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1278 - mae: 50890.9648 - val_loss: 0.1312 - val_mae: 48834.4766\n",
      "Epoch 89/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1272 - mae: 50777.5703 - val_loss: 0.1305 - val_mae: 48694.6523\n",
      "Epoch 90/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1267 - mae: 50603.2969 - val_loss: 0.1297 - val_mae: 48518.7461\n",
      "Epoch 91/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1261 - mae: 50518.0703 - val_loss: 0.1292 - val_mae: 48440.0273\n",
      "Epoch 92/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1255 - mae: 50386.5703 - val_loss: 0.1284 - val_mae: 48258.5391\n",
      "Epoch 93/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1249 - mae: 50261.0000 - val_loss: 0.1278 - val_mae: 48156.4570\n",
      "Epoch 94/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1242 - mae: 50100.0977 - val_loss: 0.1271 - val_mae: 48002.7695\n",
      "Epoch 95/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1235 - mae: 49984.8008 - val_loss: 0.1265 - val_mae: 47899.2773\n",
      "Epoch 96/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1228 - mae: 49821.1211 - val_loss: 0.1256 - val_mae: 47685.1016\n",
      "Epoch 97/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1221 - mae: 49690.5469 - val_loss: 0.1250 - val_mae: 47593.7422\n",
      "Epoch 98/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1215 - mae: 49551.6055 - val_loss: 0.1240 - val_mae: 47356.9688\n",
      "Epoch 99/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1207 - mae: 49340.0703 - val_loss: 0.1231 - val_mae: 47167.4336\n",
      "Epoch 100/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1198 - mae: 49174.7578 - val_loss: 0.1225 - val_mae: 47067.6445\n",
      "Epoch 101/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1190 - mae: 49044.6445 - val_loss: 0.1215 - val_mae: 46857.1484\n",
      "Epoch 102/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1182 - mae: 48820.2344 - val_loss: 0.1206 - val_mae: 46652.7656\n",
      "Epoch 103/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1173 - mae: 48612.6484 - val_loss: 0.1195 - val_mae: 46424.6797\n",
      "Epoch 104/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1164 - mae: 48448.2031 - val_loss: 0.1186 - val_mae: 46233.7227\n",
      "Epoch 105/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1155 - mae: 48295.9961 - val_loss: 0.1177 - val_mae: 46050.8594\n",
      "Epoch 106/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1144 - mae: 47988.3242 - val_loss: 0.1163 - val_mae: 45724.5039\n",
      "Epoch 107/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1134 - mae: 47792.5391 - val_loss: 0.1155 - val_mae: 45577.7734\n",
      "Epoch 108/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1124 - mae: 47543.9492 - val_loss: 0.1142 - val_mae: 45286.3281\n",
      "Epoch 109/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1113 - mae: 47351.4844 - val_loss: 0.1131 - val_mae: 45065.6523\n",
      "Epoch 110/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1103 - mae: 47084.7188 - val_loss: 0.1118 - val_mae: 44768.0664\n",
      "Epoch 111/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1092 - mae: 46823.5820 - val_loss: 0.1104 - val_mae: 44462.7930\n",
      "Epoch 112/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1079 - mae: 46593.9297 - val_loss: 0.1094 - val_mae: 44236.7461\n",
      "Epoch 113/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1068 - mae: 46262.9531 - val_loss: 0.1079 - val_mae: 43899.3867\n",
      "Epoch 114/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1053 - mae: 46014.6133 - val_loss: 0.1068 - val_mae: 43653.1797\n",
      "Epoch 115/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1041 - mae: 45752.8086 - val_loss: 0.1051 - val_mae: 43265.8594\n",
      "Epoch 116/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1028 - mae: 45412.2227 - val_loss: 0.1034 - val_mae: 42897.2539\n",
      "Epoch 117/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1014 - mae: 45076.4297 - val_loss: 0.1022 - val_mae: 42601.9844\n",
      "Epoch 118/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1001 - mae: 44702.2422 - val_loss: 0.1006 - val_mae: 42225.3906\n",
      "Epoch 119/750\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0987 - mae: 44482.9297 - val_loss: 0.0992 - val_mae: 41904.3477\n",
      "Epoch 120/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0972 - mae: 44050.5117 - val_loss: 0.0976 - val_mae: 41523.5430\n",
      "Epoch 121/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0956 - mae: 43710.7031 - val_loss: 0.0962 - val_mae: 41190.7461\n",
      "Epoch 122/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0941 - mae: 43368.8477 - val_loss: 0.0944 - val_mae: 40785.7266\n",
      "Epoch 123/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0924 - mae: 42995.4219 - val_loss: 0.0926 - val_mae: 40370.1367\n",
      "Epoch 124/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0909 - mae: 42564.1211 - val_loss: 0.0907 - val_mae: 39904.9609\n",
      "Epoch 125/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0892 - mae: 42209.3398 - val_loss: 0.0891 - val_mae: 39525.6328\n",
      "Epoch 126/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0875 - mae: 41743.5352 - val_loss: 0.0874 - val_mae: 39107.5742\n",
      "Epoch 127/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0859 - mae: 41400.6797 - val_loss: 0.0853 - val_mae: 38615.3984\n",
      "Epoch 128/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0839 - mae: 40878.3711 - val_loss: 0.0838 - val_mae: 38219.5898\n",
      "Epoch 129/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0822 - mae: 40437.2891 - val_loss: 0.0818 - val_mae: 37708.1797\n",
      "Epoch 130/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0803 - mae: 40003.4062 - val_loss: 0.0799 - val_mae: 37227.7070\n",
      "Epoch 131/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0784 - mae: 39523.4844 - val_loss: 0.0776 - val_mae: 36685.6172\n",
      "Epoch 132/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0767 - mae: 39011.2148 - val_loss: 0.0760 - val_mae: 36268.9922\n",
      "Epoch 133/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0747 - mae: 38581.5430 - val_loss: 0.0740 - val_mae: 35748.1523\n",
      "Epoch 134/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0728 - mae: 38058.8633 - val_loss: 0.0721 - val_mae: 35296.9102\n",
      "Epoch 135/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0710 - mae: 37639.0625 - val_loss: 0.0699 - val_mae: 34695.3750\n",
      "Epoch 136/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0691 - mae: 37160.2070 - val_loss: 0.0683 - val_mae: 34286.3906\n",
      "Epoch 137/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 36607.5273 - val_loss: 0.0664 - val_mae: 33803.8438\n",
      "Epoch 138/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0655 - mae: 36109.1094 - val_loss: 0.0649 - val_mae: 33397.0391\n",
      "Epoch 139/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0640 - mae: 35810.3398 - val_loss: 0.0630 - val_mae: 32958.1211\n",
      "Epoch 140/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0623 - mae: 35261.7461 - val_loss: 0.0615 - val_mae: 32568.2012\n",
      "Epoch 141/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0606 - mae: 34791.7344 - val_loss: 0.0601 - val_mae: 32200.0039\n",
      "Epoch 142/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0591 - mae: 34343.3867 - val_loss: 0.0586 - val_mae: 31859.3867\n",
      "Epoch 143/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0576 - mae: 33921.9375 - val_loss: 0.0574 - val_mae: 31516.8770\n",
      "Epoch 144/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0565 - mae: 33604.8633 - val_loss: 0.0562 - val_mae: 31206.9141\n",
      "Epoch 145/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0552 - mae: 33187.0000 - val_loss: 0.0554 - val_mae: 30996.7676\n",
      "Epoch 146/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0538 - mae: 32803.6523 - val_loss: 0.0540 - val_mae: 30597.9141\n",
      "Epoch 147/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0527 - mae: 32471.6328 - val_loss: 0.0532 - val_mae: 30413.6055\n",
      "Epoch 148/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0516 - mae: 32169.4961 - val_loss: 0.0521 - val_mae: 30094.7676\n",
      "Epoch 149/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0507 - mae: 31916.9238 - val_loss: 0.0514 - val_mae: 29915.9590\n",
      "Epoch 150/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0499 - mae: 31630.1816 - val_loss: 0.0506 - val_mae: 29672.9492\n",
      "Epoch 151/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0489 - mae: 31313.3945 - val_loss: 0.0500 - val_mae: 29561.7676\n",
      "Epoch 152/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0482 - mae: 30998.5547 - val_loss: 0.0493 - val_mae: 29401.4141\n",
      "Epoch 153/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0475 - mae: 30833.4355 - val_loss: 0.0485 - val_mae: 29012.4512\n",
      "Epoch 154/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0465 - mae: 30490.3730 - val_loss: 0.0478 - val_mae: 28898.6504\n",
      "Epoch 155/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0459 - mae: 30365.1816 - val_loss: 0.0471 - val_mae: 28709.1035\n",
      "Epoch 156/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0451 - mae: 30046.9219 - val_loss: 0.0465 - val_mae: 28469.6641\n",
      "Epoch 157/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0444 - mae: 29777.6172 - val_loss: 0.0459 - val_mae: 28302.2051\n",
      "Epoch 158/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0439 - mae: 29630.3867 - val_loss: 0.0454 - val_mae: 28052.2930\n",
      "Epoch 159/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0432 - mae: 29500.3965 - val_loss: 0.0453 - val_mae: 27814.2480\n",
      "Epoch 160/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0427 - mae: 29353.9102 - val_loss: 0.0449 - val_mae: 27647.3984\n",
      "Epoch 161/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0420 - mae: 29010.6406 - val_loss: 0.0436 - val_mae: 27599.0078\n",
      "Epoch 162/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 28728.6133 - val_loss: 0.0431 - val_mae: 27546.5820\n",
      "Epoch 163/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 28730.8281 - val_loss: 0.0427 - val_mae: 27527.6016\n",
      "Epoch 164/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0400 - mae: 28347.8262 - val_loss: 0.0420 - val_mae: 26967.6465\n",
      "Epoch 165/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0394 - mae: 28134.5703 - val_loss: 0.0414 - val_mae: 26940.3281\n",
      "Epoch 166/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0389 - mae: 28089.6348 - val_loss: 0.0410 - val_mae: 26584.0977\n",
      "Epoch 167/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0382 - mae: 27668.6094 - val_loss: 0.0406 - val_mae: 26825.5879\n",
      "Epoch 168/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0380 - mae: 27687.0273 - val_loss: 0.0404 - val_mae: 26212.3652\n",
      "Epoch 169/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0370 - mae: 27361.0859 - val_loss: 0.0398 - val_mae: 26667.9336\n",
      "Epoch 170/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0365 - mae: 27132.2852 - val_loss: 0.0387 - val_mae: 25922.1113\n",
      "Epoch 171/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0360 - mae: 26919.1133 - val_loss: 0.0382 - val_mae: 25728.0488\n",
      "Epoch 172/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0354 - mae: 26706.7578 - val_loss: 0.0376 - val_mae: 25579.9609\n",
      "Epoch 173/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0348 - mae: 26553.5625 - val_loss: 0.0373 - val_mae: 25232.5762\n",
      "Epoch 174/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0343 - mae: 26303.2930 - val_loss: 0.0365 - val_mae: 25118.7422\n",
      "Epoch 175/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 26260.9453 - val_loss: 0.0361 - val_mae: 25122.0312\n",
      "Epoch 176/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0333 - mae: 25895.0547 - val_loss: 0.0355 - val_mae: 24833.3496\n",
      "Epoch 177/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0328 - mae: 25720.6582 - val_loss: 0.0356 - val_mae: 25084.2480\n",
      "Epoch 178/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0325 - mae: 25702.2656 - val_loss: 0.0346 - val_mae: 24413.3066\n",
      "Epoch 179/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0320 - mae: 25532.5293 - val_loss: 0.0342 - val_mae: 24146.0781\n",
      "Epoch 180/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0314 - mae: 25104.3613 - val_loss: 0.0337 - val_mae: 24108.8906\n",
      "Epoch 181/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0309 - mae: 24973.4238 - val_loss: 0.0332 - val_mae: 23901.3301\n",
      "Epoch 182/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0305 - mae: 24869.3574 - val_loss: 0.0332 - val_mae: 23661.0781\n",
      "Epoch 183/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0303 - mae: 24688.7422 - val_loss: 0.0325 - val_mae: 23529.7422\n",
      "Epoch 184/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0298 - mae: 24521.7852 - val_loss: 0.0320 - val_mae: 23458.7207\n",
      "Epoch 185/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0297 - mae: 24497.6465 - val_loss: 0.0323 - val_mae: 23260.2031\n",
      "Epoch 186/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0290 - mae: 24162.1582 - val_loss: 0.0314 - val_mae: 23132.1738\n",
      "Epoch 187/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0285 - mae: 24004.5020 - val_loss: 0.0311 - val_mae: 23135.7891\n",
      "Epoch 188/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0285 - mae: 23973.5352 - val_loss: 0.0307 - val_mae: 22877.0488\n",
      "Epoch 189/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0280 - mae: 23751.6309 - val_loss: 0.0304 - val_mae: 22705.5371\n",
      "Epoch 190/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0279 - mae: 23674.9824 - val_loss: 0.0300 - val_mae: 22637.7852\n",
      "Epoch 191/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0273 - mae: 23489.2773 - val_loss: 0.0299 - val_mae: 22658.0684\n",
      "Epoch 192/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0273 - mae: 23471.4062 - val_loss: 0.0294 - val_mae: 22344.7090\n",
      "Epoch 193/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0269 - mae: 23231.6738 - val_loss: 0.0293 - val_mae: 22203.6602\n",
      "Epoch 194/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0265 - mae: 23109.5410 - val_loss: 0.0296 - val_mae: 22160.9727\n",
      "Epoch 195/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0264 - mae: 23010.4824 - val_loss: 0.0288 - val_mae: 21964.0684\n",
      "Epoch 196/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0262 - mae: 22903.6328 - val_loss: 0.0285 - val_mae: 21849.8770\n",
      "Epoch 197/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0261 - mae: 22888.6035 - val_loss: 0.0285 - val_mae: 21765.8164\n",
      "Epoch 198/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0256 - mae: 22657.2012 - val_loss: 0.0281 - val_mae: 21634.9590\n",
      "Epoch 199/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0255 - mae: 22489.7285 - val_loss: 0.0277 - val_mae: 21630.3906\n",
      "Epoch 200/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0253 - mae: 22498.2168 - val_loss: 0.0275 - val_mae: 21390.1543\n",
      "Epoch 201/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0249 - mae: 22349.0469 - val_loss: 0.0273 - val_mae: 21316.1113\n",
      "Epoch 202/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0248 - mae: 22370.7910 - val_loss: 0.0277 - val_mae: 21403.5430\n",
      "Epoch 203/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0247 - mae: 22217.0410 - val_loss: 0.0269 - val_mae: 21139.4785\n",
      "Epoch 204/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0246 - mae: 22146.7227 - val_loss: 0.0267 - val_mae: 21088.8027\n",
      "Epoch 205/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0243 - mae: 21992.8066 - val_loss: 0.0267 - val_mae: 21118.6836\n",
      "Epoch 206/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0244 - mae: 22053.1016 - val_loss: 0.0266 - val_mae: 21049.0625\n",
      "Epoch 207/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0242 - mae: 21925.9863 - val_loss: 0.0269 - val_mae: 21036.5449\n",
      "Epoch 208/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0241 - mae: 21863.5137 - val_loss: 0.0262 - val_mae: 20812.5137\n",
      "Epoch 209/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0242 - mae: 21809.1895 - val_loss: 0.0260 - val_mae: 20739.7422\n",
      "Epoch 210/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0237 - mae: 21619.0527 - val_loss: 0.0259 - val_mae: 20703.9062\n",
      "Epoch 211/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0237 - mae: 21650.5312 - val_loss: 0.0259 - val_mae: 20704.9727\n",
      "Epoch 212/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0235 - mae: 21516.7734 - val_loss: 0.0262 - val_mae: 20715.7715\n",
      "Epoch 213/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0234 - mae: 21497.2383 - val_loss: 0.0257 - val_mae: 20598.1680\n",
      "Epoch 214/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0234 - mae: 21467.3926 - val_loss: 0.0256 - val_mae: 20549.5371\n",
      "Epoch 215/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0241 - mae: 21676.5586 - val_loss: 0.0255 - val_mae: 20468.7422\n",
      "Epoch 216/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0231 - mae: 21288.2441 - val_loss: 0.0254 - val_mae: 20432.1895\n",
      "Epoch 217/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0232 - mae: 21341.0918 - val_loss: 0.0254 - val_mae: 20449.2773\n",
      "Epoch 218/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0234 - mae: 21423.0840 - val_loss: 0.0252 - val_mae: 20388.9961\n",
      "Epoch 219/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0230 - mae: 21266.5957 - val_loss: 0.0255 - val_mae: 20406.9336\n",
      "Epoch 220/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0229 - mae: 21224.7070 - val_loss: 0.0250 - val_mae: 20285.1934\n",
      "Epoch 221/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0228 - mae: 21107.3965 - val_loss: 0.0249 - val_mae: 20212.2695\n",
      "Epoch 222/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 21172.6680 - val_loss: 0.0251 - val_mae: 20224.3672\n",
      "Epoch 223/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0226 - mae: 21028.2109 - val_loss: 0.0249 - val_mae: 20213.4434\n",
      "Epoch 224/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 21106.2422 - val_loss: 0.0256 - val_mae: 20438.0488\n",
      "Epoch 225/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0226 - mae: 20931.2637 - val_loss: 0.0247 - val_mae: 20058.2422\n",
      "Epoch 226/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0230 - mae: 21134.6172 - val_loss: 0.0248 - val_mae: 20122.3242\n",
      "Epoch 227/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0228 - mae: 20977.6406 - val_loss: 0.0252 - val_mae: 20268.2441\n",
      "Epoch 228/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0224 - mae: 20889.7148 - val_loss: 0.0245 - val_mae: 19972.4395\n",
      "Epoch 229/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0223 - mae: 20832.7168 - val_loss: 0.0245 - val_mae: 19987.2285\n",
      "Epoch 230/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0231 - mae: 21078.0898 - val_loss: 0.0252 - val_mae: 20272.5449\n",
      "Epoch 231/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0226 - mae: 20905.7441 - val_loss: 0.0244 - val_mae: 19928.4023\n",
      "Epoch 232/750\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0222 - mae: 20704.8828 - val_loss: 0.0243 - val_mae: 19869.7988\n",
      "Epoch 233/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0221 - mae: 20672.4844 - val_loss: 0.0249 - val_mae: 20079.3516\n",
      "Epoch 234/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0224 - mae: 20746.7695 - val_loss: 0.0255 - val_mae: 20307.9395\n",
      "Epoch 235/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0221 - mae: 20762.0762 - val_loss: 0.0242 - val_mae: 19795.9707\n",
      "Epoch 236/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 20681.3164 - val_loss: 0.0241 - val_mae: 19768.5645\n",
      "Epoch 237/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 20726.7109 - val_loss: 0.0249 - val_mae: 20051.6719\n",
      "Epoch 238/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0224 - mae: 20794.5801 - val_loss: 0.0241 - val_mae: 19745.0918\n",
      "Epoch 239/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 20632.8438 - val_loss: 0.0242 - val_mae: 19803.1035\n",
      "Epoch 240/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 20565.1699 - val_loss: 0.0240 - val_mae: 19683.9375\n",
      "Epoch 241/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 20543.6426 - val_loss: 0.0239 - val_mae: 19640.9609\n",
      "Epoch 242/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0217 - mae: 20501.7344 - val_loss: 0.0243 - val_mae: 19851.2266\n",
      "Epoch 243/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 20485.4883 - val_loss: 0.0239 - val_mae: 19667.4805\n",
      "Epoch 244/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 20552.4258 - val_loss: 0.0237 - val_mae: 19558.3867\n",
      "Epoch 245/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0216 - mae: 20390.6699 - val_loss: 0.0237 - val_mae: 19528.1738\n",
      "Epoch 246/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 20552.2598 - val_loss: 0.0242 - val_mae: 19708.0996\n",
      "Epoch 247/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 20555.9727 - val_loss: 0.0238 - val_mae: 19554.9102\n",
      "Epoch 248/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0216 - mae: 20348.5371 - val_loss: 0.0236 - val_mae: 19499.2012\n",
      "Epoch 249/750\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0217 - mae: 20389.2266 - val_loss: 0.0235 - val_mae: 19454.7988\n",
      "Epoch 250/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0216 - mae: 20317.1523 - val_loss: 0.0235 - val_mae: 19442.3828\n",
      "Epoch 251/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 20477.0488 - val_loss: 0.0235 - val_mae: 19466.6738\n",
      "Epoch 252/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 20396.3535 - val_loss: 0.0234 - val_mae: 19427.2305\n",
      "Epoch 253/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0215 - mae: 20296.1152 - val_loss: 0.0238 - val_mae: 19511.1758\n",
      "Epoch 254/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0215 - mae: 20358.2188 - val_loss: 0.0235 - val_mae: 19397.1777\n",
      "Epoch 255/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0214 - mae: 20282.6973 - val_loss: 0.0234 - val_mae: 19359.7383\n",
      "Epoch 256/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0214 - mae: 20242.4961 - val_loss: 0.0234 - val_mae: 19377.6895\n",
      "Epoch 257/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0212 - mae: 20151.0000 - val_loss: 0.0232 - val_mae: 19301.0898\n",
      "Epoch 258/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0215 - mae: 20187.4238 - val_loss: 0.0240 - val_mae: 19676.0742\n",
      "Epoch 259/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0212 - mae: 20094.9121 - val_loss: 0.0232 - val_mae: 19267.3672\n",
      "Epoch 260/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0212 - mae: 20182.0117 - val_loss: 0.0232 - val_mae: 19270.0215\n",
      "Epoch 261/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 20001.1328 - val_loss: 0.0233 - val_mae: 19268.3652\n",
      "Epoch 262/750\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0212 - mae: 20171.5352 - val_loss: 0.0231 - val_mae: 19191.0918\n",
      "Epoch 263/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0213 - mae: 20180.3496 - val_loss: 0.0231 - val_mae: 19236.4648\n",
      "Epoch 264/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0211 - mae: 20072.4512 - val_loss: 0.0230 - val_mae: 19156.4414\n",
      "Epoch 265/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0213 - mae: 20173.7051 - val_loss: 0.0230 - val_mae: 19133.9668\n",
      "Epoch 266/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 20494.1816 - val_loss: 0.0231 - val_mae: 19255.0781\n",
      "Epoch 267/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 19984.0078 - val_loss: 0.0230 - val_mae: 19122.8066\n",
      "Epoch 268/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0212 - mae: 20204.3945 - val_loss: 0.0245 - val_mae: 19987.0977\n",
      "Epoch 269/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 20060.5723 - val_loss: 0.0229 - val_mae: 19082.5000\n",
      "Epoch 270/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 20036.7012 - val_loss: 0.0228 - val_mae: 19077.9824\n",
      "Epoch 271/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 19993.9902 - val_loss: 0.0228 - val_mae: 19078.7500\n",
      "Epoch 272/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0209 - mae: 19965.6328 - val_loss: 0.0229 - val_mae: 19037.5488\n",
      "Epoch 273/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 19919.6426 - val_loss: 0.0230 - val_mae: 19087.0254\n",
      "Epoch 274/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0209 - mae: 19906.4727 - val_loss: 0.0226 - val_mae: 18963.9238\n",
      "Epoch 275/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0209 - mae: 19944.7656 - val_loss: 0.0228 - val_mae: 19103.5215\n",
      "Epoch 276/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0215 - mae: 20237.8594 - val_loss: 0.0226 - val_mae: 18996.3906\n",
      "Epoch 277/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0207 - mae: 19911.4219 - val_loss: 0.0226 - val_mae: 18995.0488\n",
      "Epoch 278/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0207 - mae: 19820.2656 - val_loss: 0.0225 - val_mae: 18897.4121\n",
      "Epoch 279/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0207 - mae: 19789.9922 - val_loss: 0.0224 - val_mae: 18903.8965\n",
      "Epoch 280/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0208 - mae: 19828.9473 - val_loss: 0.0231 - val_mae: 19209.6465\n",
      "Epoch 281/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 19817.4219 - val_loss: 0.0227 - val_mae: 18913.7988\n",
      "Epoch 282/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0206 - mae: 19812.6602 - val_loss: 0.0228 - val_mae: 19122.9980\n",
      "Epoch 283/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0214 - mae: 20229.8516 - val_loss: 0.0224 - val_mae: 18813.0000\n",
      "Epoch 284/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0208 - mae: 19776.8984 - val_loss: 0.0224 - val_mae: 18810.0645\n",
      "Epoch 285/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0207 - mae: 19813.5625 - val_loss: 0.0225 - val_mae: 18829.6992\n",
      "Epoch 286/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0208 - mae: 19890.5039 - val_loss: 0.0223 - val_mae: 18800.5156\n",
      "Epoch 287/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0207 - mae: 19790.8906 - val_loss: 0.0228 - val_mae: 19167.5840\n",
      "Epoch 288/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 20127.2246 - val_loss: 0.0226 - val_mae: 19035.5840\n",
      "Epoch 289/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 19904.8711 - val_loss: 0.0227 - val_mae: 19096.9883\n",
      "Epoch 290/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 19663.5449 - val_loss: 0.0228 - val_mae: 18900.9062\n",
      "Epoch 291/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 19732.3887 - val_loss: 0.0223 - val_mae: 18713.4297\n",
      "Epoch 292/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 19701.9785 - val_loss: 0.0226 - val_mae: 18967.3086\n",
      "Epoch 293/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0207 - mae: 19762.7070 - val_loss: 0.0222 - val_mae: 18785.1758\n",
      "Epoch 294/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 19779.6113 - val_loss: 0.0228 - val_mae: 18926.7578\n",
      "Epoch 295/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0203 - mae: 19642.1699 - val_loss: 0.0224 - val_mae: 18855.9492\n",
      "Epoch 296/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0203 - mae: 19600.7188 - val_loss: 0.0220 - val_mae: 18617.9434\n",
      "Epoch 297/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 19648.4844 - val_loss: 0.0224 - val_mae: 18852.3516\n",
      "Epoch 298/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 19698.2598 - val_loss: 0.0219 - val_mae: 18649.0742\n",
      "Epoch 299/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0203 - mae: 19626.7598 - val_loss: 0.0219 - val_mae: 18600.4043\n",
      "Epoch 300/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 19648.9219 - val_loss: 0.0221 - val_mae: 18701.2715\n",
      "Epoch 301/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0202 - mae: 19495.2461 - val_loss: 0.0226 - val_mae: 18777.3398\n",
      "Epoch 302/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0203 - mae: 19579.6523 - val_loss: 0.0219 - val_mae: 18549.0059\n",
      "Epoch 303/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0202 - mae: 19591.7578 - val_loss: 0.0218 - val_mae: 18584.2383\n",
      "Epoch 304/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0202 - mae: 19535.3457 - val_loss: 0.0220 - val_mae: 18540.2930\n",
      "Epoch 305/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0202 - mae: 19499.4082 - val_loss: 0.0232 - val_mae: 19027.0840\n",
      "Epoch 306/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0202 - mae: 19494.3965 - val_loss: 0.0218 - val_mae: 18551.2305\n",
      "Epoch 307/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0203 - mae: 19629.9277 - val_loss: 0.0218 - val_mae: 18498.7227\n",
      "Epoch 308/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 19579.4688 - val_loss: 0.0220 - val_mae: 18517.1172\n",
      "Epoch 309/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 19533.1836 - val_loss: 0.0219 - val_mae: 18502.7422\n",
      "Epoch 310/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0202 - mae: 19485.4785 - val_loss: 0.0217 - val_mae: 18440.2734\n",
      "Epoch 311/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 19468.5762 - val_loss: 0.0217 - val_mae: 18424.6621\n",
      "Epoch 312/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0202 - mae: 19489.7617 - val_loss: 0.0216 - val_mae: 18456.8828\n",
      "Epoch 313/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 19421.1660 - val_loss: 0.0219 - val_mae: 18650.8887\n",
      "Epoch 314/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 19332.3398 - val_loss: 0.0220 - val_mae: 18656.0488\n",
      "Epoch 315/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0201 - mae: 19464.9727 - val_loss: 0.0217 - val_mae: 18389.6621\n",
      "Epoch 316/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 19527.8848 - val_loss: 0.0215 - val_mae: 18377.9277\n",
      "Epoch 317/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0200 - mae: 19458.3711 - val_loss: 0.0216 - val_mae: 18403.8965\n",
      "Epoch 318/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 19674.7090 - val_loss: 0.0237 - val_mae: 19199.5586\n",
      "Epoch 319/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 19573.8242 - val_loss: 0.0224 - val_mae: 18636.5898\n",
      "Epoch 320/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 19394.5723 - val_loss: 0.0218 - val_mae: 18543.7637\n",
      "Epoch 321/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 19337.5488 - val_loss: 0.0216 - val_mae: 18323.4375\n",
      "Epoch 322/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 19301.3008 - val_loss: 0.0215 - val_mae: 18311.6211\n",
      "Epoch 323/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 19292.1777 - val_loss: 0.0214 - val_mae: 18300.0449\n",
      "Epoch 324/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 19387.2715 - val_loss: 0.0215 - val_mae: 18350.5352\n",
      "Epoch 325/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 19359.9844 - val_loss: 0.0214 - val_mae: 18338.0176\n",
      "Epoch 326/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 19290.1465 - val_loss: 0.0214 - val_mae: 18262.2656\n",
      "Epoch 327/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 19289.6387 - val_loss: 0.0215 - val_mae: 18250.7969\n",
      "Epoch 328/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0202 - mae: 19487.0605 - val_loss: 0.0218 - val_mae: 18380.5918\n",
      "Epoch 329/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 19424.9199 - val_loss: 0.0220 - val_mae: 18619.4961\n",
      "Epoch 330/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 19376.3223 - val_loss: 0.0214 - val_mae: 18338.5762\n",
      "Epoch 331/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0206 - mae: 19601.3066 - val_loss: 0.0226 - val_mae: 18991.4434\n",
      "Epoch 332/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 19432.1973 - val_loss: 0.0216 - val_mae: 18420.5859\n",
      "Epoch 333/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 19261.5273 - val_loss: 0.0226 - val_mae: 18714.0137\n",
      "Epoch 334/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0203 - mae: 19565.9375 - val_loss: 0.0218 - val_mae: 18581.0371\n",
      "Epoch 335/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 19250.8574 - val_loss: 0.0213 - val_mae: 18178.2617\n",
      "Epoch 336/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 19218.0527 - val_loss: 0.0217 - val_mae: 18327.0859\n",
      "Epoch 337/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 19418.4668 - val_loss: 0.0213 - val_mae: 18222.7129\n",
      "Epoch 338/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 19376.5234 - val_loss: 0.0215 - val_mae: 18233.0703\n",
      "Epoch 339/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 19872.4727 - val_loss: 0.0228 - val_mae: 18793.5898\n",
      "Epoch 340/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 19441.3652 - val_loss: 0.0212 - val_mae: 18137.5723\n",
      "Epoch 341/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 19239.3008 - val_loss: 0.0212 - val_mae: 18199.3164\n",
      "Epoch 342/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 19193.0781 - val_loss: 0.0212 - val_mae: 18148.0176\n",
      "Epoch 343/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 19208.5332 - val_loss: 0.0211 - val_mae: 18126.8262\n",
      "Epoch 344/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 19145.0938 - val_loss: 0.0223 - val_mae: 18795.2871\n",
      "Epoch 345/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 19230.7852 - val_loss: 0.0217 - val_mae: 18278.9570\n",
      "Epoch 346/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 19177.0742 - val_loss: 0.0218 - val_mae: 18510.0625\n",
      "Epoch 347/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 19259.0996 - val_loss: 0.0218 - val_mae: 18533.1738\n",
      "Epoch 348/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 19254.0625 - val_loss: 0.0212 - val_mae: 18092.8926\n",
      "Epoch 349/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 19221.4258 - val_loss: 0.0214 - val_mae: 18139.5195\n",
      "Epoch 350/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0195 - mae: 19187.4551 - val_loss: 0.0212 - val_mae: 18146.7891\n",
      "Epoch 351/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 19250.3203 - val_loss: 0.0212 - val_mae: 18121.6172\n",
      "Epoch 352/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 19241.1484 - val_loss: 0.0211 - val_mae: 18051.7734\n",
      "Epoch 353/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 19084.6895 - val_loss: 0.0213 - val_mae: 18088.8066\n",
      "Epoch 354/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 19093.5391 - val_loss: 0.0210 - val_mae: 17970.3594\n",
      "Epoch 355/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 19124.3691 - val_loss: 0.0211 - val_mae: 18076.1270\n",
      "Epoch 356/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 19111.1094 - val_loss: 0.0209 - val_mae: 17976.8965\n",
      "Epoch 357/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 19015.1211 - val_loss: 0.0213 - val_mae: 18086.6113\n",
      "Epoch 358/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 19063.1445 - val_loss: 0.0209 - val_mae: 17967.4102\n",
      "Epoch 359/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 19109.8262 - val_loss: 0.0214 - val_mae: 18309.6328\n",
      "Epoch 360/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 19238.4512 - val_loss: 0.0209 - val_mae: 17945.9570\n",
      "Epoch 361/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 18996.3633 - val_loss: 0.0229 - val_mae: 18775.5527\n",
      "Epoch 362/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 19255.0195 - val_loss: 0.0229 - val_mae: 19038.6543\n",
      "Epoch 363/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 19268.2617 - val_loss: 0.0221 - val_mae: 18704.7480\n",
      "Epoch 364/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 19080.7891 - val_loss: 0.0208 - val_mae: 17929.1895\n",
      "Epoch 365/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 19125.0918 - val_loss: 0.0208 - val_mae: 17910.0195\n",
      "Epoch 366/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0196 - mae: 19129.9043 - val_loss: 0.0214 - val_mae: 18082.9941\n",
      "Epoch 367/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 19075.6797 - val_loss: 0.0212 - val_mae: 18229.8398\n",
      "Epoch 368/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 19015.3594 - val_loss: 0.0211 - val_mae: 18098.1387\n",
      "Epoch 369/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 19010.9082 - val_loss: 0.0209 - val_mae: 17952.6328\n",
      "Epoch 370/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 18989.8887 - val_loss: 0.0213 - val_mae: 18043.6152\n",
      "Epoch 371/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18962.5625 - val_loss: 0.0207 - val_mae: 17855.5508\n",
      "Epoch 372/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 18986.3906 - val_loss: 0.0209 - val_mae: 17921.1387\n",
      "Epoch 373/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 18961.7539 - val_loss: 0.0215 - val_mae: 18109.4531\n",
      "Epoch 374/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 19081.2578 - val_loss: 0.0208 - val_mae: 17838.9180\n",
      "Epoch 375/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 18928.9551 - val_loss: 0.0208 - val_mae: 17839.7637\n",
      "Epoch 376/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 18945.0273 - val_loss: 0.0207 - val_mae: 17817.7832\n",
      "Epoch 377/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 18933.2988 - val_loss: 0.0208 - val_mae: 17814.4941\n",
      "Epoch 378/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 18802.5586 - val_loss: 0.0210 - val_mae: 17982.3809\n",
      "Epoch 379/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 19057.8125 - val_loss: 0.0213 - val_mae: 18021.8965\n",
      "Epoch 380/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 19176.4922 - val_loss: 0.0209 - val_mae: 17865.2402\n",
      "Epoch 381/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18968.5742 - val_loss: 0.0209 - val_mae: 17928.5059\n",
      "Epoch 382/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0194 - mae: 18969.9609 - val_loss: 0.0211 - val_mae: 18033.8809\n",
      "Epoch 383/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18963.7578 - val_loss: 0.0209 - val_mae: 17957.1992\n",
      "Epoch 384/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 19024.9805 - val_loss: 0.0209 - val_mae: 17839.9297\n",
      "Epoch 385/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18836.4238 - val_loss: 0.0206 - val_mae: 17745.7949\n",
      "Epoch 386/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18827.4395 - val_loss: 0.0206 - val_mae: 17797.1699\n",
      "Epoch 387/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 19103.3125 - val_loss: 0.0209 - val_mae: 17812.8926\n",
      "Epoch 388/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18995.0879 - val_loss: 0.0217 - val_mae: 18180.7207\n",
      "Epoch 389/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18886.7402 - val_loss: 0.0206 - val_mae: 17722.9453\n",
      "Epoch 390/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18923.6016 - val_loss: 0.0209 - val_mae: 17808.0977\n",
      "Epoch 391/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 18880.7324 - val_loss: 0.0205 - val_mae: 17670.7441\n",
      "Epoch 392/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 18869.7676 - val_loss: 0.0208 - val_mae: 17831.3555\n",
      "Epoch 393/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18840.5332 - val_loss: 0.0210 - val_mae: 17828.7695\n",
      "Epoch 394/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 18967.6797 - val_loss: 0.0206 - val_mae: 17792.9629\n",
      "Epoch 395/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18863.5781 - val_loss: 0.0205 - val_mae: 17642.6934\n",
      "Epoch 396/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18962.2852 - val_loss: 0.0209 - val_mae: 17950.1289\n",
      "Epoch 397/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 18967.7832 - val_loss: 0.0205 - val_mae: 17667.5020\n",
      "Epoch 398/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18783.2051 - val_loss: 0.0205 - val_mae: 17654.8926\n",
      "Epoch 399/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 18772.9180 - val_loss: 0.0207 - val_mae: 17676.1875\n",
      "Epoch 400/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 18942.2012 - val_loss: 0.0207 - val_mae: 17789.9902\n",
      "Epoch 401/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 18985.5723 - val_loss: 0.0205 - val_mae: 17623.3086\n",
      "Epoch 402/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 18890.5078 - val_loss: 0.0205 - val_mae: 17624.6465\n",
      "Epoch 403/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18847.0293 - val_loss: 0.0205 - val_mae: 17597.8770\n",
      "Epoch 404/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 18706.9609 - val_loss: 0.0205 - val_mae: 17601.4785\n",
      "Epoch 405/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 18783.8965 - val_loss: 0.0207 - val_mae: 17640.3086\n",
      "Epoch 406/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18711.2500 - val_loss: 0.0208 - val_mae: 17771.9980\n",
      "Epoch 407/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18765.4434 - val_loss: 0.0205 - val_mae: 17583.5371\n",
      "Epoch 408/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18860.2305 - val_loss: 0.0206 - val_mae: 17646.3770\n",
      "Epoch 409/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18763.0430 - val_loss: 0.0211 - val_mae: 17827.2070\n",
      "Epoch 410/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18699.1035 - val_loss: 0.0204 - val_mae: 17600.8848\n",
      "Epoch 411/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18749.8555 - val_loss: 0.0204 - val_mae: 17585.4082\n",
      "Epoch 412/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0190 - mae: 18686.2969 - val_loss: 0.0209 - val_mae: 17841.4766\n",
      "Epoch 413/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18894.0938 - val_loss: 0.0217 - val_mae: 18278.6602\n",
      "Epoch 414/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18656.8516 - val_loss: 0.0204 - val_mae: 17554.8457\n",
      "Epoch 415/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18748.7578 - val_loss: 0.0206 - val_mae: 17719.6992\n",
      "Epoch 416/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18708.8066 - val_loss: 0.0206 - val_mae: 17694.2422\n",
      "Epoch 417/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18666.9590 - val_loss: 0.0205 - val_mae: 17569.0410\n",
      "Epoch 418/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 18795.0781 - val_loss: 0.0216 - val_mae: 18044.9277\n",
      "Epoch 419/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18836.4043 - val_loss: 0.0225 - val_mae: 18460.5957\n",
      "Epoch 420/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18886.4062 - val_loss: 0.0204 - val_mae: 17492.8984\n",
      "Epoch 421/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 18860.9629 - val_loss: 0.0212 - val_mae: 17868.1348\n",
      "Epoch 422/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18790.1602 - val_loss: 0.0203 - val_mae: 17483.7383\n",
      "Epoch 423/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18667.8965 - val_loss: 0.0206 - val_mae: 17706.6777\n",
      "Epoch 424/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 18789.9277 - val_loss: 0.0210 - val_mae: 17914.3574\n",
      "Epoch 425/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18599.0273 - val_loss: 0.0207 - val_mae: 17743.3262\n",
      "Epoch 426/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18628.0488 - val_loss: 0.0213 - val_mae: 18098.7715\n",
      "Epoch 427/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18744.4492 - val_loss: 0.0204 - val_mae: 17574.1621\n",
      "Epoch 428/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18593.6699 - val_loss: 0.0205 - val_mae: 17682.4609\n",
      "Epoch 429/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18799.6875 - val_loss: 0.0203 - val_mae: 17457.2734\n",
      "Epoch 430/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 18878.0371 - val_loss: 0.0210 - val_mae: 17763.3965\n",
      "Epoch 431/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18488.0020 - val_loss: 0.0216 - val_mae: 18175.2441\n",
      "Epoch 432/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18689.1602 - val_loss: 0.0203 - val_mae: 17424.8066\n",
      "Epoch 433/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18656.2266 - val_loss: 0.0207 - val_mae: 17725.5918\n",
      "Epoch 434/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18582.9102 - val_loss: 0.0206 - val_mae: 17701.5078\n",
      "Epoch 435/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18694.9102 - val_loss: 0.0203 - val_mae: 17468.9121\n",
      "Epoch 436/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 18910.3418 - val_loss: 0.0213 - val_mae: 17829.2715\n",
      "Epoch 437/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18829.2188 - val_loss: 0.0203 - val_mae: 17478.3184\n",
      "Epoch 438/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18495.4551 - val_loss: 0.0202 - val_mae: 17384.9785\n",
      "Epoch 439/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18697.7617 - val_loss: 0.0202 - val_mae: 17418.9395\n",
      "Epoch 440/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18533.7773 - val_loss: 0.0209 - val_mae: 17656.4238\n",
      "Epoch 441/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 18779.8340 - val_loss: 0.0207 - val_mae: 17581.2910\n",
      "Epoch 442/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18588.2578 - val_loss: 0.0201 - val_mae: 17381.6230\n",
      "Epoch 443/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18562.4629 - val_loss: 0.0202 - val_mae: 17377.1504\n",
      "Epoch 444/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 18485.8809 - val_loss: 0.0203 - val_mae: 17494.9922\n",
      "Epoch 445/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18546.3359 - val_loss: 0.0203 - val_mae: 17475.7168\n",
      "Epoch 446/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 18575.5059 - val_loss: 0.0211 - val_mae: 17734.4219\n",
      "Epoch 447/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18709.9355 - val_loss: 0.0202 - val_mae: 17382.7598\n",
      "Epoch 448/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18604.3652 - val_loss: 0.0202 - val_mae: 17440.5645\n",
      "Epoch 449/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18762.7012 - val_loss: 0.0203 - val_mae: 17396.7207\n",
      "Epoch 450/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 18607.3613 - val_loss: 0.0205 - val_mae: 17518.8535\n",
      "Epoch 451/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18622.6543 - val_loss: 0.0201 - val_mae: 17378.5938\n",
      "Epoch 452/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18562.3242 - val_loss: 0.0203 - val_mae: 17495.8535\n",
      "Epoch 453/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18753.0000 - val_loss: 0.0212 - val_mae: 17978.3145\n",
      "Epoch 454/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18530.6777 - val_loss: 0.0202 - val_mae: 17418.6797\n",
      "Epoch 455/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 18734.5918 - val_loss: 0.0204 - val_mae: 17407.9043\n",
      "Epoch 456/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 18474.9922 - val_loss: 0.0202 - val_mae: 17332.7246\n",
      "Epoch 457/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18665.5645 - val_loss: 0.0209 - val_mae: 17754.4609\n",
      "Epoch 458/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 18951.6738 - val_loss: 0.0202 - val_mae: 17376.5488\n",
      "Epoch 459/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18473.2871 - val_loss: 0.0213 - val_mae: 17817.2852\n",
      "Epoch 460/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18473.4102 - val_loss: 0.0201 - val_mae: 17314.0938\n",
      "Epoch 461/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18446.1270 - val_loss: 0.0209 - val_mae: 17720.5332\n",
      "Epoch 462/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18551.5352 - val_loss: 0.0204 - val_mae: 17485.7480\n",
      "Epoch 463/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0208 - mae: 19562.3887 - val_loss: 0.0208 - val_mae: 17694.6895\n",
      "Epoch 464/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18527.7520 - val_loss: 0.0205 - val_mae: 17448.9727\n",
      "Epoch 465/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18531.9414 - val_loss: 0.0201 - val_mae: 17268.2285\n",
      "Epoch 466/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18501.2051 - val_loss: 0.0207 - val_mae: 17495.5273\n",
      "Epoch 467/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18517.7500 - val_loss: 0.0200 - val_mae: 17304.3340\n",
      "Epoch 468/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18383.4453 - val_loss: 0.0201 - val_mae: 17268.3945\n",
      "Epoch 469/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18475.3301 - val_loss: 0.0200 - val_mae: 17255.0098\n",
      "Epoch 470/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18446.5449 - val_loss: 0.0202 - val_mae: 17349.3125\n",
      "Epoch 471/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18618.1602 - val_loss: 0.0213 - val_mae: 17967.8066\n",
      "Epoch 472/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 18374.8789 - val_loss: 0.0211 - val_mae: 17685.0742\n",
      "Epoch 473/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18501.3047 - val_loss: 0.0202 - val_mae: 17326.4062\n",
      "Epoch 474/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18465.3086 - val_loss: 0.0201 - val_mae: 17245.0918\n",
      "Epoch 475/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18462.5840 - val_loss: 0.0226 - val_mae: 18556.7871\n",
      "Epoch 476/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18489.6328 - val_loss: 0.0200 - val_mae: 17211.3477\n",
      "Epoch 477/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18389.6328 - val_loss: 0.0200 - val_mae: 17209.6602\n",
      "Epoch 478/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18451.8867 - val_loss: 0.0200 - val_mae: 17209.7422\n",
      "Epoch 479/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18404.8535 - val_loss: 0.0199 - val_mae: 17198.2578\n",
      "Epoch 480/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18617.5000 - val_loss: 0.0202 - val_mae: 17298.1543\n",
      "Epoch 481/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18274.7324 - val_loss: 0.0204 - val_mae: 17358.1875\n",
      "Epoch 482/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18431.7207 - val_loss: 0.0200 - val_mae: 17201.9297\n",
      "Epoch 483/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18351.7305 - val_loss: 0.0201 - val_mae: 17238.5684\n",
      "Epoch 484/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18285.6816 - val_loss: 0.0201 - val_mae: 17241.3730\n",
      "Epoch 485/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18347.4121 - val_loss: 0.0202 - val_mae: 17246.9551\n",
      "Epoch 486/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18273.3027 - val_loss: 0.0202 - val_mae: 17314.9277\n",
      "Epoch 487/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 18252.2168 - val_loss: 0.0201 - val_mae: 17265.3340\n",
      "Epoch 488/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18344.8086 - val_loss: 0.0204 - val_mae: 17411.1777\n",
      "Epoch 489/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 18481.6309 - val_loss: 0.0200 - val_mae: 17165.6934\n",
      "Epoch 490/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18437.9180 - val_loss: 0.0200 - val_mae: 17165.0840\n",
      "Epoch 491/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18398.2012 - val_loss: 0.0205 - val_mae: 17348.8984\n",
      "Epoch 492/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18592.3613 - val_loss: 0.0202 - val_mae: 17248.4180\n",
      "Epoch 493/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18355.0996 - val_loss: 0.0199 - val_mae: 17137.5137\n",
      "Epoch 494/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18560.9102 - val_loss: 0.0199 - val_mae: 17133.7148\n",
      "Epoch 495/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18300.4629 - val_loss: 0.0200 - val_mae: 17186.7520\n",
      "Epoch 496/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18284.6543 - val_loss: 0.0202 - val_mae: 17231.5801\n",
      "Epoch 497/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18515.5586 - val_loss: 0.0199 - val_mae: 17158.7812\n",
      "Epoch 498/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18238.8496 - val_loss: 0.0198 - val_mae: 17073.4355\n",
      "Epoch 499/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18302.4492 - val_loss: 0.0201 - val_mae: 17173.8750\n",
      "Epoch 500/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18499.3594 - val_loss: 0.0200 - val_mae: 17198.3223\n",
      "Epoch 501/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0183 - mae: 18299.5469 - val_loss: 0.0200 - val_mae: 17143.9688\n",
      "Epoch 502/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18427.3223 - val_loss: 0.0204 - val_mae: 17378.3027\n",
      "Epoch 503/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18366.4824 - val_loss: 0.0200 - val_mae: 17120.9219\n",
      "Epoch 504/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18296.4434 - val_loss: 0.0205 - val_mae: 17387.8086\n",
      "Epoch 505/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18362.7031 - val_loss: 0.0199 - val_mae: 17142.5098\n",
      "Epoch 506/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 18797.9492 - val_loss: 0.0216 - val_mae: 17961.4492\n",
      "Epoch 507/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 18645.6270 - val_loss: 0.0212 - val_mae: 17805.3711\n",
      "Epoch 508/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 18578.7520 - val_loss: 0.0199 - val_mae: 17158.0098\n",
      "Epoch 509/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0184 - mae: 18354.7285 - val_loss: 0.0199 - val_mae: 17116.2207\n",
      "Epoch 510/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18332.5781 - val_loss: 0.0207 - val_mae: 17392.6953\n",
      "Epoch 511/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18283.3438 - val_loss: 0.0199 - val_mae: 17078.6660\n",
      "Epoch 512/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18252.6445 - val_loss: 0.0199 - val_mae: 17076.8438\n",
      "Epoch 513/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18237.4258 - val_loss: 0.0199 - val_mae: 17061.5234\n",
      "Epoch 514/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18382.5645 - val_loss: 0.0203 - val_mae: 17260.9648\n",
      "Epoch 515/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18235.2246 - val_loss: 0.0203 - val_mae: 17233.2812\n",
      "Epoch 516/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18344.2109 - val_loss: 0.0199 - val_mae: 17077.7988\n",
      "Epoch 517/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0185 - mae: 18305.8008 - val_loss: 0.0210 - val_mae: 17552.0332\n",
      "Epoch 518/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18374.5352 - val_loss: 0.0200 - val_mae: 17087.3828\n",
      "Epoch 519/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18374.3633 - val_loss: 0.0198 - val_mae: 17060.0156\n",
      "Epoch 520/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18338.4609 - val_loss: 0.0202 - val_mae: 17229.1426\n",
      "Epoch 521/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 18207.0059 - val_loss: 0.0198 - val_mae: 17028.2754\n",
      "Epoch 522/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18178.0234 - val_loss: 0.0201 - val_mae: 17098.4902\n",
      "Epoch 523/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 18295.8145 - val_loss: 0.0202 - val_mae: 17147.0410\n",
      "Epoch 524/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18193.4102 - val_loss: 0.0214 - val_mae: 17804.8398\n",
      "Epoch 525/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 18478.1543 - val_loss: 0.0198 - val_mae: 16995.7578\n",
      "Epoch 526/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 18167.5762 - val_loss: 0.0200 - val_mae: 17069.1738\n",
      "Epoch 527/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18321.8164 - val_loss: 0.0198 - val_mae: 16989.1738\n",
      "Epoch 528/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18094.0762 - val_loss: 0.0198 - val_mae: 16988.8477\n",
      "Epoch 529/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18384.5098 - val_loss: 0.0197 - val_mae: 16976.6445\n",
      "Epoch 530/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18317.1328 - val_loss: 0.0198 - val_mae: 16990.5801\n",
      "Epoch 531/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 18326.1328 - val_loss: 0.0198 - val_mae: 16991.2734\n",
      "Epoch 532/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 18271.2070 - val_loss: 0.0200 - val_mae: 17061.4551\n",
      "Epoch 533/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18106.1738 - val_loss: 0.0202 - val_mae: 17130.3125\n",
      "Epoch 534/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18326.2188 - val_loss: 0.0198 - val_mae: 16968.0098\n",
      "Epoch 535/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18225.9219 - val_loss: 0.0205 - val_mae: 17280.6465\n",
      "Epoch 536/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18233.3750 - val_loss: 0.0198 - val_mae: 16946.0332\n",
      "Epoch 537/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0183 - mae: 18129.6777 - val_loss: 0.0205 - val_mae: 17245.8203\n",
      "Epoch 538/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 18138.9258 - val_loss: 0.0199 - val_mae: 16999.5977\n",
      "Epoch 539/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18266.7773 - val_loss: 0.0203 - val_mae: 17155.3809\n",
      "Epoch 540/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 18263.3691 - val_loss: 0.0207 - val_mae: 17330.7578\n",
      "Epoch 541/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18177.4883 - val_loss: 0.0198 - val_mae: 16985.7793\n",
      "Epoch 542/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18119.8613 - val_loss: 0.0202 - val_mae: 17104.6914\n",
      "Epoch 543/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 18129.5918 - val_loss: 0.0199 - val_mae: 16998.7930\n",
      "Epoch 544/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18037.5254 - val_loss: 0.0201 - val_mae: 17119.2559\n",
      "Epoch 545/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 18055.4375 - val_loss: 0.0202 - val_mae: 17122.2266\n",
      "Epoch 546/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 18052.6035 - val_loss: 0.0197 - val_mae: 16915.8203\n",
      "Epoch 547/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18127.2871 - val_loss: 0.0197 - val_mae: 16881.5469\n",
      "Epoch 548/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 18213.7852 - val_loss: 0.0199 - val_mae: 16982.8672\n",
      "Epoch 549/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 18118.6328 - val_loss: 0.0198 - val_mae: 16953.9492\n",
      "Epoch 550/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18015.7012 - val_loss: 0.0197 - val_mae: 16915.4316\n",
      "Epoch 551/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18155.3027 - val_loss: 0.0197 - val_mae: 16868.3848\n",
      "Epoch 552/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 18001.6582 - val_loss: 0.0235 - val_mae: 18557.6172\n",
      "Epoch 553/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 18496.1816 - val_loss: 0.0197 - val_mae: 16859.4648\n",
      "Epoch 554/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17935.1016 - val_loss: 0.0197 - val_mae: 16859.8926\n",
      "Epoch 555/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17922.5684 - val_loss: 0.0197 - val_mae: 16845.3340\n",
      "Epoch 556/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17965.3809 - val_loss: 0.0197 - val_mae: 16846.6641\n",
      "Epoch 557/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17996.9199 - val_loss: 0.0196 - val_mae: 16818.5176\n",
      "Epoch 558/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17941.9453 - val_loss: 0.0197 - val_mae: 16857.2891\n",
      "Epoch 559/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17918.8223 - val_loss: 0.0196 - val_mae: 16810.4883\n",
      "Epoch 560/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 17974.2852 - val_loss: 0.0196 - val_mae: 16792.8262\n",
      "Epoch 561/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17879.4414 - val_loss: 0.0196 - val_mae: 16819.8457\n",
      "Epoch 562/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18057.4297 - val_loss: 0.0198 - val_mae: 16881.0957\n",
      "Epoch 563/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17932.8965 - val_loss: 0.0204 - val_mae: 17144.4941\n",
      "Epoch 564/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 18230.9648 - val_loss: 0.0197 - val_mae: 16795.9609\n",
      "Epoch 565/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 18032.2715 - val_loss: 0.0206 - val_mae: 17228.7754\n",
      "Epoch 566/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 17958.9414 - val_loss: 0.0196 - val_mae: 16773.3691\n",
      "Epoch 567/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 18081.9512 - val_loss: 0.0201 - val_mae: 16985.4961\n",
      "Epoch 568/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17967.1973 - val_loss: 0.0199 - val_mae: 16894.9316\n",
      "Epoch 569/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18053.3867 - val_loss: 0.0195 - val_mae: 16739.4375\n",
      "Epoch 570/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17919.5195 - val_loss: 0.0197 - val_mae: 16815.4277\n",
      "Epoch 571/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 17794.7734 - val_loss: 0.0198 - val_mae: 16833.2715\n",
      "Epoch 572/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 18080.2969 - val_loss: 0.0200 - val_mae: 16905.3418\n",
      "Epoch 573/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 17887.5312 - val_loss: 0.0199 - val_mae: 16868.0352\n",
      "Epoch 574/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 17968.8105 - val_loss: 0.0197 - val_mae: 16842.9414\n",
      "Epoch 575/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17940.5547 - val_loss: 0.0196 - val_mae: 16759.2148\n",
      "Epoch 576/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17854.6152 - val_loss: 0.0195 - val_mae: 16693.4668\n",
      "Epoch 577/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 17766.7676 - val_loss: 0.0203 - val_mae: 17027.9180\n",
      "Epoch 578/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17914.6172 - val_loss: 0.0195 - val_mae: 16691.6738\n",
      "Epoch 579/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17901.3535 - val_loss: 0.0197 - val_mae: 16755.1211\n",
      "Epoch 580/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 17797.5977 - val_loss: 0.0196 - val_mae: 16720.5215\n",
      "Epoch 581/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0179 - mae: 17924.8965 - val_loss: 0.0195 - val_mae: 16663.3613\n",
      "Epoch 582/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 18345.9414 - val_loss: 0.0194 - val_mae: 16637.5352\n",
      "Epoch 583/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 17787.8145 - val_loss: 0.0198 - val_mae: 16815.6426\n",
      "Epoch 584/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 17869.9180 - val_loss: 0.0207 - val_mae: 17212.8594\n",
      "Epoch 585/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 17759.9922 - val_loss: 0.0194 - val_mae: 16637.7578\n",
      "Epoch 586/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 17850.4551 - val_loss: 0.0206 - val_mae: 17126.8887\n",
      "Epoch 587/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 17815.6465 - val_loss: 0.0194 - val_mae: 16635.5762\n",
      "Epoch 588/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18004.7695 - val_loss: 0.0194 - val_mae: 16640.6465\n",
      "Epoch 589/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 17960.4355 - val_loss: 0.0197 - val_mae: 16772.1152\n",
      "Epoch 590/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17937.0684 - val_loss: 0.0199 - val_mae: 16807.4160\n",
      "Epoch 591/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17926.7148 - val_loss: 0.0197 - val_mae: 16790.3438\n",
      "Epoch 592/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0184 - mae: 18141.4102 - val_loss: 0.0202 - val_mae: 16938.0078\n",
      "Epoch 593/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 17919.8809 - val_loss: 0.0195 - val_mae: 16653.8867\n",
      "Epoch 594/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 17866.4141 - val_loss: 0.0194 - val_mae: 16609.7422\n",
      "Epoch 595/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 18021.8691 - val_loss: 0.0194 - val_mae: 16607.8984\n",
      "Epoch 596/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 17959.2422 - val_loss: 0.0194 - val_mae: 16591.1582\n",
      "Epoch 597/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17841.3027 - val_loss: 0.0194 - val_mae: 16587.9785\n",
      "Epoch 598/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17851.6836 - val_loss: 0.0195 - val_mae: 16644.0215\n",
      "Epoch 599/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17819.5312 - val_loss: 0.0198 - val_mae: 16748.6035\n",
      "Epoch 600/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 17763.1172 - val_loss: 0.0195 - val_mae: 16667.6602\n",
      "Epoch 601/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17794.6426 - val_loss: 0.0199 - val_mae: 16811.0312\n",
      "Epoch 602/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 17910.4395 - val_loss: 0.0210 - val_mae: 17286.1895\n",
      "Epoch 603/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 18034.9375 - val_loss: 0.0195 - val_mae: 16630.3828\n",
      "Epoch 604/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 17674.2832 - val_loss: 0.0194 - val_mae: 16567.2168\n",
      "Epoch 605/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 17622.2285 - val_loss: 0.0208 - val_mae: 17178.2441\n",
      "Epoch 606/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 17660.8984 - val_loss: 0.0202 - val_mae: 16940.0586\n",
      "Epoch 607/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17785.8359 - val_loss: 0.0194 - val_mae: 16569.3223\n",
      "Epoch 608/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17832.9980 - val_loss: 0.0202 - val_mae: 16892.7090\n",
      "Epoch 609/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17785.2656 - val_loss: 0.0192 - val_mae: 16493.8535\n",
      "Epoch 610/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0179 - mae: 17732.2090 - val_loss: 0.0195 - val_mae: 16611.9746\n",
      "Epoch 611/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 17608.7637 - val_loss: 0.0192 - val_mae: 16469.8887\n",
      "Epoch 612/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 17572.4492 - val_loss: 0.0194 - val_mae: 16581.1152\n",
      "Epoch 613/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 17714.0137 - val_loss: 0.0193 - val_mae: 16485.3828\n",
      "Epoch 614/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 18013.0312 - val_loss: 0.0196 - val_mae: 16589.7285\n",
      "Epoch 615/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 17613.0215 - val_loss: 0.0192 - val_mae: 16426.9043\n",
      "Epoch 616/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 17618.8672 - val_loss: 0.0198 - val_mae: 16678.9395\n",
      "Epoch 617/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 17584.5645 - val_loss: 0.0193 - val_mae: 16454.2441\n",
      "Epoch 618/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 17531.7578 - val_loss: 0.0194 - val_mae: 16519.1465\n",
      "Epoch 619/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 17492.3965 - val_loss: 0.0196 - val_mae: 16554.1875\n",
      "Epoch 620/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 17492.3672 - val_loss: 0.0195 - val_mae: 16561.0195\n",
      "Epoch 621/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 17519.9141 - val_loss: 0.0200 - val_mae: 16746.8867\n",
      "Epoch 622/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 17535.6582 - val_loss: 0.0197 - val_mae: 16615.8184\n",
      "Epoch 623/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 17864.6406 - val_loss: 0.0197 - val_mae: 16631.9102\n",
      "Epoch 624/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 17607.3398 - val_loss: 0.0194 - val_mae: 16502.8809\n",
      "Epoch 625/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 17489.8086 - val_loss: 0.0191 - val_mae: 16356.7637\n",
      "Epoch 626/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 17698.0605 - val_loss: 0.0191 - val_mae: 16334.3320\n",
      "Epoch 627/750\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0174 - mae: 17511.7148 - val_loss: 0.0193 - val_mae: 16396.5977\n",
      "Epoch 628/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 17579.1914 - val_loss: 0.0194 - val_mae: 16436.2207\n",
      "Epoch 629/750\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0174 - mae: 17464.0527 - val_loss: 0.0191 - val_mae: 16324.1289\n",
      "Epoch 630/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 17621.8574 - val_loss: 0.0190 - val_mae: 16304.2041\n",
      "Epoch 631/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 17557.7754 - val_loss: 0.0197 - val_mae: 16596.3223\n",
      "Epoch 632/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 17693.9336 - val_loss: 0.0198 - val_mae: 16606.0332\n",
      "Epoch 633/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 17468.0801 - val_loss: 0.0195 - val_mae: 16456.5078\n",
      "Epoch 634/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 17487.5430 - val_loss: 0.0192 - val_mae: 16373.1064\n",
      "Epoch 635/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17341.7715 - val_loss: 0.0193 - val_mae: 16362.7090\n",
      "Epoch 636/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 17435.9082 - val_loss: 0.0189 - val_mae: 16268.1641\n",
      "Epoch 637/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 17501.6016 - val_loss: 0.0194 - val_mae: 16445.6914\n",
      "Epoch 638/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 17730.0176 - val_loss: 0.0192 - val_mae: 16363.0381\n",
      "Epoch 639/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 17368.4746 - val_loss: 0.0191 - val_mae: 16246.4160\n",
      "Epoch 640/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0172 - mae: 17284.6211 - val_loss: 0.0190 - val_mae: 16207.5732\n",
      "Epoch 641/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 17488.9043 - val_loss: 0.0196 - val_mae: 16444.9766\n",
      "Epoch 642/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 17406.8926 - val_loss: 0.0191 - val_mae: 16253.4473\n",
      "Epoch 643/750\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.0173 - mae: 17380.8125 - val_loss: 0.0195 - val_mae: 16402.7734\n",
      "Epoch 644/750\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.0176 - mae: 17607.0801 - val_loss: 0.0202 - val_mae: 16685.1074\n",
      "Epoch 645/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 17592.8652 - val_loss: 0.0188 - val_mae: 16207.3750\n",
      "Epoch 646/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 17655.6621 - val_loss: 0.0193 - val_mae: 16337.6162\n",
      "Epoch 647/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 17176.5039 - val_loss: 0.0189 - val_mae: 16152.9365\n",
      "Epoch 648/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17237.8359 - val_loss: 0.0193 - val_mae: 16290.2793\n",
      "Epoch 649/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 17297.6016 - val_loss: 0.0190 - val_mae: 16197.4004\n",
      "Epoch 650/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 17476.6016 - val_loss: 0.0190 - val_mae: 16149.3799\n",
      "Epoch 651/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 17326.5488 - val_loss: 0.0191 - val_mae: 16181.5889\n",
      "Epoch 652/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 17744.7812 - val_loss: 0.0192 - val_mae: 16237.5254\n",
      "Epoch 653/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17166.3477 - val_loss: 0.0195 - val_mae: 16370.5684\n",
      "Epoch 654/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 17267.9004 - val_loss: 0.0189 - val_mae: 16169.8438\n",
      "Epoch 655/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17824.8711 - val_loss: 0.0217 - val_mae: 17424.2207\n",
      "Epoch 656/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 17597.5293 - val_loss: 0.0198 - val_mae: 16567.3848\n",
      "Epoch 657/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 17218.7012 - val_loss: 0.0188 - val_mae: 16062.1133\n",
      "Epoch 658/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17468.1250 - val_loss: 0.0195 - val_mae: 16375.5596\n",
      "Epoch 659/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 17247.6367 - val_loss: 0.0189 - val_mae: 16090.4004\n",
      "Epoch 660/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17256.5859 - val_loss: 0.0188 - val_mae: 16044.1777\n",
      "Epoch 661/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 17237.7578 - val_loss: 0.0190 - val_mae: 16059.9521\n",
      "Epoch 662/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0172 - mae: 17144.6953 - val_loss: 0.0210 - val_mae: 17025.1387\n",
      "Epoch 663/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0172 - mae: 17225.9473 - val_loss: 0.0192 - val_mae: 16135.5732\n",
      "Epoch 664/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17123.0840 - val_loss: 0.0195 - val_mae: 16254.2754\n",
      "Epoch 665/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 17171.7988 - val_loss: 0.0191 - val_mae: 16099.8135\n",
      "Epoch 666/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 17220.4180 - val_loss: 0.0193 - val_mae: 16223.2383\n",
      "Epoch 667/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0179 - mae: 17542.0723 - val_loss: 0.0201 - val_mae: 16523.7129\n",
      "Epoch 668/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 17318.1758 - val_loss: 0.0189 - val_mae: 16098.9502\n",
      "Epoch 669/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17157.5762 - val_loss: 0.0187 - val_mae: 16013.1748\n",
      "Epoch 670/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17108.7969 - val_loss: 0.0188 - val_mae: 15970.1494\n",
      "Epoch 671/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17112.3340 - val_loss: 0.0187 - val_mae: 15940.9570\n",
      "Epoch 672/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17152.5840 - val_loss: 0.0192 - val_mae: 16101.8428\n",
      "Epoch 673/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 17070.4688 - val_loss: 0.0187 - val_mae: 15919.2861\n",
      "Epoch 674/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17172.3594 - val_loss: 0.0189 - val_mae: 16024.0908\n",
      "Epoch 675/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 17273.5488 - val_loss: 0.0190 - val_mae: 16092.0664\n",
      "Epoch 676/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17096.3145 - val_loss: 0.0187 - val_mae: 15920.5840\n",
      "Epoch 677/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 17019.6309 - val_loss: 0.0192 - val_mae: 16109.1934\n",
      "Epoch 678/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17186.5938 - val_loss: 0.0186 - val_mae: 15852.0977\n",
      "Epoch 679/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 17167.1602 - val_loss: 0.0187 - val_mae: 15881.4004\n",
      "Epoch 680/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 17033.5371 - val_loss: 0.0189 - val_mae: 15945.8701\n",
      "Epoch 681/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 16964.1367 - val_loss: 0.0188 - val_mae: 15971.3799\n",
      "Epoch 682/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 17090.0137 - val_loss: 0.0186 - val_mae: 15824.3867\n",
      "Epoch 683/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 17042.1172 - val_loss: 0.0198 - val_mae: 16330.0039\n",
      "Epoch 684/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17065.4863 - val_loss: 0.0187 - val_mae: 15883.8320\n",
      "Epoch 685/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 17367.1406 - val_loss: 0.0189 - val_mae: 15977.6357\n",
      "Epoch 686/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 16943.0645 - val_loss: 0.0187 - val_mae: 15883.9980\n",
      "Epoch 687/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 17058.1172 - val_loss: 0.0186 - val_mae: 15813.7705\n",
      "Epoch 688/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 16937.9609 - val_loss: 0.0198 - val_mae: 16351.2588\n",
      "Epoch 689/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 17142.1387 - val_loss: 0.0192 - val_mae: 16059.3994\n",
      "Epoch 690/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17216.5957 - val_loss: 0.0197 - val_mae: 16268.3457\n",
      "Epoch 691/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 16995.4941 - val_loss: 0.0192 - val_mae: 16009.2979\n",
      "Epoch 692/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 16935.1055 - val_loss: 0.0186 - val_mae: 15805.2178\n",
      "Epoch 693/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 17204.8125 - val_loss: 0.0188 - val_mae: 15847.2744\n",
      "Epoch 694/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 16923.1328 - val_loss: 0.0185 - val_mae: 15757.5273\n",
      "Epoch 695/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 17094.9727 - val_loss: 0.0195 - val_mae: 16292.1289\n",
      "Epoch 696/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 17150.5957 - val_loss: 0.0185 - val_mae: 15765.8164\n",
      "Epoch 697/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17073.4277 - val_loss: 0.0185 - val_mae: 15796.2744\n",
      "Epoch 698/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 16825.9609 - val_loss: 0.0189 - val_mae: 15826.0312\n",
      "Epoch 699/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 16959.1152 - val_loss: 0.0185 - val_mae: 15715.4004\n",
      "Epoch 700/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 16740.7012 - val_loss: 0.0194 - val_mae: 16072.2812\n",
      "Epoch 701/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17153.9844 - val_loss: 0.0200 - val_mae: 16387.6875\n",
      "Epoch 702/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 17237.0078 - val_loss: 0.0190 - val_mae: 15934.3633\n",
      "Epoch 703/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 16808.8320 - val_loss: 0.0186 - val_mae: 15697.5977\n",
      "Epoch 704/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 16877.3242 - val_loss: 0.0196 - val_mae: 16115.5518\n",
      "Epoch 705/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 17110.9102 - val_loss: 0.0186 - val_mae: 15686.7324\n",
      "Epoch 706/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 16779.5039 - val_loss: 0.0185 - val_mae: 15675.6064\n",
      "Epoch 707/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 16869.0117 - val_loss: 0.0191 - val_mae: 16038.2637\n",
      "Epoch 708/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 16912.3477 - val_loss: 0.0187 - val_mae: 15858.4111\n",
      "Epoch 709/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 16929.4160 - val_loss: 0.0185 - val_mae: 15644.8320\n",
      "Epoch 710/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 16818.7090 - val_loss: 0.0194 - val_mae: 16221.3906\n",
      "Epoch 711/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 17057.1133 - val_loss: 0.0186 - val_mae: 15659.5205\n",
      "Epoch 712/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 16803.0117 - val_loss: 0.0184 - val_mae: 15584.7363\n",
      "Epoch 713/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 16827.8047 - val_loss: 0.0185 - val_mae: 15609.7998\n",
      "Epoch 714/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 16913.9102 - val_loss: 0.0184 - val_mae: 15581.1299\n",
      "Epoch 715/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 16757.1699 - val_loss: 0.0189 - val_mae: 15737.8164\n",
      "Epoch 716/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 16710.6250 - val_loss: 0.0183 - val_mae: 15541.9756\n",
      "Epoch 717/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 16725.5703 - val_loss: 0.0183 - val_mae: 15546.9863\n",
      "Epoch 718/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 16764.5723 - val_loss: 0.0183 - val_mae: 15535.4951\n",
      "Epoch 719/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 16780.8965 - val_loss: 0.0184 - val_mae: 15543.0801\n",
      "Epoch 720/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 16730.7402 - val_loss: 0.0187 - val_mae: 15762.5479\n",
      "Epoch 721/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 16725.2715 - val_loss: 0.0182 - val_mae: 15484.4619\n",
      "Epoch 722/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 16835.4492 - val_loss: 0.0185 - val_mae: 15546.8291\n",
      "Epoch 723/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 16679.7422 - val_loss: 0.0183 - val_mae: 15465.4473\n",
      "Epoch 724/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 16695.9512 - val_loss: 0.0186 - val_mae: 15597.6562\n",
      "Epoch 725/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 16656.4883 - val_loss: 0.0184 - val_mae: 15539.9756\n",
      "Epoch 726/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 16677.5332 - val_loss: 0.0186 - val_mae: 15758.8340\n",
      "Epoch 727/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 16995.8105 - val_loss: 0.0190 - val_mae: 15924.1387\n",
      "Epoch 728/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0163 - mae: 16720.0625 - val_loss: 0.0183 - val_mae: 15479.9795\n",
      "Epoch 729/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 16651.6914 - val_loss: 0.0183 - val_mae: 15424.5518\n",
      "Epoch 730/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 16650.7832 - val_loss: 0.0184 - val_mae: 15463.5186\n",
      "Epoch 731/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 17106.0254 - val_loss: 0.0184 - val_mae: 15495.9541\n",
      "Epoch 732/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 16807.1797 - val_loss: 0.0225 - val_mae: 17444.6270\n",
      "Epoch 733/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 17116.2520 - val_loss: 0.0182 - val_mae: 15453.7090\n",
      "Epoch 734/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0163 - mae: 16585.2402 - val_loss: 0.0182 - val_mae: 15443.1699\n",
      "Epoch 735/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 16675.2988 - val_loss: 0.0182 - val_mae: 15422.5186\n",
      "Epoch 736/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0162 - mae: 16533.8125 - val_loss: 0.0186 - val_mae: 15549.8164\n",
      "Epoch 737/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 16561.5000 - val_loss: 0.0182 - val_mae: 15407.3789\n",
      "Epoch 738/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 16543.0547 - val_loss: 0.0183 - val_mae: 15505.8711\n",
      "Epoch 739/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 16544.7207 - val_loss: 0.0183 - val_mae: 15414.1289\n",
      "Epoch 740/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 16673.4551 - val_loss: 0.0194 - val_mae: 16173.5664\n",
      "Epoch 741/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 16629.8047 - val_loss: 0.0189 - val_mae: 15642.9473\n",
      "Epoch 742/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 16577.8125 - val_loss: 0.0183 - val_mae: 15396.4434\n",
      "Epoch 743/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 16471.2227 - val_loss: 0.0182 - val_mae: 15384.6660\n",
      "Epoch 744/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 16618.2578 - val_loss: 0.0195 - val_mae: 15876.9590\n",
      "Epoch 745/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 16763.1660 - val_loss: 0.0183 - val_mae: 15434.0723\n",
      "Epoch 746/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 16958.9668 - val_loss: 0.0184 - val_mae: 15553.9980\n",
      "Epoch 747/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 16560.1816 - val_loss: 0.0183 - val_mae: 15357.7256\n",
      "Epoch 748/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 16461.0801 - val_loss: 0.0183 - val_mae: 15364.9570\n",
      "Epoch 749/750\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0163 - mae: 16534.1152 - val_loss: 0.0203 - val_mae: 16316.9502\n",
      "Epoch 750/750\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 16568.5371 - val_loss: 0.0183 - val_mae: 15334.1660\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=750, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на уровне лучших, что неплохо! Вообще, функции потерь напрямую влияют на качество модели, так как именно её оптимизатор и старается минимизировать. В целом оптимизировать квадратичные функции всегда приятно, так как мы знаем \"близость\" к \"яме\" с минимумом."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "WHgYPYiiXxd2J3kqISUUbA",
     "type": "MD"
    }
   },
   "source": [
    "### Прогнозирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остановимся на последней модели, так как она показала одни из лучших результатов, и сделаем по ней предсказание:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "NvP6Ro1j8jijcQa8KEVbbS",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>117309.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>107610.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>180175.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>189423.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>188846.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>84532.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>78478.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>169794.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>118547.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>234159.296875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  117309.671875\n",
       "1     1462  107610.031250\n",
       "2     1463  180175.453125\n",
       "3     1464  189423.671875\n",
       "4     1465  188846.437500\n",
       "...    ...            ...\n",
       "1454  2915   84532.539062\n",
       "1455  2916   78478.726562\n",
       "1456  2917  169794.984375\n",
       "1457  2918  118547.234375\n",
       "1458  2919  234159.296875\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(test_edited)\n",
    "\n",
    "output = pd.DataFrame(\n",
    "{\n",
    "    'Id':test_data['Id'],\n",
    "    'SalePrice': np.squeeze(preds)\n",
    "})\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом всё, спасибо!"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "computation_mode": "JUPYTER",
   "packages": [],
   "report_link": "https://datalore.jetbrains.com/report/Ippm1sKLQ1QOrshQAIqWf1/kPU14UXGF1igAxK1XjcH1j",
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
